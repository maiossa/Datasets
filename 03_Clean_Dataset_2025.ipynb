{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a28af644",
   "metadata": {},
   "source": [
    "# 03_Clean_Dataset_2025 - Intelligente Adressextraktion\n",
    "\n",
    "## ðŸŽ¯ **Spezifische Bereinigung fÃ¼r Dataset 2025**\n",
    "\n",
    "### **Hauptfunktionen:**\n",
    "- **Intelligente PLZ-Extraktion** aus verschiedenen Adressformaten\n",
    "- **Bezirk-Normalisierung** mit Alias-Mapping\n",
    "- **Multi-Listing-Behandlung** (Preis- und GrÃ¶ÃŸenspannen)\n",
    "- **Filter-Harmonisierung** mit anderen Datasets\n",
    "- **Standardisierte Ausgabe** kompatibel mit anderen Datasets\n",
    "\n",
    "### **ðŸ”„ Filter-Harmonisierung (Konsistent mit allen Datasets):**\n",
    "- **Preis-Filter:** 100â‚¬ - 10.000â‚¬ (Kaltmiete)\n",
    "- **GrÃ¶ÃŸen-Filter:** 10mÂ² - 500mÂ² (WohnflÃ¤che)\n",
    "- **Bezirk-Validierung:** Nur gÃ¼ltige Berliner Bezirke\n",
    "\n",
    "### **ðŸ“‹ Adressformate im 2025 Dataset:**\n",
    "1. **VollstÃ¤ndige Adresse mit PLZ:** \"Johannisplatz 3, 10117 Berlin\"\n",
    "2. **Adresse mit Bezirk:** \"Johannisplatz 5, Mitte (Ortsteil), Berlin\" \n",
    "3. **Nur Bezirk:** \"Tiergarten, Berlin\"\n",
    "4. **Nur PLZ:** \"10557 Berlin\"\n",
    "5. **Adresse mit Ortsteil:** \"Friedrichshain, Berlin\"\n",
    "\n",
    "### **ðŸŽ¯ Ziel:** \n",
    "Einheitliche Bezirk-Zuordnung und maximale Vergleichbarkeit mit Dataset 2018-2019 und Dataset 2022\n",
    "\n",
    "---\n",
    "**Teil der modularen Preprocessing-Pipeline**  \n",
    "**Datum:** 4. Juli 2025  \n",
    "**Version:** 1.1 (Filter-Harmonisierung)  \n",
    "**Status:** âœ… Harmonisiert mit allen anderen Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2b3a266",
   "metadata": {},
   "source": [
    "## 1. Setup und Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9a456e00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bibliotheken erfolgreich importiert!\n",
      "Pandas Version: 2.2.3\n",
      "Dataset: 2025 (ImmobilienScout24)\n",
      "Ziel: Intelligente Adressextraktion und Bezirk-Normalisierung\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from collections import Counter\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"Bibliotheken erfolgreich importiert!\")\n",
    "print(f\"Pandas Version: {pd.__version__}\")\n",
    "print(\"Dataset: 2025 (ImmobilienScout24)\")\n",
    "print(\"Ziel: Intelligente Adressextraktion und Bezirk-Normalisierung\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a068c88",
   "metadata": {},
   "source": [
    "## 2. PLZ-Mapping und Bezirk-Normalisierung laden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9037091a",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "unterminated string literal (detected at line 118) (4274493469.py, line 118)",
     "output_type": "error",
     "traceback": [
      "  \u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 118\u001b[39m\n\u001b[31m    \u001b[39m\u001b[31mprint(\"\u001b[39m\n          ^\n\u001b[31mSyntaxError\u001b[39m\u001b[31m:\u001b[39m unterminated string literal (detected at line 118)\n"
     ]
    }
   ],
   "source": [
    "print(\"=\"*60)\n",
    "print(\"PLZ-MAPPING UND BEZIRK-NORMALISIERUNG\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# PLZ-Mapping laden\n",
    "plz_mapping_df = pd.read_csv('data/processed/berlin_plz_mapping.csv')\n",
    "plz_to_district = dict(zip(plz_mapping_df['PLZ'], plz_mapping_df['Bezirk']))\n",
    "\n",
    "# Erweiterte PLZ-Mappings fÃ¼r alle Datasets\n",
    "extended_plz_mapping = {\n",
    "    12627: 'Marzahn-Hellersdorf',\n",
    "    12629: 'Marzahn-Hellersdorf', \n",
    "    12679: 'Marzahn-Hellersdorf',\n",
    "    12681: 'Marzahn-Hellersdorf',\n",
    "    12683: 'Marzahn-Hellersdorf',\n",
    "    12685: 'Marzahn-Hellersdorf',\n",
    "    12687: 'Marzahn-Hellersdorf',\n",
    "    12689: 'Marzahn-Hellersdorf',\n",
    "    13593: 'Spandau',\n",
    "    13595: 'Spandau',\n",
    "    13597: 'Spandau',\n",
    "    13599: 'Spandau',\n",
    "    14052: 'Charlottenburg-Wilmersdorf',\n",
    "    14055: 'Charlottenburg-Wilmersdorf',\n",
    "    14057: 'Charlottenburg-Wilmersdorf', \n",
    "    14059: 'Charlottenburg-Wilmersdorf',\n",
    "    10315: 'Lichtenberg',\n",
    "    10317: 'Lichtenberg',\n",
    "    10318: 'Lichtenberg',\n",
    "    10319: 'Lichtenberg',\n",
    "    10365: 'Lichtenberg',\n",
    "    10367: 'Lichtenberg',\n",
    "    10369: 'Lichtenberg',\n",
    "    13125: 'Pankow',\n",
    "    13127: 'Pankow',\n",
    "    13129: 'Pankow',\n",
    "    13156: 'Pankow',\n",
    "    13158: 'Pankow',\n",
    "    13159: 'Pankow',\n",
    "    13187: 'Pankow',\n",
    "    13189: 'Pankow',\n",
    "    12305: 'Tempelhof-SchÃ¶neberg',\n",
    "    12307: 'Tempelhof-SchÃ¶neberg',\n",
    "    12309: 'Tempelhof-SchÃ¶neberg',\n",
    "    12347: 'NeukÃ¶lln',\n",
    "    12349: 'NeukÃ¶lln',\n",
    "    12351: 'NeukÃ¶lln',\n",
    "    12353: 'NeukÃ¶lln',\n",
    "    12355: 'NeukÃ¶lln',\n",
    "    12357: 'NeukÃ¶lln',\n",
    "    12359: 'NeukÃ¶lln',\n",
    "    12524: 'Treptow-KÃ¶penick',\n",
    "    12555: 'Treptow-KÃ¶penick',\n",
    "    10247: 'Friedrichshain-Kreuzberg',\n",
    "    10249: 'Friedrichshain-Kreuzberg',\n",
    "    10367: 'Lichtenberg',\n",
    "    10369: 'Lichtenberg',\n",
    "    14612: 'Falkensee',  # AuÃŸerhalb Berlin\n",
    "    13507: 'Reinickendorf',\n",
    "    10585: 'Charlottenburg-Wilmersdorf',\n",
    "    10709: 'Charlottenburg-Wilmersdorf',\n",
    "    10559: 'Mitte',\n",
    "}\n",
    "\n",
    "# Erweitere PLZ-Mapping\n",
    "plz_to_district.update(extended_plz_mapping)\n",
    "\n",
    "# Bezirk-Normalisierung (verschiedene Schreibweisen auf einheitliche Namen mappen)\n",
    "district_aliases = {\n",
    "    'Mitte (Ortsteil)': 'Mitte',\n",
    "    'Pankow (Ortsteil)': 'Pankow',\n",
    "    'Spandau (Ortsteil)': 'Spandau',\n",
    "    'NeukÃ¶lln (Ortsteil)': 'NeukÃ¶lln',\n",
    "    'Friedrichshain': 'Friedrichshain-Kreuzberg',\n",
    "    'Kreuzberg': 'Friedrichshain-Kreuzberg',\n",
    "    'Charlottenburg': 'Charlottenburg-Wilmersdorf',\n",
    "    'Wilmersdorf': 'Charlottenburg-Wilmersdorf',\n",
    "    'SchÃ¶neberg': 'Tempelhof-SchÃ¶neberg',\n",
    "    'Tempelhof': 'Tempelhof-SchÃ¶neberg',\n",
    "    'KÃ¶penick': 'Treptow-KÃ¶penick',\n",
    "    'Treptow': 'Treptow-KÃ¶penick',\n",
    "    'Alt-Treptow': 'Treptow-KÃ¶penick',\n",
    "    'Rummelsburg': 'Lichtenberg',\n",
    "    'Friedrichshagen': 'Treptow-KÃ¶penick',\n",
    "    'PlÃ¤nterwald': 'Treptow-KÃ¶penick',\n",
    "    'Prenzlauer Berg': 'Pankow',\n",
    "    'WeiÃŸensee': 'Pankow',\n",
    "    'Buch': 'Pankow',\n",
    "    'NiederschÃ¶nhausen': 'Pankow',\n",
    "    'Gesundbrunnen': 'Mitte',\n",
    "    'Wedding': 'Mitte',\n",
    "    'Moabit': 'Mitte',\n",
    "    'Tiergarten': 'Mitte',\n",
    "    'Friedenau': 'Tempelhof-SchÃ¶neberg',\n",
    "    'Steglitz': 'Steglitz-Zehlendorf',\n",
    "    'Zehlendorf': 'Steglitz-Zehlendorf',\n",
    "    'Schmargendorf': 'Charlottenburg-Wilmersdorf',\n",
    "    'Grunewald': 'Charlottenburg-Wilmersdorf',\n",
    "    'Halensee': 'Charlottenburg-Wilmersdorf',\n",
    "    'Tegel': 'Reinickendorf',\n",
    "    'Heiligensee': 'Reinickendorf',\n",
    "    'Staaken': 'Spandau',\n",
    "    'Siemensstadt': 'Spandau',\n",
    "    'Malchow': 'Pankow',\n",
    "    'Reinickendorf': 'Reinickendorf',\n",
    "    'Lichtenberg': 'Lichtenberg',\n",
    "    'Marzahn-Hellersdorf': 'Marzahn-Hellersdorf',\n",
    "    'Spandau': 'Spandau',\n",
    "    'NeukÃ¶lln': 'NeukÃ¶lln',\n",
    "    'Mitte': 'Mitte',\n",
    "    'Pankow': 'Pankow',\n",
    "}\n",
    "\n",
    "print(f\"âœ… PLZ-Mapping geladen: {len(plz_to_district)} Zuordnungen\")\n",
    "print(f\"âœ… Bezirk-Aliases definiert: {len(district_aliases)} Zuordnungen\")\n",
    "\n",
    "# Zeige Beispiele\n",
    "print(\"\n",
    "PLZ-Mapping Beispiele:\")\n",
    "for plz, district in list(plz_to_district.items())[:5]:\n",
    "    print(f\"  {plz} â†’ {district}\")\n",
    "    \n",
    "print(\"\n",
    "Bezirk-Normalisierung Beispiele:\")\n",
    "for alias, normalized in list(district_aliases.items())[:5]:\n",
    "    print(f\"  '{alias}' â†’ '{normalized}'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31e94ac7",
   "metadata": {},
   "source": [
    "## 3. Dataset 2025 laden und analysieren"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fed89cb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "DATASET 2025 LADEN UND ANALYSIEREN\n",
      "============================================================\n",
      "Dataset geladen: 6,109 Zeilen, 5 Spalten\n",
      "\n",
      "Spalten: ['title', 'price', 'size', 'address', 'link']\n",
      "\n",
      "Datentypen:\n",
      "title      object\n",
      "price      object\n",
      "size       object\n",
      "address    object\n",
      "link       object\n",
      "dtype: object\n",
      "\n",
      "Fehlende Werte:\n",
      "\n",
      "=== ADRESSFORMAT-ANALYSE ===\n",
      "Erste 10 Adressen:\n",
      "  1. Biedenkopfer StraÃŸe 46-54, 13507 Berlin\n",
      "  2. Seegefelder StraÃŸe 150, 14612 Falkensee\n",
      "  3. Johannisplatz 5, Mitte (Ortsteil), Berlin\n",
      "  4. PufendorfstraÃŸe 3A-3E, Friedrichshain, Berlin\n",
      "  5. Warburgzeile 1, 10585 Berlin\n",
      "  6. Johannisplatz 3, 10117 Berlin\n",
      "  7. KreutzigerstraÃŸe 14, Friedrichshain, Berlin\n",
      "  8. Elsa-Neumann-StraÃŸe 1, 13629 Berlin\n",
      "  9. Tiergarten, Berlin\n",
      "  10. ChausseestraÃŸe 108, Mitte (Ortsteil), Berlin\n",
      "\n",
      "Einzigartige Adressformate (Sample):\n",
      "  â€¢ Biedenkopfer StraÃŸe 46-54, 13507 Berlin\n",
      "  â€¢ Seegefelder StraÃŸe 150, 14612 Falkensee\n",
      "  â€¢ Johannisplatz 5, Mitte (Ortsteil), Berlin\n",
      "  â€¢ PufendorfstraÃŸe 3A-3E, Friedrichshain, Berlin\n",
      "  â€¢ Warburgzeile 1, 10585 Berlin\n"
     ]
    }
   ],
   "source": [
    "print(\"=\"*60)\n",
    "print(\"DATASET 2025 LADEN UND ANALYSIEREN\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Dataset laden\n",
    "df = pd.read_csv('data/raw/Dataset_2025.csv')\n",
    "print(f\"Dataset geladen: {len(df):,} Zeilen, {len(df.columns)} Spalten\")\n",
    "\n",
    "print(f\"Spalten: {list(df.columns)}\")\n",
    "\n",
    "print(f\"Datentypen:\")\n",
    "print(df.dtypes)\n",
    "\n",
    "print(f\"Fehlende Werte:\")\n",
    "missing_values = df.isnull().sum()\n",
    "missing_values = missing_values[missing_values > 0]\n",
    "for col, count in missing_values.items():\n",
    "    print(f\"  {col}: {count} ({100*count/len(df):.2f}%)\")\n",
    "\n",
    "# Erste Adressfelder analysieren\n",
    "print(f\"=== ADRESSFORMAT-ANALYSE ===\")\n",
    "print(\"Erste 10 Adressen:\")\n",
    "for i, addr in enumerate(df['address'].head(10)):\n",
    "    print(f\"  {i+1}. {addr}\")\n",
    "\n",
    "print(f\"Einzigartige Adressformate (Sample):\")\n",
    "unique_addresses = df['address'].dropna().unique()\n",
    "for addr in unique_addresses[:5]:\n",
    "    print(f\"  â€¢ {addr}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d5851ec",
   "metadata": {},
   "source": [
    "## 4. Intelligente Adressextraktion und Bezirk-Zuordnung"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11ffb666",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "INTELLIGENTE ADRESSEXTRAKTION\n",
      "============================================================\n",
      "Extrahiere Bezirke aus Adressen...\n",
      "âœ… Bezirk-Extraktion abgeschlossen:\n",
      "  Gesamt Adressen: 6,109\n",
      "  Erfolgreiche Extraktion: 4,779\n",
      "  Erfolgsrate: 78.2%\n",
      "\n",
      "=== ERFOLGREICHE EXTRAKTION (Beispiele) ===\n",
      "  'Biedenkopfer StraÃŸe 46-54, 13507 Berlin' â†’ Reinickendorf\n",
      "  'Seegefelder StraÃŸe 150, 14612 Falkensee' â†’ Falkensee\n",
      "  'Johannisplatz 5, Mitte (Ortsteil), Berlin' â†’ Mitte\n",
      "  'PufendorfstraÃŸe 3A-3E, Friedrichshain, Berlin' â†’ Friedrichshain-Kreuzberg\n",
      "  'Warburgzeile 1, 10585 Berlin' â†’ Charlottenburg-Wilmersdorf\n",
      "  'Johannisplatz 3, 10117 Berlin' â†’ Mitte\n",
      "  'KreutzigerstraÃŸe 14, Friedrichshain, Berlin' â†’ Friedrichshain-Kreuzberg\n",
      "  'Elsa-Neumann-StraÃŸe 1, 13629 Berlin' â†’ Spandau\n",
      "  'Tiergarten, Berlin' â†’ Mitte\n",
      "  'ChausseestraÃŸe 108, Mitte (Ortsteil), Berlin' â†’ Mitte\n",
      "\n",
      "=== NICHT-EXTRAHIERTE ADRESSEN (1330 EintrÃ¤ge) ===\n",
      "  âŒ 'Abendseglersteig 55, Rahnsdorf, Berlin'\n",
      "  âŒ 'GrÃ¼nauer StraÃŸe 26, Altglienicke, Berlin'\n",
      "  âŒ 'Am Maselakepark 31, Hakenfelde, Berlin'\n",
      "  âŒ 'Lion-Feuchtwanger StraÃŸe 61, Hellersdorf, Berlin'\n",
      "  âŒ 'LehderstraÃŸe 26-27, 13806 Berlin'\n",
      "  âŒ 'RegattastraÃŸe 7, GrÃ¼nau, Berlin'\n",
      "  âŒ 'Ahrenshooper StraÃŸe 10, Neu-HohenschÃ¶nhausen, Berlin'\n",
      "  âŒ 'Ahrenshooper StraÃŸe 14, Neu-HohenschÃ¶nhausen, Berlin'\n",
      "  âŒ 'Parksiedlung Spruch 3 bis 137, Buckow, Berlin'\n",
      "  âŒ 'Brixplatz 13, Westend, Berlin'\n",
      "\n",
      "=== BEZIRK-VERTEILUNG ===\n",
      "Anzahl einzigartiger Bezirke: 22\n",
      "  Mitte: 1026 EintrÃ¤ge\n",
      "  Pankow: 784 EintrÃ¤ge\n",
      "  Friedrichshain-Kreuzberg: 776 EintrÃ¤ge\n",
      "  Charlottenburg-Wilmersdorf: 602 EintrÃ¤ge\n",
      "  NeukÃ¶lln: 397 EintrÃ¤ge\n",
      "  Tempelhof-SchÃ¶neberg: 355 EintrÃ¤ge\n",
      "  Treptow-KÃ¶penick: 276 EintrÃ¤ge\n",
      "  Steglitz-Zehlendorf: 170 EintrÃ¤ge\n",
      "  Lichtenberg: 148 EintrÃ¤ge\n",
      "  Reinickendorf: 129 EintrÃ¤ge\n",
      "\n",
      "âœ… Verbleibende EintrÃ¤ge nach Bezirk-Extraktion: 4,779\n",
      "Datenverlust: 1,330 EintrÃ¤ge (21.8%)\n"
     ]
    }
   ],
   "source": [
    "def extract_district_from_address(address):\n",
    "    \"\"\"\n",
    "    Intelligente Bezirk-Extraktion aus verschiedenen Adressformaten\n",
    "    \n",
    "    UnterstÃ¼tzte Formate:\n",
    "    1. PLZ-basiert: \"Johannisplatz 3, 10117 Berlin\"\n",
    "    2. Bezirk direkt: \"Johannisplatz 5, Mitte (Ortsteil), Berlin\"\n",
    "    3. Nur Bezirk: \"Tiergarten, Berlin\"\n",
    "    4. Nur PLZ: \"10557 Berlin\"\n",
    "    \"\"\"\n",
    "    if pd.isna(address):\n",
    "        return None\n",
    "    \n",
    "    address = str(address).strip()\n",
    "    \n",
    "    # Methode 1: PLZ-Extraktion (5-stellige Zahlen)\n",
    "    plz_match = re.search(r'\\b(\\d{5})\\b', address)\n",
    "    if plz_match:\n",
    "        plz = int(plz_match.group(1))\n",
    "        if plz in plz_to_district:\n",
    "            return plz_to_district[plz]\n",
    "    \n",
    "    # Methode 2: Bezirk-Namen direkt im Text finden\n",
    "    # Entferne \"Berlin\" vom Ende und teile bei Komma\n",
    "    address_clean = address.replace(', Berlin', '').replace(' Berlin', '')\n",
    "    \n",
    "    # Suche nach bekannten Bezirken in der Adresse\n",
    "    for alias, normalized in district_aliases.items():\n",
    "        if alias.lower() in address_clean.lower():\n",
    "            return normalized\n",
    "    \n",
    "    # Methode 3: Letzte Komponente vor \"Berlin\" als Bezirk\n",
    "    parts = address_clean.split(',')\n",
    "    if len(parts) >= 2:\n",
    "        potential_district = parts[-1].strip()\n",
    "        # Entferne ZusÃ¤tze wie \"(Ortsteil)\"\n",
    "        potential_district = re.sub(r'\\s*\\([^)]+\\)', '', potential_district)\n",
    "        \n",
    "        # PrÃ¼fe ob es ein bekannter Bezirk ist\n",
    "        if potential_district in district_aliases:\n",
    "            return district_aliases[potential_district]\n",
    "    \n",
    "    # Methode 4: Direkte Bezirk-Suche im gesamten Text\n",
    "    for bezirk in district_aliases.values():\n",
    "        if bezirk.lower() in address_clean.lower():\n",
    "            return bezirk\n",
    "    \n",
    "    return None\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"INTELLIGENTE ADRESSEXTRAKTION\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Arbeite mit einer Kopie\n",
    "df_clean = df.copy()\n",
    "\n",
    "# Bezirk extrahieren\n",
    "print(\"Extrahiere Bezirke aus Adressen...\")\n",
    "df_clean['district'] = df_clean['address'].apply(extract_district_from_address)\n",
    "\n",
    "# Statistiken\n",
    "total_addresses = len(df_clean)\n",
    "successful_extractions = df_clean['district'].notna().sum()\n",
    "success_rate = 100 * successful_extractions / total_addresses\n",
    "\n",
    "print(f\"âœ… Bezirk-Extraktion abgeschlossen:\")\n",
    "print(f\"  Gesamt Adressen: {total_addresses:,}\")\n",
    "print(f\"  Erfolgreiche Extraktion: {successful_extractions:,}\")\n",
    "print(f\"  Erfolgsrate: {success_rate:.1f}%\")\n",
    "\n",
    "# Zeige Beispiele erfolgreicher Extraktion\n",
    "print(f\"=== ERFOLGREICHE EXTRAKTION (Beispiele) ===\")\n",
    "successful_examples = df_clean[df_clean['district'].notna()][['address', 'district']].head(10)\n",
    "for idx, row in successful_examples.iterrows():\n",
    "    print(f\"  '{row['address']}' â†’ {row['district']}\")\n",
    "\n",
    "# Zeige nicht-extrahierte Adressen\n",
    "failed_extractions = df_clean[df_clean['district'].isna()]\n",
    "if len(failed_extractions) > 0:\n",
    "    print(f\"=== NICHT-EXTRAHIERTE ADRESSEN ({len(failed_extractions)} EintrÃ¤ge) ===\")\n",
    "    for addr in failed_extractions['address'].unique()[:10]:\n",
    "        print(f\"  âŒ '{addr}'\")\n",
    "        \n",
    "# Bezirk-Verteilung\n",
    "print(f\"=== BEZIRK-VERTEILUNG ===\")\n",
    "district_counts = df_clean['district'].value_counts()\n",
    "print(f\"Anzahl einzigartiger Bezirke: {len(district_counts)}\")\n",
    "for district, count in district_counts.head(10).items():\n",
    "    print(f\"  {district}: {count} EintrÃ¤ge\")\n",
    "    \n",
    "# Nur Zeilen mit erfolgreich extrahierten Bezirken behalten\n",
    "df_clean = df_clean[df_clean['district'].notna()]\n",
    "print(f\"âœ… Verbleibende EintrÃ¤ge nach Bezirk-Extraktion: {len(df_clean):,}\")\n",
    "print(f\"Datenverlust: {total_addresses - len(df_clean):,} EintrÃ¤ge ({100*(total_addresses - len(df_clean))/total_addresses:.1f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e64402b8",
   "metadata": {},
   "source": [
    "## 5. Datenbereinigung und Filter-Harmonisierung\n",
    "\n",
    "### ðŸŽ¯ **Einheitliche Bereinigungskriterien**\n",
    "**Konsistent mit allen anderen Datasets in der Pipeline:**\n",
    "- **Preis-Filter:** 100â‚¬ - 10.000â‚¬ (Kaltmiete)\n",
    "- **GrÃ¶ÃŸen-Filter:** 10mÂ² - 500mÂ² (WohnflÃ¤che)\n",
    "- **Bezirk-Validierung:** Nur gÃ¼ltige Berliner Bezirke\n",
    "\n",
    "### ðŸ“‹ **Multi-Listing-Behandlung**\n",
    "Dataset 2025 enthÃ¤lt Multi-Listings (Preis- und GrÃ¶ÃŸenspannen):\n",
    "- **Preisspannen:** \"725 - 1.965â‚¬\" â†’ Nimm Mindestpreis (725â‚¬)\n",
    "- **GrÃ¶ÃŸenspannen:** \"26,55 - 112,82mÂ²\" â†’ Nimm MindestgrÃ¶ÃŸe (26,55mÂ²)\n",
    "- **Rationale:** Konservative Schï¿½ï¿½tzung fÃ¼r Vergleichbarkeit\n",
    "\n",
    "### ðŸ”„ **Harmonisierung mit anderen Datasets**\n",
    "- **Dataset 2018-2019:** Gleiche Filter (100â‚¬-10.000â‚¬, 10mÂ²-500mÂ²)\n",
    "- **Dataset 2022:** Filter aktualisiert auf gleiche Werte\n",
    "- **Dataset 2025:** Implementiert gleiche Logik\n",
    "\n",
    "**Ziel:** Maximale Vergleichbarkeit und Konsistenz zwischen allen ZeitrÃ¤umen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c4d1cb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "DATENBEREINIGUNG UND MULTI-LISTING-BEHANDLUNG\n",
      "============================================================\n",
      "Bereinige Preisfelder...\n",
      "Bereinige GrÃ¶ÃŸenfelder...\n",
      "\n",
      "=== BEREINIGUNGSSTATISTIKEN ===\n",
      "UrsprÃ¼ngliche EintrÃ¤ge: 4,779\n",
      "GÃ¼ltige Preise: 4,779/4,779 (100.0%)\n",
      "GÃ¼ltige GrÃ¶ÃŸen: 4,779/4,779 (100.0%)\n",
      "Beide gÃ¼ltig: 4,779/4,779 (100.0%)\n",
      "\n",
      "=== UNREALISTISCHE WERTE ENTFERNEN ===\n",
      "Nach Preis-Filter: 4,764 (entfernt: 15)\n",
      "Nach GrÃ¶ÃŸen-Filter: 4,763 (entfernt: 1)\n",
      "\n",
      "âœ… Datenbereinigung abgeschlossen\n",
      "Finale DatensÃ¤tze: 4,763\n",
      "\n",
      "=== FINALE DATENVERTEILUNG ===\n",
      "Preis - Min: 150.00â‚¬, Max: 9990.00â‚¬, Median: 1000.00â‚¬\n",
      "GrÃ¶ÃŸe - Min: 11.0mÂ², Max: 361.0mÂ², Median: 65.0mÂ²\n"
     ]
    }
   ],
   "source": [
    "def clean_price_field(price_str):\n",
    "    \"\"\"\n",
    "    Bereinige Preisfeld und extrahiere Einzelpreise aus Multi-Listings\n",
    "    \n",
    "    Behandelt folgende Formate:\n",
    "    - Einzelpreis: \"1.235â‚¬\" â†’ 1235.0\n",
    "    - Preisspanne: \"725 - 1.965â‚¬\" â†’ 725.0 (Mindestpreis)\n",
    "    - Deutsche Formate: \"1.235,65â‚¬\" â†’ 1235.65\n",
    "    \n",
    "    Returns:\n",
    "        float: Bereinigter Preis oder None bei Fehlern\n",
    "    \"\"\"\n",
    "    if pd.isna(price_str):\n",
    "        return None\n",
    "    \n",
    "    price_str = str(price_str).strip()\n",
    "    \n",
    "    # Entferne Euro-Zeichen und Leerzeichen\n",
    "    price_str = price_str.replace('â‚¬', '').replace(' ', '')\n",
    "    \n",
    "    # Behandle Preisspannen (z.B. \"725 - 1.965\")\n",
    "    if '-' in price_str:\n",
    "        # Multi-Listing: Nimm Minimalpreis fÃ¼r Vergleichbarkeit\n",
    "        parts = price_str.split('-')\n",
    "        try:\n",
    "            min_price = float(parts[0].replace('.', '').replace(',', '.'))\n",
    "            return min_price\n",
    "        except:\n",
    "            return None\n",
    "    \n",
    "    # Einzelpreis\n",
    "    try:\n",
    "        # Behandle deutsche Zahlenformate (1.435,65 â†’ 1435.65)\n",
    "        if ',' in price_str and '.' in price_str:\n",
    "            # Format: 1.435,65\n",
    "            price_str = price_str.replace('.', '').replace(',', '.')\n",
    "        elif ',' in price_str:\n",
    "            # Format: 1435,65\n",
    "            price_str = price_str.replace(',', '.')\n",
    "        elif '.' in price_str and len(price_str.split('.')[-1]) == 2:\n",
    "            # Format: 1435.65 (bereits korrekt)\n",
    "            pass\n",
    "        else:\n",
    "            # Format: 1435 (Tausender-Trennzeichen entfernen)\n",
    "            price_str = price_str.replace('.', '')\n",
    "        \n",
    "        return float(price_str)\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "def clean_size_field(size_str):\n",
    "    \"\"\"\n",
    "    Bereinige GrÃ¶ÃŸenfeld und extrahiere EinzelgrÃ¶ÃŸen aus Multi-Listings\n",
    "    \n",
    "    Behandelt folgende Formate:\n",
    "    - EinzelgrÃ¶ÃŸe: \"67,5mÂ²\" â†’ 67.5\n",
    "    - GrÃ¶ÃŸenspanne: \"26,55 - 112,82mÂ²\" â†’ 26.55 (MindestgrÃ¶ÃŸe)\n",
    "    - Verschiedene Trennzeichen: \"67,5\" oder \"67.5\"\n",
    "    \n",
    "    Returns:\n",
    "        float: Bereinigte GrÃ¶ÃŸe oder None bei Fehlern\n",
    "    \"\"\"\n",
    "    if pd.isna(size_str):\n",
    "        return None\n",
    "    \n",
    "    size_str = str(size_str).strip()\n",
    "    \n",
    "    # Entferne mÂ² und Leerzeichen\n",
    "    size_str = size_str.replace('mÂ²', '').replace(' ', '')\n",
    "    \n",
    "    # Behandle GrÃ¶ÃŸenspannen (z.B. \"26,55 - 112,82\")\n",
    "    if '-' in size_str:\n",
    "        # Multi-Listing: Nimm MinimalgrÃ¶ÃŸe fÃ¼r Vergleichbarkeit\n",
    "        parts = size_str.split('-')\n",
    "        try:\n",
    "            min_size = float(parts[0].replace(',', '.'))\n",
    "            return min_size\n",
    "        except:\n",
    "            return None\n",
    "    \n",
    "    # EinzelgrÃ¶ÃŸe\n",
    "    try:\n",
    "        return float(size_str.replace(',', '.'))\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "# ===================================================================\n",
    "# EINHEITLICHE DATENBEREINIGUNG (HARMONISIERT MIT ALLEN DATASETS)\n",
    "# ===================================================================\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"DATENBEREINIGUNG UND MULTI-LISTING-BEHANDLUNG\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Bereinige Preise\n",
    "print(\"Bereinige Preisfelder...\")\n",
    "df_clean['price_clean'] = df_clean['price'].apply(clean_price_field)\n",
    "\n",
    "# Bereinige GrÃ¶ÃŸen\n",
    "print(\"Bereinige GrÃ¶ÃŸenfelder...\")\n",
    "df_clean['size_clean'] = df_clean['size'].apply(clean_size_field)\n",
    "\n",
    "# Statistiken vor Bereinigung\n",
    "print(f\"=== BEREINIGUNGSSTATISTIKEN ===\")\n",
    "print(f\"UrsprÃ¼ngliche EintrÃ¤ge: {len(df_clean):,}\")\n",
    "\n",
    "# Entferne Zeilen ohne gÃ¼ltige Preise\n",
    "valid_prices = df_clean['price_clean'].notna()\n",
    "print(f\"GÃ¼ltige Preise: {valid_prices.sum():,}/{len(df_clean):,} ({100*valid_prices.sum()/len(df_clean):.1f}%)\")\n",
    "\n",
    "# Entferne Zeilen ohne gÃ¼ltige GrÃ¶ÃŸen\n",
    "valid_sizes = df_clean['size_clean'].notna()\n",
    "print(f\"GÃ¼ltige GrÃ¶ÃŸen: {valid_sizes.sum():,}/{len(df_clean):,} ({100*valid_sizes.sum()/len(df_clean):.1f}%)\")\n",
    "\n",
    "# Kombiniere Bedingungen\n",
    "valid_data = valid_prices & valid_sizes\n",
    "print(f\"Beide gÃ¼ltig: {valid_data.sum():,}/{len(df_clean):,} ({100*valid_data.sum()/len(df_clean):.1f}%)\")\n",
    "\n",
    "# Behalte nur gÃ¼ltige Daten\n",
    "df_clean = df_clean[valid_data]\n",
    "\n",
    "# ===================================================================\n",
    "# EINHEITLICHE FILTER-KRITERIEN (KONSISTENT MIT ALLEN DATASETS)\n",
    "# ===================================================================\n",
    "\n",
    "print(f\"=== EINHEITLICHE FILTER-KRITERIEN ===\")\n",
    "print(f\"ðŸ“‹ Harmonisiert mit Dataset 2018-2019 und Dataset 2022\")\n",
    "print(f\"ðŸŽ¯ Ziel: Maximale Vergleichbarkeit zwischen allen ZeitrÃ¤umen\")\n",
    "\n",
    "initial_count = len(df_clean)\n",
    "\n",
    "# Preis-Filter (100â‚¬ - 10.000â‚¬) - KONSISTENT MIT ALLEN DATASETS\n",
    "print(f\"ðŸ”¹ Preis-Filter: 100â‚¬ - 10.000â‚¬\")\n",
    "df_clean = df_clean[(df_clean['price_clean'] >= 100) & (df_clean['price_clean'] <= 10000)]\n",
    "print(f\"Nach Preis-Filter: {len(df_clean):,} (entfernt: {initial_count - len(df_clean):,})\")\n",
    "\n",
    "# GrÃ¶ÃŸen-Filter (10mÂ² - 500mÂ²) - KONSISTENT MIT ALLEN DATASETS\n",
    "print(f\"ðŸ”¹ GrÃ¶ÃŸen-Filter: 10mÂ² - 500mÂ²\")\n",
    "initial_count = len(df_clean)\n",
    "df_clean = df_clean[(df_clean['size_clean'] >= 10) & (df_clean['size_clean'] <= 500)]\n",
    "print(f\"Nach GrÃ¶ÃŸen-Filter: {len(df_clean):,} (entfernt: {initial_count - len(df_clean):,})\")\n",
    "\n",
    "print(f\"âœ… Datenbereinigung abgeschlossen\")\n",
    "print(f\"âœ… Filter-Harmonisierung erfolgreich\")\n",
    "print(f\"Finale DatensÃ¤tze: {len(df_clean):,}\")\n",
    "\n",
    "# Zeige Preis- und GrÃ¶ÃŸenverteilung\n",
    "print(f\"=== FINALE DATENVERTEILUNG ===\")\n",
    "print(f\"Preis - Min: {df_clean['price_clean'].min():.2f}â‚¬, Max: {df_clean['price_clean'].max():.2f}â‚¬, Median: {df_clean['price_clean'].median():.2f}â‚¬\")\n",
    "print(f\"GrÃ¶ÃŸe - Min: {df_clean['size_clean'].min():.1f}mÂ², Max: {df_clean['size_clean'].max():.1f}mÂ², Median: {df_clean['size_clean'].median():.1f}mÂ²\")\n",
    "\n",
    "print(f\"ðŸ“Š BEREINIGUNGSLOGIK KONSISTENT MIT:\")\n",
    "print(f\"   â€¢ 01_Clean_Dataset_2018_2019.ipynb\")\n",
    "print(f\"   â€¢ 02_Clean_Dataset_2022.ipynb\")\n",
    "print(f\"   â€¢ 03_Clean_Dataset_2025.ipynb (dieses Notebook)\")\n",
    "print(f\"   â€¢ 04_Combine_Datasets.ipynb (finale Validierung)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55e08766",
   "metadata": {},
   "source": [
    "## 6. Normalisierung in Standardformat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1ff76d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "NORMALISIERUNG IN STANDARDFORMAT\n",
      "============================================================\n",
      "Normalisiertes Dataset erstellt: 4,763 Zeilen\n",
      "Standardspalten: ['price', 'size', 'district', 'rooms', 'year', 'dataset_id', 'source']\n",
      "ZusÃ¤tzliche Spalten: 5\n",
      "\n",
      "=== DATENQUALITÃ„T NORMALISIERTES DATASET ===\n",
      "Zeilen mit Preis: 4,763\n",
      "Zeilen mit GrÃ¶ÃŸe: 4,763\n",
      "Zeilen mit Bezirk: 4,763\n",
      "Zeilen mit Zimmeranzahl: 0\n",
      "\n",
      "=== STATISTIKEN ===\n",
      "Preis - Min: 150.00â‚¬, Max: 9990.00â‚¬, Median: 1000.00â‚¬\n",
      "GrÃ¶ÃŸe - Min: 11.0mÂ², Max: 361.0mÂ², Median: 65.0mÂ²\n",
      "\n",
      "=== BEZIRKSVERTEILUNG ===\n",
      "Anzahl Bezirke: 21\n",
      "  Mitte: 1023 EintrÃ¤ge\n",
      "  Pankow: 781 EintrÃ¤ge\n",
      "  Friedrichshain-Kreuzberg: 773 EintrÃ¤ge\n",
      "  Charlottenburg-Wilmersdorf: 600 EintrÃ¤ge\n",
      "  NeukÃ¶lln: 396 EintrÃ¤ge\n",
      "  Tempelhof-SchÃ¶neberg: 355 EintrÃ¤ge\n",
      "  Treptow-KÃ¶penick: 276 EintrÃ¤ge\n",
      "  Steglitz-Zehlendorf: 169 EintrÃ¤ge\n",
      "  Lichtenberg: 148 EintrÃ¤ge\n",
      "  Reinickendorf: 129 EintrÃ¤ge\n",
      "\n",
      "âœ… Normalisierung abgeschlossen!\n"
     ]
    }
   ],
   "source": [
    "print(\"=\"*60)\n",
    "print(\"NORMALISIERUNG IN STANDARDFORMAT\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Erstelle normalisiertes Dataset\n",
    "df_normalized = pd.DataFrame()\n",
    "\n",
    "# Standardspalten (kompatibel mit anderen Datasets)\n",
    "df_normalized['price'] = df_clean['price_clean']\n",
    "df_normalized['size'] = df_clean['size_clean']\n",
    "df_normalized['district'] = df_clean['district']\n",
    "df_normalized['rooms'] = np.nan  # Nicht verfÃ¼gbar im 2025 Dataset\n",
    "df_normalized['year'] = 2025\n",
    "df_normalized['dataset_id'] = 'recent'\n",
    "df_normalized['source'] = 'ImmobilienScout24'\n",
    "\n",
    "# ZusÃ¤tzliche Spalten aus dem 2025 Dataset\n",
    "df_normalized['title'] = df_clean['title']\n",
    "df_normalized['address'] = df_clean['address']\n",
    "df_normalized['link'] = df_clean['link']\n",
    "df_normalized['price_original'] = df_clean['price']\n",
    "df_normalized['size_original'] = df_clean['size']\n",
    "\n",
    "print(f\"Normalisiertes Dataset erstellt: {len(df_normalized):,} Zeilen\")\n",
    "print(f\"Standardspalten: {['price', 'size', 'district', 'rooms', 'year', 'dataset_id', 'source']}\")\n",
    "print(f\"ZusÃ¤tzliche Spalten: {len(df_normalized.columns) - 7}\")\n",
    "\n",
    "# DatenqualitÃ¤t prÃ¼fen\n",
    "print(f\"=== DATENQUALITÃ„T NORMALISIERTES DATASET ===\")\n",
    "print(f\"Zeilen mit Preis: {df_normalized['price'].notna().sum():,}\")\n",
    "print(f\"Zeilen mit GrÃ¶ÃŸe: {df_normalized['size'].notna().sum():,}\")\n",
    "print(f\"Zeilen mit Bezirk: {df_normalized['district'].notna().sum():,}\")\n",
    "print(f\"Zeilen mit Zimmeranzahl: {df_normalized['rooms'].notna().sum():,}\")\n",
    "\n",
    "# Statistiken\n",
    "print(f\"=== STATISTIKEN ===\")\n",
    "print(f\"Preis - Min: {df_normalized['price'].min():.2f}â‚¬, Max: {df_normalized['price'].max():.2f}â‚¬, Median: {df_normalized['price'].median():.2f}â‚¬\")\n",
    "print(f\"GrÃ¶ÃŸe - Min: {df_normalized['size'].min():.1f}mÂ², Max: {df_normalized['size'].max():.1f}mÂ², Median: {df_normalized['size'].median():.1f}mÂ²\")\n",
    "\n",
    "# Bezirksverteilung\n",
    "print(f\"=== BEZIRKSVERTEILUNG ===\")\n",
    "district_counts = df_normalized['district'].value_counts()\n",
    "print(f\"Anzahl Bezirke: {len(district_counts)}\")\n",
    "for district, count in district_counts.head(10).items():\n",
    "    print(f\"  {district}: {count} EintrÃ¤ge\")\n",
    "\n",
    "print(f\"âœ… Normalisierung abgeschlossen!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "055d649d",
   "metadata": {},
   "source": [
    "## 7. Export des normalisierten Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0cc7cac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "EXPORT NORMALISIERTES DATASET\n",
      "============================================================\n",
      "âœ… Normalisiertes Dataset exportiert: data/processed/dataset_2025_normalized.csv\n",
      "DateigrÃ¶ÃŸe: 4,763 Zeilen x 12 Spalten\n",
      "âœ… Export-Validierung erfolgreich: 4,763 Zeilen geladen\n",
      "\n",
      "=== ZUSAMMENFASSUNG DATASET 2025 ===\n",
      "Input: data/raw/Dataset_2025.csv (6,109 Zeilen)\n",
      "Output: data/processed/dataset_2025_normalized.csv (4,763 Zeilen)\n",
      "Datenverlust: 1,346 Zeilen (22.0%)\n",
      "Bezirk-Extraktion: 4,763/6,109 (78.0%) erfolgreich\n",
      "Standardisierte Spalten: price, size, district, rooms, year, dataset_id, source\n",
      "ZusÃ¤tzliche Spalten: 5\n",
      "\n",
      "ðŸŽ¯ DATASET 2025 BEREINIGUNG ABGESCHLOSSEN!\n",
      "Bereit fÃ¼r Kombination mit anderen normalisierten Datasets.\n"
     ]
    }
   ],
   "source": [
    "print(\"=\"*60)\n",
    "print(\"EXPORT NORMALISIERTES DATASET\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Export des normalisierten Datasets\n",
    "output_path = 'data/processed/dataset_2025_normalized.csv'\n",
    "df_normalized.to_csv(output_path, index=False)\n",
    "\n",
    "print(f\"âœ… Normalisiertes Dataset exportiert: {output_path}\")\n",
    "print(f\"DateigrÃ¶ÃŸe: {len(df_normalized):,} Zeilen x {len(df_normalized.columns)} Spalten\")\n",
    "\n",
    "# Validierung durch Wiedereinlesen\n",
    "df_validation = pd.read_csv(output_path)\n",
    "print(f\"âœ… Export-Validierung erfolgreich: {len(df_validation):,} Zeilen geladen\")\n",
    "\n",
    "# Zusammenfassung\n",
    "print(f\"=== ZUSAMMENFASSUNG DATASET 2025 ===\")\n",
    "print(f\"Input: data/raw/Dataset_2025.csv ({len(df):,} Zeilen)\")\n",
    "print(f\"Output: {output_path} ({len(df_normalized):,} Zeilen)\")\n",
    "print(f\"Datenverlust: {len(df) - len(df_normalized):,} Zeilen ({100*(len(df) - len(df_normalized))/len(df):.1f}%)\")\n",
    "print(f\"Bezirk-Extraktion: {len(df_normalized):,}/{len(df):,} ({100*len(df_normalized)/len(df):.1f}%) erfolgreich\")\n",
    "\n",
    "# Standardisierung und KompatibilitÃ¤t\n",
    "print(f\"=== STANDARDISIERUNG UND KOMPATIBILITÃ„T ===\")\n",
    "print(f\"âœ… Standardisierte Spalten: price, size, district, rooms, year, dataset_id, source\")\n",
    "print(f\"âœ… ZusÃ¤tzliche Spalten: {len(df_normalized.columns) - 7} (dataset-spezifisch)\")\n",
    "print(f\"âœ… Einheitliche Filter-Kriterien: Preis 100â‚¬-10.000â‚¬, GrÃ¶ÃŸe 10mÂ²-500mÂ²\")\n",
    "print(f\"âœ… Multi-Listing-Behandlung: Mindestpreise fÃ¼r Vergleichbarkeit\")\n",
    "\n",
    "# Harmonisierung mit anderen Datasets\n",
    "print(f\"=== HARMONISIERUNG MIT ANDEREN DATASETS ===\")\n",
    "print(f\"ðŸ”„ Dataset 2018-2019: Identische Filter-Kriterien\")\n",
    "print(f\"ðŸ”„ Dataset 2022: Filter-Kriterien harmonisiert\")\n",
    "print(f\"ðŸ”„ Dataset 2025: Implementiert (dieses Notebook)\")\n",
    "print(f\"ðŸ”„ Combine-Step: Bereit fÃ¼r nahtlose Integration\")\n",
    "\n",
    "print(f\"ðŸŽ¯ DATASET 2025 BEREINIGUNG ABGESCHLOSSEN!\")\n",
    "print(f\"ðŸ“Š Bereit fÃ¼r Kombination mit anderen normalisierten Datasets\")\n",
    "print(f\"ðŸš€ Konsistente DatenqualitÃ¤t und Vergleichbarkeit gewÃ¤hrleistet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1b2c3d6",
   "metadata": {},
   "source": [
    "## 8. Lade angereicherte Wohnlagendaten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5f6g7h0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*60)\n",
    "print(\"ANGEREICHERTE WOHNLAGENDATEN LADEN\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "enriched_data_path = 'data/raw/wohnlagen_enriched.csv'\n",
    "try:\n",
    "    enriched_df = pd.read_csv(enriched_data_path)\n",
    "    print(f\"âœ… Angereicherte Daten geladen: {len(enriched_df):,} Zeilen, {len(enriched_df.columns)} Spalten\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"âŒ Datei nicht gefunden: {enriched_data_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "i9j0k1l4",
   "metadata": {},
   "source": [
    "## 9. Kombiniere Datasets mit Wohnlagendaten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "m3n4o5p8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*60)\n",
    "print(\"KOMBINIERE MIT WOHNLAGENDATEN\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Extract PLZ from address for merging\n",
    "df_normalized['plz'] = df_normalized['address'].str.extract(r'(\\d{5})')\n",
    "\n",
    "# Merge the two dataframes\n",
    "enriched_df_subset = enriched_df[['plz', 'wol', 'ortsteil_neu']]\n",
    "df_enriched = pd.merge(df_normalized, enriched_df_subset, how='left', on=['plz'])\n",
    "\n",
    "print(f\"âœ… Kombiniertes und angereichertes Dataset erstellt: {len(df_enriched):,} Zeilen\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "q7r8s9t2",
   "metadata": {},
   "source": [
    "## 10. Export des finalen angereicherten Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "u1v2w3x6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*60)\n",
    "print(\"EXPORT FINALES ANGEREICHERTES DATASET\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Export\n",
    "output_file_enriched = 'data/processed/dataset_2025_enriched.csv'\n",
    "df_enriched.to_csv(output_file_enriched, index=False)\n",
    "\n",
    "print(f\"âœ… Finales angereichertes Dataset exportiert: {output_file_enriched}\")\n",
    "print(f\"DateigrÃ¶ÃŸe: {len(df_enriched):,} Zeilen x {len(df_enriched.columns)} Spalten\")\n",
    "\n",
    "# Validierung durch Wiedereinlesen\n",
    "test_df_enriched = pd.read_csv(output_file_enriched)\n",
    "print(f\"âœ… Export-Validierung erfolgreich: {len(test_df_enriched):,} Zeilen geladen\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
