{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2eacc2b7",
   "metadata": {},
   "source": [
    "# 04_Combine_Datasets - Finale Dataset-Kombination\n",
    "\n",
    "**Kombination aller normalisierten und angereicherten Datasets**\n",
    "- Lädt die drei normalisierten und angereicherten Datasets (2018-2019, 2022, 2025)\n",
    "- Prüft Schema-Kompatibilität\n",
    "- Führt Qualitätsprüfungen durch\n",
    "- Erstellt finales kombiniertes und angereichertes Dataset\n",
    "\n",
    "**Input:**\n",
    "- `data/processed/dataset_2018_2019_enriched.csv`\n",
    "- `data/processed/dataset_2022_enriched.csv` \n",
    "- `data/processed/dataset_2025_enriched.csv`\n",
    "\n",
    "**Output:**\n",
    "- `data/processed/berlin_housing_combined_enriched_final.csv`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "478a928a",
   "metadata": {},
   "source": [
    "## 1. Setup und Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "90c54540",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bibliotheken erfolgreich importiert!\n",
      "Pandas Version: 2.2.3\n",
      "Ziel: Kombination aller normalisierten Datasets\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"Bibliotheken erfolgreich importiert!\")\n",
    "print(f\"Pandas Version: {pd.__version__}\")\n",
    "print(\"Ziel: Kombination aller normalisierten Datasets\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc575363",
   "metadata": {},
   "source": [
    "## 2. Angereicherte Datasets laden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f81cd754",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "ANGEREICHERTE DATASETS LADEN\n",
      "============================================================\n",
      "✅ 2018_2019: 10,387 Zeilen, 15 Spalten\n",
      "✅ 2022: 2,676 Zeilen, 25 Spalten\n",
      "✅ 2025: 4,424 Zeilen, 15 Spalten\n",
      "\n",
      "Geladen: 3 von 3 Datasets\n"
     ]
    }
   ],
   "source": [
    "print(\"=\"*60)\n",
    "print(\"ANGEREICHERTE DATASETS LADEN\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Lade alle drei angereicherten Datasets\n",
    "datasets = {}\n",
    "file_paths = {\n",
    "    '2018_2019': 'data/processed/dataset_2018_2019_enriched.csv',\n",
    "    '2022': 'data/processed/dataset_2022_enriched.csv', \n",
    "    '2025': 'data/processed/dataset_2025_enriched.csv'\n",
    "}\n",
    "\n",
    "for dataset_name, file_path in file_paths.items():\n",
    "    try:\n",
    "        df = pd.read_csv(file_path)\n",
    "        datasets[dataset_name] = df\n",
    "        print(f\"✅ {dataset_name}: {len(df):,} Zeilen, {len(df.columns)} Spalten\")\n",
    "    except FileNotFoundError:\n",
    "        print(f\"❌ {dataset_name}: Datei nicht gefunden: {file_path}\")\n",
    "        \n",
    "print(f\"\\nGeladen: {len(datasets)} von {len(file_paths)} Datasets\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d4e8d61",
   "metadata": {},
   "source": [
    "## 3. Schema-Kompatibilität prüfen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f2fb70ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "SCHEMA-KOMPATIBILITÄT PRÜFEN\n",
      "============================================================\n",
      "Erwartete Standardspalten:\n",
      "  - price\n",
      "  - size\n",
      "  - district\n",
      "  - rooms\n",
      "  - year\n",
      "  - dataset_id\n",
      "  - source\n",
      "  - wol\n",
      "  - ortsteil_neu\n",
      "\n",
      "=== DATASET 2018_2019 ===\n",
      "Spalten: ['price', 'size', 'district', 'rooms', 'year', 'dataset_id', 'source', 'street', 'floor', 'typeOfFlat', 'yearConstructed', 'totalRent', 'strasse', 'wol', 'ortsteil_neu']\n",
      "✅ Alle Standardspalten vorhanden\n",
      "ℹ️  Zusätzliche Spalten: 6 (['street', 'floor', 'typeOfFlat']...)\n",
      "\n",
      "=== DATASET 2022 ===\n",
      "Spalten: ['price', 'size', 'district', 'rooms', 'year', 'dataset_id', 'source', 'plz', 'warmmiete', 'nebenkosten', 'kaution', 'baujahr', 'zustand', 'energieeffiziensklasse', 'ausstattung_möbliert', 'ausstattung_balkon', 'ausstattung_terrasse', 'ausstattung_garten', 'ausstattung_einbauküche', 'ausstattung_garage', 'ausstattung_stellplatz', 'ausstattung_personenaufzug', 'ausstattung_keller', 'wol', 'ortsteil_neu']\n",
      "✅ Alle Standardspalten vorhanden\n",
      "ℹ️  Zusätzliche Spalten: 16 (['plz', 'warmmiete', 'nebenkosten']...)\n",
      "\n",
      "=== DATASET 2025 ===\n",
      "Spalten: ['wol', 'source', 'ortsteil_neu', 'size_original', 'rooms', 'address', 'size', 'link', 'plz', 'price', 'dataset_id', 'price_original', 'year', 'title', 'district']\n",
      "✅ Alle Standardspalten vorhanden\n",
      "ℹ️  Zusätzliche Spalten: 6 (['size_original', 'address', 'link']...)\n",
      "\n",
      "=== SCHEMA-KOMPATIBILITÄT ===\n",
      "Valide Datasets: 3/3\n",
      "✅ Alle Datasets sind schema-kompatibel!\n"
     ]
    }
   ],
   "source": [
    "print(\"=\"*60)\n",
    "print(\"SCHEMA-KOMPATIBILITÄT PRÜFEN\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Definiere erwartete Standardspalten\n",
    "required_columns = ['price', 'size', 'district', 'rooms', 'year', 'dataset_id', 'source', 'wol', 'ortsteil_neu']\n",
    "\n",
    "print(\"Erwartete Standardspalten:\")\n",
    "for col in required_columns:\n",
    "    print(f\"  - {col}\")\n",
    "\n",
    "# Prüfe jedes Dataset\n",
    "schema_check = {}\n",
    "for dataset_name, df in datasets.items():\n",
    "    missing_cols = [col for col in required_columns if col not in df.columns]\n",
    "    extra_cols = [col for col in df.columns if col not in required_columns]\n",
    "    \n",
    "    schema_check[dataset_name] = {\n",
    "        'missing': missing_cols,\n",
    "        'extra': extra_cols,\n",
    "        'valid': len(missing_cols) == 0\n",
    "    }\n",
    "    \n",
    "    print(f\"\\n=== DATASET {dataset_name.upper()} ===\")\n",
    "    print(f\"Spalten: {list(df.columns)}\")\n",
    "    if missing_cols:\n",
    "        print(f\"❌ Fehlende Standardspalten: {missing_cols}\")\n",
    "    else:\n",
    "        print(f\"✅ Alle Standardspalten vorhanden\")\n",
    "    \n",
    "    if extra_cols:\n",
    "        print(f\"ℹ️  Zusätzliche Spalten: {len(extra_cols)} ({extra_cols[:3]}...)\")\n",
    "    \n",
    "# Zusammenfassung\n",
    "valid_datasets = [name for name, check in schema_check.items() if check['valid']]\n",
    "print(f\"\\n=== SCHEMA-KOMPATIBILITÄT ===\")\n",
    "print(f\"Valide Datasets: {len(valid_datasets)}/{len(datasets)}\")\n",
    "if len(valid_datasets) == len(datasets):\n",
    "    print(\"✅ Alle Datasets sind schema-kompatibel!\")\n",
    "else:\n",
    "    print(\"❌ Schema-Inkompatibilitäten gefunden!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e6b09c5",
   "metadata": {},
   "source": [
    "## 4. Datenqualität prüfen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "70223a5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "DATENQUALITÄT PRÜFEN\n",
      "============================================================\n",
      "\n",
      "=== DATASET 2018_2019 ===\n",
      "  price: 10,387/10,387 (100.0%) nicht-null\n",
      "  size: 10,387/10,387 (100.0%) nicht-null\n",
      "  district: 10,387/10,387 (100.0%) nicht-null\n",
      "  rooms: 10,387/10,387 (100.0%) nicht-null\n",
      "  year: 10,387/10,387 (100.0%) nicht-null\n",
      "  dataset_id: 10,387/10,387 (100.0%) nicht-null\n",
      "  source: 10,387/10,387 (100.0%) nicht-null\n",
      "  wol: 1,760/10,387 (16.9%) nicht-null\n",
      "  ortsteil_neu: 1,760/10,387 (16.9%) nicht-null\n",
      "  Preis (50-20000€): 10,387/10,387 (100.0%) gültig\n",
      "  Größe (5-1000m²): 10,387/10,387 (100.0%) gültig\n",
      "  Einzigartige Bezirke: 79\n",
      "\n",
      "=== DATASET 2022 ===\n",
      "  price: 2,676/2,676 (100.0%) nicht-null\n",
      "  size: 2,676/2,676 (100.0%) nicht-null\n",
      "  district: 2,676/2,676 (100.0%) nicht-null\n",
      "  rooms: 2,676/2,676 (100.0%) nicht-null\n",
      "  year: 2,676/2,676 (100.0%) nicht-null\n",
      "  dataset_id: 2,676/2,676 (100.0%) nicht-null\n",
      "  source: 2,676/2,676 (100.0%) nicht-null\n",
      "  wol: 2,676/2,676 (100.0%) nicht-null\n",
      "  ortsteil_neu: 2,676/2,676 (100.0%) nicht-null\n",
      "  Preis (50-20000€): 2,676/2,676 (100.0%) gültig\n",
      "  Größe (5-1000m²): 2,676/2,676 (100.0%) gültig\n",
      "  Einzigartige Bezirke: 21\n",
      "\n",
      "=== DATASET 2025 ===\n",
      "  price: 4,424/4,424 (100.0%) nicht-null\n",
      "  size: 4,424/4,424 (100.0%) nicht-null\n",
      "  district: 4,424/4,424 (100.0%) nicht-null\n",
      "  rooms: 0/4,424 (0.0%) nicht-null\n",
      "  year: 4,424/4,424 (100.0%) nicht-null\n",
      "  dataset_id: 4,424/4,424 (100.0%) nicht-null\n",
      "  source: 4,424/4,424 (100.0%) nicht-null\n",
      "  wol: 54/4,424 (1.2%) nicht-null\n",
      "  ortsteil_neu: 4,422/4,424 (100.0%) nicht-null\n",
      "  Preis (50-20000€): 4,424/4,424 (100.0%) gültig\n",
      "  Größe (5-1000m²): 4,424/4,424 (100.0%) gültig\n",
      "  Einzigartige Bezirke: 20\n",
      "\n",
      "✅ Datenqualitätsprüfung abgeschlossen\n"
     ]
    }
   ],
   "source": [
    "print(\"=\"*60)\n",
    "print(\"DATENQUALITÄT PRÜFEN\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "quality_report = {}\n",
    "\n",
    "for dataset_name, df in datasets.items():\n",
    "    print(f\"\\n=== DATASET {dataset_name.upper()} ===\")\n",
    "    \n",
    "    # Grundlegende Statistiken\n",
    "    total_rows = len(df)\n",
    "    \n",
    "    # Vollständigkeit prüfen\n",
    "    completeness = {}\n",
    "    for col in required_columns:\n",
    "        if col in df.columns:\n",
    "            non_null = df[col].notna().sum()\n",
    "            completeness[col] = (non_null, non_null/total_rows*100)\n",
    "            print(f\"  {col}: {non_null:,}/{total_rows:,} ({non_null/total_rows*100:.1f}%) nicht-null\")\n",
    "    \n",
    "    # Wertebereichs-Prüfungen\n",
    "    if 'price' in df.columns:\n",
    "        price_valid = ((df['price'] >= 50) & (df['price'] <= 20000)).sum()\n",
    "        print(f\"  Preis (50-20000€): {price_valid:,}/{total_rows:,} ({price_valid/total_rows*100:.1f}%) gültig\")\n",
    "    \n",
    "    if 'size' in df.columns:\n",
    "        size_valid = ((df['size'] >= 5) & (df['size'] <= 1000)).sum()\n",
    "        print(f\"  Größe (5-1000m²): {size_valid:,}/{total_rows:,} ({size_valid/total_rows*100:.1f}%) gültig\")\n",
    "    \n",
    "    if 'district' in df.columns:\n",
    "        unique_districts = df['district'].nunique()\n",
    "        print(f\"  Einzigartige Bezirke: {unique_districts}\")\n",
    "    \n",
    "    quality_report[dataset_name] = {\n",
    "        'total_rows': total_rows,\n",
    "        'completeness': completeness,\n",
    "        'unique_districts': df['district'].nunique() if 'district' in df.columns else 0\n",
    "    }\n",
    "\n",
    "print(f\"\\n✅ Datenqualitätsprüfung abgeschlossen\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de277ee0",
   "metadata": {},
   "source": [
    "## 5. Datasets kombinieren"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "74881885",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "DATASETS KOMBINIEREN\n",
      "============================================================\n",
      "2018_2019: 10,387 Zeilen mit 9 Standardspalten\n",
      "2022: 2,676 Zeilen mit 9 Standardspalten\n",
      "2025: 4,424 Zeilen mit 9 Standardspalten\n",
      "\n",
      "Kombiniere Datasets...\n",
      "✅ Kombiniertes Dataset erstellt: 17,487 Zeilen\n",
      "\n",
      "=== KOMBINATIONS-ZUSAMMENFASSUNG ===\n",
      "Input-Zeilen gesamt: 17,487\n",
      "Output-Zeilen: 17,487\n",
      "Datenverlust: 0 (0.0%)\n",
      "\n",
      "=== JAHRESVERTEILUNG ===\n",
      "  2019: 10,387 Einträge (59.4%)\n",
      "  2022: 2,676 Einträge (15.3%)\n",
      "  2025: 4,424 Einträge (25.3%)\n",
      "\n",
      "=== DATASET-VERTEILUNG ===\n",
      "  historical: 10,387 Einträge (59.4%)\n",
      "  recent: 4,424 Einträge (25.3%)\n",
      "  current: 2,676 Einträge (15.3%)\n"
     ]
    }
   ],
   "source": [
    "print(\"=\"*60)\n",
    "print(\"DATASETS KOMBINIEREN\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Nur Standardspalten für Kombination verwenden\n",
    "datasets_standard = {}\n",
    "for dataset_name, df in datasets.items():\n",
    "    # Wähle nur Standardspalten aus\n",
    "    available_std_cols = [col for col in required_columns if col in df.columns]\n",
    "    df_std = df[available_std_cols].copy()\n",
    "    datasets_standard[dataset_name] = df_std\n",
    "    print(f\"{dataset_name}: {len(df_std):,} Zeilen mit {len(available_std_cols)} Standardspalten\")\n",
    "\n",
    "# Kombiniere alle Datasets\n",
    "print(f\"\\nKombiniere Datasets...\")\n",
    "combined_df = pd.concat(datasets_standard.values(), ignore_index=True, sort=False)\n",
    "\n",
    "print(f\"✅ Kombiniertes Dataset erstellt: {len(combined_df):,} Zeilen\")\n",
    "\n",
    "# Zusammenfassung\n",
    "print(f\"\\n=== KOMBINATIONS-ZUSAMMENFASSUNG ===\")\n",
    "total_input_rows = sum(len(df) for df in datasets.values())\n",
    "print(f\"Input-Zeilen gesamt: {total_input_rows:,}\")\n",
    "print(f\"Output-Zeilen: {len(combined_df):,}\")\n",
    "print(f\"Datenverlust: {total_input_rows - len(combined_df):,} ({(total_input_rows - len(combined_df))/total_input_rows*100:.1f}%)\")\n",
    "\n",
    "# Verteilung nach Jahren\n",
    "print(f\"\\n=== JAHRESVERTEILUNG ===\")\n",
    "year_counts = combined_df['year'].value_counts().sort_index()\n",
    "for year, count in year_counts.items():\n",
    "    print(f\"  {year}: {count:,} Einträge ({count/len(combined_df)*100:.1f}%)\")\n",
    "\n",
    "# Verteilung nach Dataset-ID\n",
    "print(f\"\\n=== DATASET-VERTEILUNG ===\")\n",
    "dataset_counts = combined_df['dataset_id'].value_counts()\n",
    "for dataset_id, count in dataset_counts.items():\n",
    "    print(f\"  {dataset_id}: {count:,} Einträge ({count/len(combined_df)*100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b81123c9",
   "metadata": {},
   "source": [
    "## 6. Finale Datenvalidierung"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c95a414f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "FINALE DATENVALIDIERUNG\n",
      "============================================================\n",
      "Duplikate: 1,233 (7.05%)\n",
      "\n",
      "=== FEHLENDE WERTE ===\n",
      "  rooms: 4,424 (25.3%)\n",
      "  wol: 12,997 (74.3%)\n",
      "  ortsteil_neu: 8,629 (49.3%)\n",
      "\n",
      "=== STATISTIKEN KOMBINIERTES DATASET ===\n",
      "Preis - Min: 150€, Max: 9990€, Median: 931€\n",
      "Größe - Min: 10m², Max: 482m², Median: 69m²\n",
      "Zimmer - Min: 1.0, Max: 10.0, Median: 2.0\n",
      "\n",
      "=== FINALE BEZIRKSVERTEILUNG ===\n",
      "Anzahl Bezirke: 87\n",
      "  Mitte: 1,923 Einträge (11.0%)\n",
      "  Pankow: 1,189 Einträge (6.8%)\n",
      "  Neukölln: 904 Einträge (5.2%)\n",
      "  Spandau: 837 Einträge (4.8%)\n",
      "  Tiergarten: 832 Einträge (4.8%)\n",
      "  Charlottenburg: 792 Einträge (4.5%)\n",
      "  Friedrichshain-Kreuzberg: 775 Einträge (4.4%)\n",
      "  Friedrichshain: 666 Einträge (3.8%)\n",
      "  Charlottenburg-Wilmersdorf: 636 Einträge (3.6%)\n",
      "  Reinickendorf: 614 Einträge (3.5%)\n",
      "\n",
      "✅ Finale Datenvalidierung abgeschlossen\n"
     ]
    }
   ],
   "source": [
    "print(\"=\"*60)\n",
    "print(\"FINALE DATENVALIDIERUNG\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Duplikate prüfen\n",
    "duplicates = combined_df.duplicated().sum()\n",
    "print(f\"Duplikate: {duplicates:,} ({duplicates/len(combined_df)*100:.2f}%)\")\n",
    "\n",
    "# Fehlende Werte\n",
    "print(f\"\\n=== FEHLENDE WERTE ===\")\n",
    "missing_summary = combined_df.isnull().sum()\n",
    "for col, missing_count in missing_summary.items():\n",
    "    if missing_count > 0:\n",
    "        print(f\"  {col}: {missing_count:,} ({missing_count/len(combined_df)*100:.1f}%)\")\n",
    "\n",
    "# Statistiken der Kernfelder\n",
    "print(f\"\\n=== STATISTIKEN KOMBINIERTES DATASET ===\")\n",
    "if 'price' in combined_df.columns:\n",
    "    price_stats = combined_df['price'].describe()\n",
    "    print(f\"Preis - Min: {price_stats['min']:.0f}€, Max: {price_stats['max']:.0f}€, Median: {price_stats['50%']:.0f}€\")\n",
    "\n",
    "if 'size' in combined_df.columns:\n",
    "    size_stats = combined_df['size'].describe()\n",
    "    print(f\"Größe - Min: {size_stats['min']:.0f}m², Max: {size_stats['max']:.0f}m², Median: {size_stats['50%']:.0f}m²\")\n",
    "\n",
    "if 'rooms' in combined_df.columns:\n",
    "    rooms_stats = combined_df['rooms'].describe()\n",
    "    print(f\"Zimmer - Min: {rooms_stats['min']:.1f}, Max: {rooms_stats['max']:.1f}, Median: {rooms_stats['50%']:.1f}\")\n",
    "\n",
    "# Bezirksverteilung\n",
    "if 'district' in combined_df.columns:\n",
    "    print(f\"\\n=== FINALE BEZIRKSVERTEILUNG ===\")\n",
    "    district_counts = combined_df['district'].value_counts()\n",
    "    print(f\"Anzahl Bezirke: {len(district_counts)}\")\n",
    "    for district, count in district_counts.head(10).items():\n",
    "        print(f\"  {district}: {count:,} Einträge ({count/len(combined_df)*100:.1f}%)\")\n",
    "\n",
    "print(f\"\\n✅ Finale Datenvalidierung abgeschlossen\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b4279a7",
   "metadata": {},
   "source": [
    "## 7. Export des finalen Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "13c3b62b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "EXPORT FINALES KOMBINIERTES DATASET\n",
      "============================================================\n",
      "✅ Finales Dataset exportiert: data/processed/berlin_housing_combined_enriched_final.csv\n",
      "Dateigröße: 17,487 Zeilen x 9 Spalten\n",
      "✅ Export-Validierung erfolgreich: 17,487 Zeilen geladen\n",
      "\n",
      "=== FINALE ZUSAMMENFASSUNG ===\n",
      "Input-Datasets: 3\n",
      "  - Dataset 2018-2019: 10,387 Zeilen\n",
      "  - Dataset 2022: 2,676 Zeilen\n",
      "  - Dataset 2025: 4,424 Zeilen\n",
      "Output: data/processed/berlin_housing_combined_enriched_final.csv (17,487 Zeilen)\n",
      "Zeitspanne: 2018-2025 (3 Jahre)\n",
      "Berliner Bezirke: 87 abgedeckt\n",
      "Standardisierte Spalten: ['price', 'size', 'district', 'rooms', 'year', 'dataset_id', 'source', 'wol', 'ortsteil_neu']\n",
      "\n",
      "🎯 DATASET-KOMBINATION ERFOLGREICH ABGESCHLOSSEN!\n",
      "Das finale Dataset ist bereit für die Mietpreis-Analyse.\n"
     ]
    }
   ],
   "source": [
    "print(\"=\"*60)\n",
    "print(\"EXPORT FINALES KOMBINIERTES DATASET\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Export\n",
    "output_file = 'data/processed/berlin_housing_combined_enriched_final.csv'\n",
    "combined_df.to_csv(output_file, index=False)\n",
    "\n",
    "print(f\"✅ Finales Dataset exportiert: {output_file}\")\n",
    "print(f\"Dateigröße: {len(combined_df):,} Zeilen x {len(combined_df.columns)} Spalten\")\n",
    "\n",
    "# Validierung durch Wiedereinlesen\n",
    "test_df = pd.read_csv(output_file)\n",
    "print(f\"✅ Export-Validierung erfolgreich: {len(test_df):,} Zeilen geladen\")\n",
    "\n",
    "# Finale Zusammenfassung\n",
    "print(f\"\\n=== FINALE ZUSAMMENFASSUNG ===\")\n",
    "print(f\"Input-Datasets: {len(datasets)}\")\n",
    "print(f\"  - Dataset 2018-2019: {quality_report.get('2018_2019', {}).get('total_rows', 0):,} Zeilen\")\n",
    "print(f\"  - Dataset 2022: {quality_report.get('2022', {}).get('total_rows', 0):,} Zeilen\") \n",
    "print(f\"  - Dataset 2025: {quality_report.get('2025', {}).get('total_rows', 0):,} Zeilen\")\n",
    "print(f\"Output: {output_file} ({len(combined_df):,} Zeilen)\")\n",
    "print(f\"Zeitspanne: 2018-2025 ({len(combined_df['year'].unique())} Jahre)\")\n",
    "print(f\"Berliner Bezirke: {len(combined_df['district'].unique())} abgedeckt\")\n",
    "print(f\"Standardisierte Spalten: {list(combined_df.columns)}\")\n",
    "\n",
    "print(f\"\\n🎯 DATASET-KOMBINATION ERFOLGREICH ABGESCHLOSSEN!\")\n",
    "print(f\"Das finale Dataset ist bereit für die Mietpreis-Analyse.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
