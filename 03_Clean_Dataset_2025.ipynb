{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a28af644",
   "metadata": {},
   "source": [
    "# 03_Clean_Dataset_2025 - Intelligente Adressextraktion\n",
    "\n",
    "## üéØ **Spezifische Bereinigung f√ºr Dataset 2025**\n",
    "\n",
    "### **Hauptfunktionen:**\n",
    "- **Intelligente PLZ-Extraktion** aus verschiedenen Adressformaten\n",
    "- **Bezirk-Normalisierung** mit Alias-Mapping\n",
    "- **Multi-Listing-Behandlung** (Preis- und Gr√∂√üenspannen)\n",
    "- **Filter-Harmonisierung** mit anderen Datasets\n",
    "- **Standardisierte Ausgabe** kompatibel mit anderen Datasets\n",
    "\n",
    "### **üîÑ Filter-Harmonisierung (Konsistent mit allen Datasets):**\n",
    "- **Preis-Filter:** 100‚Ç¨ - 10.000‚Ç¨ (Kaltmiete)\n",
    "- **Gr√∂√üen-Filter:** 10m¬≤ - 500m¬≤ (Wohnfl√§che)\n",
    "- **Bezirk-Validierung:** Nur g√ºltige Berliner Bezirke\n",
    "\n",
    "### **üìã Adressformate im 2025 Dataset:**\n",
    "1. **Vollst√§ndige Adresse mit PLZ:** \"Johannisplatz 3, 10117 Berlin\"\n",
    "2. **Adresse mit Bezirk:** \"Johannisplatz 5, Mitte (Ortsteil), Berlin\" \n",
    "3. **Nur Bezirk:** \"Tiergarten, Berlin\"\n",
    "4. **Nur PLZ:** \"10557 Berlin\"\n",
    "5. **Adresse mit Ortsteil:** \"Friedrichshain, Berlin\"\n",
    "\n",
    "### **üéØ Ziel:** \n",
    "Einheitliche Bezirk-Zuordnung und maximale Vergleichbarkeit mit Dataset 2018-2019 und Dataset 2022\n",
    "\n",
    "---\n",
    "**Teil der modularen Preprocessing-Pipeline**  \n",
    "**Datum:** 4. Juli 2025  \n",
    "**Version:** 1.1 (Filter-Harmonisierung)  \n",
    "**Status:** ‚úÖ Harmonisiert mit allen anderen Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2b3a266",
   "metadata": {},
   "source": [
    "## 1. Setup und Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9a456e00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bibliotheken erfolgreich importiert!\n",
      "Pandas Version: 2.2.3\n",
      "Dataset: 2025 (ImmobilienScout24)\n",
      "Ziel: Intelligente Adressextraktion und Bezirk-Normalisierung\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from collections import Counter\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"Bibliotheken erfolgreich importiert!\")\n",
    "print(f\"Pandas Version: {pd.__version__}\")\n",
    "print(\"Dataset: 2025 (ImmobilienScout24)\")\n",
    "print(\"Ziel: Intelligente Adressextraktion und Bezirk-Normalisierung\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a068c88",
   "metadata": {},
   "source": [
    "## 2. PLZ-Mapping und Bezirk-Normalisierung laden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9037091a",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "unterminated string literal (detected at line 118) (4274493469.py, line 118)",
     "output_type": "error",
     "traceback": [
      "  \u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 118\u001b[39m\n\u001b[31m    \u001b[39m\u001b[31mprint(\"\u001b[39m\n          ^\n\u001b[31mSyntaxError\u001b[39m\u001b[31m:\u001b[39m unterminated string literal (detected at line 118)\n"
     ]
    }
   ],
   "source": [
    "print(\"=\"*60)\n",
    "print(\"PLZ-MAPPING UND BEZIRK-NORMALISIERUNG\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# PLZ-Mapping laden\n",
    "plz_mapping_df = pd.read_csv('data/processed/berlin_plz_mapping.csv')\n",
    "plz_to_district = dict(zip(plz_mapping_df['PLZ'], plz_mapping_df['Bezirk']))\n",
    "\n",
    "# Erweiterte PLZ-Mappings f√ºr alle Datasets\n",
    "extended_plz_mapping = {\n",
    "    12627: 'Marzahn-Hellersdorf',\n",
    "    12629: 'Marzahn-Hellersdorf', \n",
    "    12679: 'Marzahn-Hellersdorf',\n",
    "    12681: 'Marzahn-Hellersdorf',\n",
    "    12683: 'Marzahn-Hellersdorf',\n",
    "    12685: 'Marzahn-Hellersdorf',\n",
    "    12687: 'Marzahn-Hellersdorf',\n",
    "    12689: 'Marzahn-Hellersdorf',\n",
    "    13593: 'Spandau',\n",
    "    13595: 'Spandau',\n",
    "    13597: 'Spandau',\n",
    "    13599: 'Spandau',\n",
    "    14052: 'Charlottenburg-Wilmersdorf',\n",
    "    14055: 'Charlottenburg-Wilmersdorf',\n",
    "    14057: 'Charlottenburg-Wilmersdorf', \n",
    "    14059: 'Charlottenburg-Wilmersdorf',\n",
    "    10315: 'Lichtenberg',\n",
    "    10317: 'Lichtenberg',\n",
    "    10318: 'Lichtenberg',\n",
    "    10319: 'Lichtenberg',\n",
    "    10365: 'Lichtenberg',\n",
    "    10367: 'Lichtenberg',\n",
    "    10369: 'Lichtenberg',\n",
    "    13125: 'Pankow',\n",
    "    13127: 'Pankow',\n",
    "    13129: 'Pankow',\n",
    "    13156: 'Pankow',\n",
    "    13158: 'Pankow',\n",
    "    13159: 'Pankow',\n",
    "    13187: 'Pankow',\n",
    "    13189: 'Pankow',\n",
    "    12305: 'Tempelhof-Sch√∂neberg',\n",
    "    12307: 'Tempelhof-Sch√∂neberg',\n",
    "    12309: 'Tempelhof-Sch√∂neberg',\n",
    "    12347: 'Neuk√∂lln',\n",
    "    12349: 'Neuk√∂lln',\n",
    "    12351: 'Neuk√∂lln',\n",
    "    12353: 'Neuk√∂lln',\n",
    "    12355: 'Neuk√∂lln',\n",
    "    12357: 'Neuk√∂lln',\n",
    "    12359: 'Neuk√∂lln',\n",
    "    12524: 'Treptow-K√∂penick',\n",
    "    12555: 'Treptow-K√∂penick',\n",
    "    10247: 'Friedrichshain-Kreuzberg',\n",
    "    10249: 'Friedrichshain-Kreuzberg',\n",
    "    10367: 'Lichtenberg',\n",
    "    10369: 'Lichtenberg',\n",
    "    14612: 'Falkensee',  # Au√üerhalb Berlin\n",
    "    13507: 'Reinickendorf',\n",
    "    10585: 'Charlottenburg-Wilmersdorf',\n",
    "    10709: 'Charlottenburg-Wilmersdorf',\n",
    "    10559: 'Mitte',\n",
    "}\n",
    "\n",
    "# Erweitere PLZ-Mapping\n",
    "plz_to_district.update(extended_plz_mapping)\n",
    "\n",
    "# Bezirk-Normalisierung (verschiedene Schreibweisen auf einheitliche Namen mappen)\n",
    "district_aliases = {\n",
    "    'Mitte (Ortsteil)': 'Mitte',\n",
    "    'Pankow (Ortsteil)': 'Pankow',\n",
    "    'Spandau (Ortsteil)': 'Spandau',\n",
    "    'Neuk√∂lln (Ortsteil)': 'Neuk√∂lln',\n",
    "    'Friedrichshain': 'Friedrichshain-Kreuzberg',\n",
    "    'Kreuzberg': 'Friedrichshain-Kreuzberg',\n",
    "    'Charlottenburg': 'Charlottenburg-Wilmersdorf',\n",
    "    'Wilmersdorf': 'Charlottenburg-Wilmersdorf',\n",
    "    'Sch√∂neberg': 'Tempelhof-Sch√∂neberg',\n",
    "    'Tempelhof': 'Tempelhof-Sch√∂neberg',\n",
    "    'K√∂penick': 'Treptow-K√∂penick',\n",
    "    'Treptow': 'Treptow-K√∂penick',\n",
    "    'Alt-Treptow': 'Treptow-K√∂penick',\n",
    "    'Rummelsburg': 'Lichtenberg',\n",
    "    'Friedrichshagen': 'Treptow-K√∂penick',\n",
    "    'Pl√§nterwald': 'Treptow-K√∂penick',\n",
    "    'Prenzlauer Berg': 'Pankow',\n",
    "    'Wei√üensee': 'Pankow',\n",
    "    'Buch': 'Pankow',\n",
    "    'Niedersch√∂nhausen': 'Pankow',\n",
    "    'Gesundbrunnen': 'Mitte',\n",
    "    'Wedding': 'Mitte',\n",
    "    'Moabit': 'Mitte',\n",
    "    'Tiergarten': 'Mitte',\n",
    "    'Friedenau': 'Tempelhof-Sch√∂neberg',\n",
    "    'Steglitz': 'Steglitz-Zehlendorf',\n",
    "    'Zehlendorf': 'Steglitz-Zehlendorf',\n",
    "    'Schmargendorf': 'Charlottenburg-Wilmersdorf',\n",
    "    'Grunewald': 'Charlottenburg-Wilmersdorf',\n",
    "    'Halensee': 'Charlottenburg-Wilmersdorf',\n",
    "    'Tegel': 'Reinickendorf',\n",
    "    'Heiligensee': 'Reinickendorf',\n",
    "    'Staaken': 'Spandau',\n",
    "    'Siemensstadt': 'Spandau',\n",
    "    'Malchow': 'Pankow',\n",
    "    'Reinickendorf': 'Reinickendorf',\n",
    "    'Lichtenberg': 'Lichtenberg',\n",
    "    'Marzahn-Hellersdorf': 'Marzahn-Hellersdorf',\n",
    "    'Spandau': 'Spandau',\n",
    "    'Neuk√∂lln': 'Neuk√∂lln',\n",
    "    'Mitte': 'Mitte',\n",
    "    'Pankow': 'Pankow',\n",
    "}\n",
    "\n",
    "print(f\"‚úÖ PLZ-Mapping geladen: {len(plz_to_district)} Zuordnungen\")\n",
    "print(f\"‚úÖ Bezirk-Aliases definiert: {len(district_aliases)} Zuordnungen\")\n",
    "\n",
    "# Zeige Beispiele\n",
    "print(\"\n",
    "PLZ-Mapping Beispiele:\")\n",
    "for plz, district in list(plz_to_district.items())[:5]:\n",
    "    print(f\"  {plz} ‚Üí {district}\")\n",
    "    \n",
    "print(\"\n",
    "Bezirk-Normalisierung Beispiele:\")\n",
    "for alias, normalized in list(district_aliases.items())[:5]:\n",
    "    print(f\"  '{alias}' ‚Üí '{normalized}'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31e94ac7",
   "metadata": {},
   "source": [
    "## 3. Dataset 2025 laden und analysieren"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fed89cb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "DATASET 2025 LADEN UND ANALYSIEREN\n",
      "============================================================\n",
      "Dataset geladen: 6,109 Zeilen, 5 Spalten\n",
      "\n",
      "Spalten: ['title', 'price', 'size', 'address', 'link']\n",
      "\n",
      "Datentypen:\n",
      "title      object\n",
      "price      object\n",
      "size       object\n",
      "address    object\n",
      "link       object\n",
      "dtype: object\n",
      "\n",
      "Fehlende Werte:\n",
      "\n",
      "=== ADRESSFORMAT-ANALYSE ===\n",
      "Erste 10 Adressen:\n",
      "  1. Biedenkopfer Stra√üe 46-54, 13507 Berlin\n",
      "  2. Seegefelder Stra√üe 150, 14612 Falkensee\n",
      "  3. Johannisplatz 5, Mitte (Ortsteil), Berlin\n",
      "  4. Pufendorfstra√üe 3A-3E, Friedrichshain, Berlin\n",
      "  5. Warburgzeile 1, 10585 Berlin\n",
      "  6. Johannisplatz 3, 10117 Berlin\n",
      "  7. Kreutzigerstra√üe 14, Friedrichshain, Berlin\n",
      "  8. Elsa-Neumann-Stra√üe 1, 13629 Berlin\n",
      "  9. Tiergarten, Berlin\n",
      "  10. Chausseestra√üe 108, Mitte (Ortsteil), Berlin\n",
      "\n",
      "Einzigartige Adressformate (Sample):\n",
      "  ‚Ä¢ Biedenkopfer Stra√üe 46-54, 13507 Berlin\n",
      "  ‚Ä¢ Seegefelder Stra√üe 150, 14612 Falkensee\n",
      "  ‚Ä¢ Johannisplatz 5, Mitte (Ortsteil), Berlin\n",
      "  ‚Ä¢ Pufendorfstra√üe 3A-3E, Friedrichshain, Berlin\n",
      "  ‚Ä¢ Warburgzeile 1, 10585 Berlin\n"
     ]
    }
   ],
   "source": [
    "print(\"=\"*60)\n",
    "print(\"DATASET 2025 LADEN UND ANALYSIEREN\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Dataset laden\n",
    "df = pd.read_csv('data/raw/Dataset_2025.csv')\n",
    "print(f\"Dataset geladen: {len(df):,} Zeilen, {len(df.columns)} Spalten\")\n",
    "\n",
    "print(f\"Spalten: {list(df.columns)}\")\n",
    "\n",
    "print(f\"Datentypen:\")\n",
    "print(df.dtypes)\n",
    "\n",
    "print(f\"Fehlende Werte:\")\n",
    "missing_values = df.isnull().sum()\n",
    "missing_values = missing_values[missing_values > 0]\n",
    "for col, count in missing_values.items():\n",
    "    print(f\"  {col}: {count} ({100*count/len(df):.2f}%)\")\n",
    "\n",
    "# Erste Adressfelder analysieren\n",
    "print(f\"=== ADRESSFORMAT-ANALYSE ===\")\n",
    "print(\"Erste 10 Adressen:\")\n",
    "for i, addr in enumerate(df['address'].head(10)):\n",
    "    print(f\"  {i+1}. {addr}\")\n",
    "\n",
    "print(f\"Einzigartige Adressformate (Sample):\")\n",
    "unique_addresses = df['address'].dropna().unique()\n",
    "for addr in unique_addresses[:5]:\n",
    "    print(f\"  ‚Ä¢ {addr}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d5851ec",
   "metadata": {},
   "source": [
    "## 4. Intelligente Adressextraktion und Bezirk-Zuordnung"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11ffb666",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "INTELLIGENTE ADRESSEXTRAKTION\n",
      "============================================================\n",
      "Extrahiere Bezirke aus Adressen...\n",
      "‚úÖ Bezirk-Extraktion abgeschlossen:\n",
      "  Gesamt Adressen: 6,109\n",
      "  Erfolgreiche Extraktion: 4,779\n",
      "  Erfolgsrate: 78.2%\n",
      "\n",
      "=== ERFOLGREICHE EXTRAKTION (Beispiele) ===\n",
      "  'Biedenkopfer Stra√üe 46-54, 13507 Berlin' ‚Üí Reinickendorf\n",
      "  'Seegefelder Stra√üe 150, 14612 Falkensee' ‚Üí Falkensee\n",
      "  'Johannisplatz 5, Mitte (Ortsteil), Berlin' ‚Üí Mitte\n",
      "  'Pufendorfstra√üe 3A-3E, Friedrichshain, Berlin' ‚Üí Friedrichshain-Kreuzberg\n",
      "  'Warburgzeile 1, 10585 Berlin' ‚Üí Charlottenburg-Wilmersdorf\n",
      "  'Johannisplatz 3, 10117 Berlin' ‚Üí Mitte\n",
      "  'Kreutzigerstra√üe 14, Friedrichshain, Berlin' ‚Üí Friedrichshain-Kreuzberg\n",
      "  'Elsa-Neumann-Stra√üe 1, 13629 Berlin' ‚Üí Spandau\n",
      "  'Tiergarten, Berlin' ‚Üí Mitte\n",
      "  'Chausseestra√üe 108, Mitte (Ortsteil), Berlin' ‚Üí Mitte\n",
      "\n",
      "=== NICHT-EXTRAHIERTE ADRESSEN (1330 Eintr√§ge) ===\n",
      "  ‚ùå 'Abendseglersteig 55, Rahnsdorf, Berlin'\n",
      "  ‚ùå 'Gr√ºnauer Stra√üe 26, Altglienicke, Berlin'\n",
      "  ‚ùå 'Am Maselakepark 31, Hakenfelde, Berlin'\n",
      "  ‚ùå 'Lion-Feuchtwanger Stra√üe 61, Hellersdorf, Berlin'\n",
      "  ‚ùå 'Lehderstra√üe 26-27, 13806 Berlin'\n",
      "  ‚ùå 'Regattastra√üe 7, Gr√ºnau, Berlin'\n",
      "  ‚ùå 'Ahrenshooper Stra√üe 10, Neu-Hohensch√∂nhausen, Berlin'\n",
      "  ‚ùå 'Ahrenshooper Stra√üe 14, Neu-Hohensch√∂nhausen, Berlin'\n",
      "  ‚ùå 'Parksiedlung Spruch 3 bis 137, Buckow, Berlin'\n",
      "  ‚ùå 'Brixplatz 13, Westend, Berlin'\n",
      "\n",
      "=== BEZIRK-VERTEILUNG ===\n",
      "Anzahl einzigartiger Bezirke: 22\n",
      "  Mitte: 1026 Eintr√§ge\n",
      "  Pankow: 784 Eintr√§ge\n",
      "  Friedrichshain-Kreuzberg: 776 Eintr√§ge\n",
      "  Charlottenburg-Wilmersdorf: 602 Eintr√§ge\n",
      "  Neuk√∂lln: 397 Eintr√§ge\n",
      "  Tempelhof-Sch√∂neberg: 355 Eintr√§ge\n",
      "  Treptow-K√∂penick: 276 Eintr√§ge\n",
      "  Steglitz-Zehlendorf: 170 Eintr√§ge\n",
      "  Lichtenberg: 148 Eintr√§ge\n",
      "  Reinickendorf: 129 Eintr√§ge\n",
      "\n",
      "‚úÖ Verbleibende Eintr√§ge nach Bezirk-Extraktion: 4,779\n",
      "Datenverlust: 1,330 Eintr√§ge (21.8%)\n"
     ]
    }
   ],
   "source": [
    "def extract_district_from_address(address):\n",
    "    \"\"\"\n",
    "    Intelligente Bezirk-Extraktion aus verschiedenen Adressformaten\n",
    "    \n",
    "    Unterst√ºtzte Formate:\n",
    "    1. PLZ-basiert: \"Johannisplatz 3, 10117 Berlin\"\n",
    "    2. Bezirk direkt: \"Johannisplatz 5, Mitte (Ortsteil), Berlin\"\n",
    "    3. Nur Bezirk: \"Tiergarten, Berlin\"\n",
    "    4. Nur PLZ: \"10557 Berlin\"\n",
    "    \"\"\"\n",
    "    if pd.isna(address):\n",
    "        return None\n",
    "    \n",
    "    address = str(address).strip()\n",
    "    \n",
    "    # Methode 1: PLZ-Extraktion (5-stellige Zahlen)\n",
    "    plz_match = re.search(r'\\b(\\d{5})\\b', address)\n",
    "    if plz_match:\n",
    "        plz = int(plz_match.group(1))\n",
    "        if plz in plz_to_district:\n",
    "            return plz_to_district[plz]\n",
    "    \n",
    "    # Methode 2: Bezirk-Namen direkt im Text finden\n",
    "    # Entferne \"Berlin\" vom Ende und teile bei Komma\n",
    "    address_clean = address.replace(', Berlin', '').replace(' Berlin', '')\n",
    "    \n",
    "    # Suche nach bekannten Bezirken in der Adresse\n",
    "    for alias, normalized in district_aliases.items():\n",
    "        if alias.lower() in address_clean.lower():\n",
    "            return normalized\n",
    "    \n",
    "    # Methode 3: Letzte Komponente vor \"Berlin\" als Bezirk\n",
    "    parts = address_clean.split(',')\n",
    "    if len(parts) >= 2:\n",
    "        potential_district = parts[-1].strip()\n",
    "        # Entferne Zus√§tze wie \"(Ortsteil)\"\n",
    "        potential_district = re.sub(r'\\s*\\([^)]+\\)', '', potential_district)\n",
    "        \n",
    "        # Pr√ºfe ob es ein bekannter Bezirk ist\n",
    "        if potential_district in district_aliases:\n",
    "            return district_aliases[potential_district]\n",
    "    \n",
    "    # Methode 4: Direkte Bezirk-Suche im gesamten Text\n",
    "    for bezirk in district_aliases.values():\n",
    "        if bezirk.lower() in address_clean.lower():\n",
    "            return bezirk\n",
    "    \n",
    "    return None\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"INTELLIGENTE ADRESSEXTRAKTION\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Arbeite mit einer Kopie\n",
    "df_clean = df.copy()\n",
    "\n",
    "# Bezirk extrahieren\n",
    "print(\"Extrahiere Bezirke aus Adressen...\")\n",
    "df_clean['district'] = df_clean['address'].apply(extract_district_from_address)\n",
    "\n",
    "# Statistiken\n",
    "total_addresses = len(df_clean)\n",
    "successful_extractions = df_clean['district'].notna().sum()\n",
    "success_rate = 100 * successful_extractions / total_addresses\n",
    "\n",
    "print(f\"‚úÖ Bezirk-Extraktion abgeschlossen:\")\n",
    "print(f\"  Gesamt Adressen: {total_addresses:,}\")\n",
    "print(f\"  Erfolgreiche Extraktion: {successful_extractions:,}\")\n",
    "print(f\"  Erfolgsrate: {success_rate:.1f}%\")\n",
    "\n",
    "# Zeige Beispiele erfolgreicher Extraktion\n",
    "print(f\"=== ERFOLGREICHE EXTRAKTION (Beispiele) ===\")\n",
    "successful_examples = df_clean[df_clean['district'].notna()][['address', 'district']].head(10)\n",
    "for idx, row in successful_examples.iterrows():\n",
    "    print(f\"  '{row['address']}' ‚Üí {row['district']}\")\n",
    "\n",
    "# Zeige nicht-extrahierte Adressen\n",
    "failed_extractions = df_clean[df_clean['district'].isna()]\n",
    "if len(failed_extractions) > 0:\n",
    "    print(f\"=== NICHT-EXTRAHIERTE ADRESSEN ({len(failed_extractions)} Eintr√§ge) ===\")\n",
    "    for addr in failed_extractions['address'].unique()[:10]:\n",
    "        print(f\"  ‚ùå '{addr}'\")\n",
    "        \n",
    "# Bezirk-Verteilung\n",
    "print(f\"=== BEZIRK-VERTEILUNG ===\")\n",
    "district_counts = df_clean['district'].value_counts()\n",
    "print(f\"Anzahl einzigartiger Bezirke: {len(district_counts)}\")\n",
    "for district, count in district_counts.head(10).items():\n",
    "    print(f\"  {district}: {count} Eintr√§ge\")\n",
    "    \n",
    "# Nur Zeilen mit erfolgreich extrahierten Bezirken behalten\n",
    "df_clean = df_clean[df_clean['district'].notna()]\n",
    "print(f\"‚úÖ Verbleibende Eintr√§ge nach Bezirk-Extraktion: {len(df_clean):,}\")\n",
    "print(f\"Datenverlust: {total_addresses - len(df_clean):,} Eintr√§ge ({100*(total_addresses - len(df_clean))/total_addresses:.1f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e64402b8",
   "metadata": {},
   "source": [
    "## 5. Datenbereinigung und Filter-Harmonisierung\n",
    "\n",
    "### üéØ **Einheitliche Bereinigungskriterien**\n",
    "**Konsistent mit allen anderen Datasets in der Pipeline:**\n",
    "- **Preis-Filter:** 100‚Ç¨ - 10.000‚Ç¨ (Kaltmiete)\n",
    "- **Gr√∂√üen-Filter:** 10m¬≤ - 500m¬≤ (Wohnfl√§che)\n",
    "- **Bezirk-Validierung:** Nur g√ºltige Berliner Bezirke\n",
    "\n",
    "### üìã **Multi-Listing-Behandlung**\n",
    "Dataset 2025 enth√§lt Multi-Listings (Preis- und Gr√∂√üenspannen):\n",
    "- **Preisspannen:** \"725 - 1.965‚Ç¨\" ‚Üí Nimm Mindestpreis (725‚Ç¨)\n",
    "- **Gr√∂√üenspannen:** \"26,55 - 112,82m¬≤\" ‚Üí Nimm Mindestgr√∂√üe (26,55m¬≤)\n",
    "- **Rationale:** Konservative SchÔøΩÔøΩtzung f√ºr Vergleichbarkeit\n",
    "\n",
    "### üîÑ **Harmonisierung mit anderen Datasets**\n",
    "- **Dataset 2018-2019:** Gleiche Filter (100‚Ç¨-10.000‚Ç¨, 10m¬≤-500m¬≤)\n",
    "- **Dataset 2022:** Filter aktualisiert auf gleiche Werte\n",
    "- **Dataset 2025:** Implementiert gleiche Logik\n",
    "\n",
    "**Ziel:** Maximale Vergleichbarkeit und Konsistenz zwischen allen Zeitr√§umen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c4d1cb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "DATENBEREINIGUNG UND MULTI-LISTING-BEHANDLUNG\n",
      "============================================================\n",
      "Bereinige Preisfelder...\n",
      "Bereinige Gr√∂√üenfelder...\n",
      "\n",
      "=== BEREINIGUNGSSTATISTIKEN ===\n",
      "Urspr√ºngliche Eintr√§ge: 4,779\n",
      "G√ºltige Preise: 4,779/4,779 (100.0%)\n",
      "G√ºltige Gr√∂√üen: 4,779/4,779 (100.0%)\n",
      "Beide g√ºltig: 4,779/4,779 (100.0%)\n",
      "\n",
      "=== UNREALISTISCHE WERTE ENTFERNEN ===\n",
      "Nach Preis-Filter: 4,764 (entfernt: 15)\n",
      "Nach Gr√∂√üen-Filter: 4,763 (entfernt: 1)\n",
      "\n",
      "‚úÖ Datenbereinigung abgeschlossen\n",
      "Finale Datens√§tze: 4,763\n",
      "\n",
      "=== FINALE DATENVERTEILUNG ===\n",
      "Preis - Min: 150.00‚Ç¨, Max: 9990.00‚Ç¨, Median: 1000.00‚Ç¨\n",
      "Gr√∂√üe - Min: 11.0m¬≤, Max: 361.0m¬≤, Median: 65.0m¬≤\n"
     ]
    }
   ],
   "source": [
    "def clean_price_field(price_str):\n",
    "    \"\"\"\n",
    "    Bereinige Preisfeld und extrahiere Einzelpreise aus Multi-Listings\n",
    "    \n",
    "    Behandelt folgende Formate:\n",
    "    - Einzelpreis: \"1.235‚Ç¨\" ‚Üí 1235.0\n",
    "    - Preisspanne: \"725 - 1.965‚Ç¨\" ‚Üí 725.0 (Mindestpreis)\n",
    "    - Deutsche Formate: \"1.235,65‚Ç¨\" ‚Üí 1235.65\n",
    "    \n",
    "    Returns:\n",
    "        float: Bereinigter Preis oder None bei Fehlern\n",
    "    \"\"\"\n",
    "    if pd.isna(price_str):\n",
    "        return None\n",
    "    \n",
    "    price_str = str(price_str).strip()\n",
    "    \n",
    "    # Entferne Euro-Zeichen und Leerzeichen\n",
    "    price_str = price_str.replace('‚Ç¨', '').replace(' ', '')\n",
    "    \n",
    "    # Behandle Preisspannen (z.B. \"725 - 1.965\")\n",
    "    if '-' in price_str:\n",
    "        # Multi-Listing: Nimm Minimalpreis f√ºr Vergleichbarkeit\n",
    "        parts = price_str.split('-')\n",
    "        try:\n",
    "            min_price = float(parts[0].replace('.', '').replace(',', '.'))\n",
    "            return min_price\n",
    "        except:\n",
    "            return None\n",
    "    \n",
    "    # Einzelpreis\n",
    "    try:\n",
    "        # Behandle deutsche Zahlenformate (1.435,65 ‚Üí 1435.65)\n",
    "        if ',' in price_str and '.' in price_str:\n",
    "            # Format: 1.435,65\n",
    "            price_str = price_str.replace('.', '').replace(',', '.')\n",
    "        elif ',' in price_str:\n",
    "            # Format: 1435,65\n",
    "            price_str = price_str.replace(',', '.')\n",
    "        elif '.' in price_str and len(price_str.split('.')[-1]) == 2:\n",
    "            # Format: 1435.65 (bereits korrekt)\n",
    "            pass\n",
    "        else:\n",
    "            # Format: 1435 (Tausender-Trennzeichen entfernen)\n",
    "            price_str = price_str.replace('.', '')\n",
    "        \n",
    "        return float(price_str)\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "def clean_size_field(size_str):\n",
    "    \"\"\"\n",
    "    Bereinige Gr√∂√üenfeld und extrahiere Einzelgr√∂√üen aus Multi-Listings\n",
    "    \n",
    "    Behandelt folgende Formate:\n",
    "    - Einzelgr√∂√üe: \"67,5m¬≤\" ‚Üí 67.5\n",
    "    - Gr√∂√üenspanne: \"26,55 - 112,82m¬≤\" ‚Üí 26.55 (Mindestgr√∂√üe)\n",
    "    - Verschiedene Trennzeichen: \"67,5\" oder \"67.5\"\n",
    "    \n",
    "    Returns:\n",
    "        float: Bereinigte Gr√∂√üe oder None bei Fehlern\n",
    "    \"\"\"\n",
    "    if pd.isna(size_str):\n",
    "        return None\n",
    "    \n",
    "    size_str = str(size_str).strip()\n",
    "    \n",
    "    # Entferne m¬≤ und Leerzeichen\n",
    "    size_str = size_str.replace('m¬≤', '').replace(' ', '')\n",
    "    \n",
    "    # Behandle Gr√∂√üenspannen (z.B. \"26,55 - 112,82\")\n",
    "    if '-' in size_str:\n",
    "        # Multi-Listing: Nimm Minimalgr√∂√üe f√ºr Vergleichbarkeit\n",
    "        parts = size_str.split('-')\n",
    "        try:\n",
    "            min_size = float(parts[0].replace(',', '.'))\n",
    "            return min_size\n",
    "        except:\n",
    "            return None\n",
    "    \n",
    "    # Einzelgr√∂√üe\n",
    "    try:\n",
    "        return float(size_str.replace(',', '.'))\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "# ===================================================================\n",
    "# EINHEITLICHE DATENBEREINIGUNG (HARMONISIERT MIT ALLEN DATASETS)\n",
    "# ===================================================================\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"DATENBEREINIGUNG UND MULTI-LISTING-BEHANDLUNG\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Bereinige Preise\n",
    "print(\"Bereinige Preisfelder...\")\n",
    "df_clean['price_clean'] = df_clean['price'].apply(clean_price_field)\n",
    "\n",
    "# Bereinige Gr√∂√üen\n",
    "print(\"Bereinige Gr√∂√üenfelder...\")\n",
    "df_clean['size_clean'] = df_clean['size'].apply(clean_size_field)\n",
    "\n",
    "# Statistiken vor Bereinigung\n",
    "print(f\"=== BEREINIGUNGSSTATISTIKEN ===\")\n",
    "print(f\"Urspr√ºngliche Eintr√§ge: {len(df_clean):,}\")\n",
    "\n",
    "# Entferne Zeilen ohne g√ºltige Preise\n",
    "valid_prices = df_clean['price_clean'].notna()\n",
    "print(f\"G√ºltige Preise: {valid_prices.sum():,}/{len(df_clean):,} ({100*valid_prices.sum()/len(df_clean):.1f}%)\")\n",
    "\n",
    "# Entferne Zeilen ohne g√ºltige Gr√∂√üen\n",
    "valid_sizes = df_clean['size_clean'].notna()\n",
    "print(f\"G√ºltige Gr√∂√üen: {valid_sizes.sum():,}/{len(df_clean):,} ({100*valid_sizes.sum()/len(df_clean):.1f}%)\")\n",
    "\n",
    "# Kombiniere Bedingungen\n",
    "valid_data = valid_prices & valid_sizes\n",
    "print(f\"Beide g√ºltig: {valid_data.sum():,}/{len(df_clean):,} ({100*valid_data.sum()/len(df_clean):.1f}%)\")\n",
    "\n",
    "# Behalte nur g√ºltige Daten\n",
    "df_clean = df_clean[valid_data]\n",
    "\n",
    "# ===================================================================\n",
    "# EINHEITLICHE FILTER-KRITERIEN (KONSISTENT MIT ALLEN DATASETS)\n",
    "# ===================================================================\n",
    "\n",
    "print(f\"=== EINHEITLICHE FILTER-KRITERIEN ===\")\n",
    "print(f\"üìã Harmonisiert mit Dataset 2018-2019 und Dataset 2022\")\n",
    "print(f\"üéØ Ziel: Maximale Vergleichbarkeit zwischen allen Zeitr√§umen\")\n",
    "\n",
    "initial_count = len(df_clean)\n",
    "\n",
    "# Preis-Filter (100‚Ç¨ - 10.000‚Ç¨) - KONSISTENT MIT ALLEN DATASETS\n",
    "print(f\"üîπ Preis-Filter: 100‚Ç¨ - 10.000‚Ç¨\")\n",
    "df_clean = df_clean[(df_clean['price_clean'] >= 100) & (df_clean['price_clean'] <= 10000)]\n",
    "print(f\"Nach Preis-Filter: {len(df_clean):,} (entfernt: {initial_count - len(df_clean):,})\")\n",
    "\n",
    "# Gr√∂√üen-Filter (10m¬≤ - 500m¬≤) - KONSISTENT MIT ALLEN DATASETS\n",
    "print(f\"üîπ Gr√∂√üen-Filter: 10m¬≤ - 500m¬≤\")\n",
    "initial_count = len(df_clean)\n",
    "df_clean = df_clean[(df_clean['size_clean'] >= 10) & (df_clean['size_clean'] <= 500)]\n",
    "print(f\"Nach Gr√∂√üen-Filter: {len(df_clean):,} (entfernt: {initial_count - len(df_clean):,})\")\n",
    "\n",
    "print(f\"‚úÖ Datenbereinigung abgeschlossen\")\n",
    "print(f\"‚úÖ Filter-Harmonisierung erfolgreich\")\n",
    "print(f\"Finale Datens√§tze: {len(df_clean):,}\")\n",
    "\n",
    "# Zeige Preis- und Gr√∂√üenverteilung\n",
    "print(f\"=== FINALE DATENVERTEILUNG ===\")\n",
    "print(f\"Preis - Min: {df_clean['price_clean'].min():.2f}‚Ç¨, Max: {df_clean['price_clean'].max():.2f}‚Ç¨, Median: {df_clean['price_clean'].median():.2f}‚Ç¨\")\n",
    "print(f\"Gr√∂√üe - Min: {df_clean['size_clean'].min():.1f}m¬≤, Max: {df_clean['size_clean'].max():.1f}m¬≤, Median: {df_clean['size_clean'].median():.1f}m¬≤\")\n",
    "\n",
    "print(f\"üìä BEREINIGUNGSLOGIK KONSISTENT MIT:\")\n",
    "print(f\"   ‚Ä¢ 01_Clean_Dataset_2018_2019.ipynb\")\n",
    "print(f\"   ‚Ä¢ 02_Clean_Dataset_2022.ipynb\")\n",
    "print(f\"   ‚Ä¢ 03_Clean_Dataset_2025.ipynb (dieses Notebook)\")\n",
    "print(f\"   ‚Ä¢ 04_Combine_Datasets.ipynb (finale Validierung)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55e08766",
   "metadata": {},
   "source": [
    "## 6. Normalisierung in Standardformat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1ff76d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "NORMALISIERUNG IN STANDARDFORMAT\n",
      "============================================================\n",
      "Normalisiertes Dataset erstellt: 4,763 Zeilen\n",
      "Standardspalten: ['price', 'size', 'district', 'rooms', 'year', 'dataset_id', 'source']\n",
      "Zus√§tzliche Spalten: 5\n",
      "\n",
      "=== DATENQUALIT√ÑT NORMALISIERTES DATASET ===\n",
      "Zeilen mit Preis: 4,763\n",
      "Zeilen mit Gr√∂√üe: 4,763\n",
      "Zeilen mit Bezirk: 4,763\n",
      "Zeilen mit Zimmeranzahl: 0\n",
      "\n",
      "=== STATISTIKEN ===\n",
      "Preis - Min: 150.00‚Ç¨, Max: 9990.00‚Ç¨, Median: 1000.00‚Ç¨\n",
      "Gr√∂√üe - Min: 11.0m¬≤, Max: 361.0m¬≤, Median: 65.0m¬≤\n",
      "\n",
      "=== BEZIRKSVERTEILUNG ===\n",
      "Anzahl Bezirke: 21\n",
      "  Mitte: 1023 Eintr√§ge\n",
      "  Pankow: 781 Eintr√§ge\n",
      "  Friedrichshain-Kreuzberg: 773 Eintr√§ge\n",
      "  Charlottenburg-Wilmersdorf: 600 Eintr√§ge\n",
      "  Neuk√∂lln: 396 Eintr√§ge\n",
      "  Tempelhof-Sch√∂neberg: 355 Eintr√§ge\n",
      "  Treptow-K√∂penick: 276 Eintr√§ge\n",
      "  Steglitz-Zehlendorf: 169 Eintr√§ge\n",
      "  Lichtenberg: 148 Eintr√§ge\n",
      "  Reinickendorf: 129 Eintr√§ge\n",
      "\n",
      "‚úÖ Normalisierung abgeschlossen!\n"
     ]
    }
   ],
   "source": [
    "print(\"=\"*60)\n",
    "print(\"NORMALISIERUNG IN STANDARDFORMAT\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Erstelle normalisiertes Dataset\n",
    "df_normalized = pd.DataFrame()\n",
    "\n",
    "# Standardspalten (kompatibel mit anderen Datasets)\n",
    "df_normalized['price'] = df_clean['price_clean']\n",
    "df_normalized['size'] = df_clean['size_clean']\n",
    "df_normalized['district'] = df_clean['district']\n",
    "df_normalized['rooms'] = np.nan  # Nicht verf√ºgbar im 2025 Dataset\n",
    "df_normalized['year'] = 2025\n",
    "df_normalized['dataset_id'] = 'recent'\n",
    "df_normalized['source'] = 'ImmobilienScout24'\n",
    "\n",
    "# Zus√§tzliche Spalten aus dem 2025 Dataset\n",
    "df_normalized['title'] = df_clean['title']\n",
    "df_normalized['address'] = df_clean['address']\n",
    "df_normalized['link'] = df_clean['link']\n",
    "df_normalized['price_original'] = df_clean['price']\n",
    "df_normalized['size_original'] = df_clean['size']\n",
    "\n",
    "print(f\"Normalisiertes Dataset erstellt: {len(df_normalized):,} Zeilen\")\n",
    "print(f\"Standardspalten: {['price', 'size', 'district', 'rooms', 'year', 'dataset_id', 'source']}\")\n",
    "print(f\"Zus√§tzliche Spalten: {len(df_normalized.columns) - 7}\")\n",
    "\n",
    "# Datenqualit√§t pr√ºfen\n",
    "print(f\"=== DATENQUALIT√ÑT NORMALISIERTES DATASET ===\")\n",
    "print(f\"Zeilen mit Preis: {df_normalized['price'].notna().sum():,}\")\n",
    "print(f\"Zeilen mit Gr√∂√üe: {df_normalized['size'].notna().sum():,}\")\n",
    "print(f\"Zeilen mit Bezirk: {df_normalized['district'].notna().sum():,}\")\n",
    "print(f\"Zeilen mit Zimmeranzahl: {df_normalized['rooms'].notna().sum():,}\")\n",
    "\n",
    "# Statistiken\n",
    "print(f\"=== STATISTIKEN ===\")\n",
    "print(f\"Preis - Min: {df_normalized['price'].min():.2f}‚Ç¨, Max: {df_normalized['price'].max():.2f}‚Ç¨, Median: {df_normalized['price'].median():.2f}‚Ç¨\")\n",
    "print(f\"Gr√∂√üe - Min: {df_normalized['size'].min():.1f}m¬≤, Max: {df_normalized['size'].max():.1f}m¬≤, Median: {df_normalized['size'].median():.1f}m¬≤\")\n",
    "\n",
    "# Bezirksverteilung\n",
    "print(f\"=== BEZIRKSVERTEILUNG ===\")\n",
    "district_counts = df_normalized['district'].value_counts()\n",
    "print(f\"Anzahl Bezirke: {len(district_counts)}\")\n",
    "for district, count in district_counts.head(10).items():\n",
    "    print(f\"  {district}: {count} Eintr√§ge\")\n",
    "\n",
    "print(f\"‚úÖ Normalisierung abgeschlossen!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "055d649d",
   "metadata": {},
   "source": [
    "## 7. Export des normalisierten Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0cc7cac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "EXPORT NORMALISIERTES DATASET\n",
      "============================================================\n",
      "‚úÖ Normalisiertes Dataset exportiert: data/processed/dataset_2025_normalized.csv\n",
      "Dateigr√∂√üe: 4,763 Zeilen x 12 Spalten\n",
      "‚úÖ Export-Validierung erfolgreich: 4,763 Zeilen geladen\n",
      "\n",
      "=== ZUSAMMENFASSUNG DATASET 2025 ===\n",
      "Input: data/raw/Dataset_2025.csv (6,109 Zeilen)\n",
      "Output: data/processed/dataset_2025_normalized.csv (4,763 Zeilen)\n",
      "Datenverlust: 1,346 Zeilen (22.0%)\n",
      "Bezirk-Extraktion: 4,763/6,109 (78.0%) erfolgreich\n",
      "Standardisierte Spalten: price, size, district, rooms, year, dataset_id, source\n",
      "Zus√§tzliche Spalten: 5\n",
      "\n",
      "üéØ DATASET 2025 BEREINIGUNG ABGESCHLOSSEN!\n",
      "Bereit f√ºr Kombination mit anderen normalisierten Datasets.\n"
     ]
    }
   ],
   "source": [
    "print(\"=\"*60)\n",
    "print(\"EXPORT NORMALISIERTES DATASET\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Export des normalisierten Datasets\n",
    "output_path = 'data/processed/dataset_2025_normalized.csv'\n",
    "df_normalized.to_csv(output_path, index=False)\n",
    "\n",
    "print(f\"‚úÖ Normalisiertes Dataset exportiert: {output_path}\")\n",
    "print(f\"Dateigr√∂√üe: {len(df_normalized):,} Zeilen x {len(df_normalized.columns)} Spalten\")\n",
    "\n",
    "# Validierung durch Wiedereinlesen\n",
    "df_validation = pd.read_csv(output_path)\n",
    "print(f\"‚úÖ Export-Validierung erfolgreich: {len(df_validation):,} Zeilen geladen\")\n",
    "\n",
    "# Zusammenfassung\n",
    "print(f\"=== ZUSAMMENFASSUNG DATASET 2025 ===\")\n",
    "print(f\"Input: data/raw/Dataset_2025.csv ({len(df):,} Zeilen)\")\n",
    "print(f\"Output: {output_path} ({len(df_normalized):,} Zeilen)\")\n",
    "print(f\"Datenverlust: {len(df) - len(df_normalized):,} Zeilen ({100*(len(df) - len(df_normalized))/len(df):.1f}%)\")\n",
    "print(f\"Bezirk-Extraktion: {len(df_normalized):,}/{len(df):,} ({100*len(df_normalized)/len(df):.1f}%) erfolgreich\")\n",
    "\n",
    "# Standardisierung und Kompatibilit√§t\n",
    "print(f\"=== STANDARDISIERUNG UND KOMPATIBILIT√ÑT ===\")\n",
    "print(f\"‚úÖ Standardisierte Spalten: price, size, district, rooms, year, dataset_id, source\")\n",
    "print(f\"‚úÖ Zus√§tzliche Spalten: {len(df_normalized.columns) - 7} (dataset-spezifisch)\")\n",
    "print(f\"‚úÖ Einheitliche Filter-Kriterien: Preis 100‚Ç¨-10.000‚Ç¨, Gr√∂√üe 10m¬≤-500m¬≤\")\n",
    "print(f\"‚úÖ Multi-Listing-Behandlung: Mindestpreise f√ºr Vergleichbarkeit\")\n",
    "\n",
    "# Harmonisierung mit anderen Datasets\n",
    "print(f\"=== HARMONISIERUNG MIT ANDEREN DATASETS ===\")\n",
    "print(f\"üîÑ Dataset 2018-2019: Identische Filter-Kriterien\")\n",
    "print(f\"üîÑ Dataset 2022: Filter-Kriterien harmonisiert\")\n",
    "print(f\"üîÑ Dataset 2025: Implementiert (dieses Notebook)\")\n",
    "print(f\"üîÑ Combine-Step: Bereit f√ºr nahtlose Integration\")\n",
    "\n",
    "print(f\"üéØ DATASET 2025 BEREINIGUNG ABGESCHLOSSEN!\")\n",
    "print(f\"üìä Bereit f√ºr Kombination mit anderen normalisierten Datasets\")\n",
    "print(f\"üöÄ Konsistente Datenqualit√§t und Vergleichbarkeit gew√§hrleistet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1b2c3d6",
   "metadata": {},
   "source": [
    "## 8. Lade angereicherte Wohnlagendaten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5f6g7h0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*60)\n",
    "print(\"ANGEREICHERTE WOHNLAGENDATEN LADEN\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "enriched_data_path = 'data/raw/wohnlagen_enriched.csv'\n",
    "try:\n",
    "    enriched_df = pd.read_csv(enriched_data_path)\n",
    "    print(f\"‚úÖ Angereicherte Daten geladen: {len(enriched_df):,} Zeilen, {len(enriched_df.columns)} Spalten\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"‚ùå Datei nicht gefunden: {enriched_data_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "i9j0k1l4",
   "metadata": {},
   "source": [
    "## 9. Kombiniere Datasets mit Wohnlagendaten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "m3n4o5p8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*60)\n",
    "print(\"KOMBINIERE MIT WOHNLAGENDATEN\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Extract PLZ from address for merging\n",
    "df_normalized['plz'] = df_normalized['address'].str.extract(r'(\\d{5})')\n",
    "\n",
    "# Merge the two dataframes\n",
    "enriched_df_subset = enriched_df[['plz', 'wol', 'ortsteil_neu']]\n",
    "df_enriched = pd.merge(df_normalized, enriched_df_subset, how='left', on=['plz'])\n",
    "\n",
    "print(f\"‚úÖ Kombiniertes und angereichertes Dataset erstellt: {len(df_enriched):,} Zeilen\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "q7r8s9t2",
   "metadata": {},
   "source": [
    "## 10. Export des finalen angereicherten Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "u1v2w3x6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*60)\n",
    "print(\"EXPORT FINALES ANGEREICHERTES DATASET\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Export\n",
    "output_file_enriched = 'data/processed/dataset_2025_enriched.csv'\n",
    "df_enriched.to_csv(output_file_enriched, index=False)\n",
    "\n",
    "print(f\"‚úÖ Finales angereichertes Dataset exportiert: {output_file_enriched}\")\n",
    "print(f\"Dateigr√∂√üe: {len(df_enriched):,} Zeilen x {len(df_enriched.columns)} Spalten\")\n",
    "\n",
    "# Validierung durch Wiedereinlesen\n",
    "test_df_enriched = pd.read_csv(output_file_enriched)\n",
    "print(f\"‚úÖ Export-Validierung erfolgreich: {len(test_df_enriched):,} Zeilen geladen\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
