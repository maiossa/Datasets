{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9b507988",
   "metadata": {},
   "source": [
    "# Berlin Housing Market Analysis - Hauptanalyse\n",
    "## Datenbereinigung, Zusammenführung und Explorative Analyse\n",
    "\n",
    "### Projektübersicht\n",
    "Dieses Notebook führt die Hauptanalyse des Berliner Wohnungsmarktes durch. Es baut auf dem PLZ-Mapping aus `01_Data_Preprocessing.ipynb` auf und erstellt eine umfassende Analyse der drei Datensätze.\n",
    "\n",
    "### Voraussetzungen\n",
    "- `01_Data_Preprocessing.ipynb` wurde erfolgreich ausgeführt\n",
    "- PLZ-Mapping-Tabelle liegt in `data/processed/berlin_plz_mapping.csv` vor\n",
    "- Originaldaten befinden sich in `data/raw/`\n",
    "\n",
    "### Analyseziele\n",
    "1. **Datenbereinigung und -normalisierung** aller drei Datensätze\n",
    "2. **Zusammenführung** in ein einheitliches Dataset\n",
    "3. **Zeitreihenanalyse** der Mietpreisentwicklung\n",
    "4. **Bezirksvergleiche** mit statistischen Tests\n",
    "5. **Explorative Datenanalyse** mit umfassenden Visualisierungen\n",
    "\n",
    "---\n",
    "\n",
    "**Autor**: Berlin Housing Market Analysis Team  \n",
    "**Datum**: 4. Juli 2025  \n",
    "**Version**: 1.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a2d5df1",
   "metadata": {},
   "source": [
    "## 1. Import Required Libraries\n",
    "Importieren der erforderlichen Python-Bibliotheken für Datenverarbeitung, Analyse und Visualisierung."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1cf07a03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alle Bibliotheken erfolgreich importiert!\n",
      "Pandas Version: 2.3.0\n",
      "NumPy Version: 2.3.0\n",
      "Matplotlib Version: 3.10.3\n",
      "Seaborn Version: 0.13.2\n",
      "Verarbeitung gestartet am: 2025-07-04 04:21:25\n"
     ]
    }
   ],
   "source": [
    "# Datenmanipulation und -analyse\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Visualisierung\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "# Statistik und Machine Learning\n",
    "from scipy import stats\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
    "\n",
    "# Textverarbeitung und Regex\n",
    "import re\n",
    "from collections import Counter\n",
    "\n",
    "# Datum und Zeit\n",
    "from datetime import datetime\n",
    "\n",
    "# Konfiguration\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', 1000)\n",
    "pd.set_option('display.max_rows', 50)\n",
    "plt.style.use('seaborn-v0_8')\n",
    "\n",
    "print(\"Alle Bibliotheken erfolgreich importiert!\")\n",
    "print(f\"Pandas Version: {pd.__version__}\")\n",
    "print(f\"NumPy Version: {np.__version__}\")\n",
    "print(f\"Matplotlib Version: {matplotlib.__version__}\")\n",
    "print(f\"Seaborn Version: {sns.__version__}\")\n",
    "print(f\"Verarbeitung gestartet am: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ca44272",
   "metadata": {},
   "source": [
    "## 2. Laden der bereinigten Daten\n",
    "### 2.1 Bereinigte Datensätze laden\n",
    "Laden der im Preprocessing-Notebook bereits bereinigten und normalisierten Datensätze."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a1a7269b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "LADEN DER BEREINIGTEN DATENSÄTZE\n",
      "============================================================\n",
      "\n",
      "Kombiniertes bereinigtes Dataset:\n",
      "Zeilen: 19,779\n",
      "Spalten: 96\n",
      "Spalten: ['regio3', 'street', 'livingSpace', 'baseRent', 'totalRent', 'noRooms', 'floor', 'typeOfFlat', 'yearConstructed', 'Jahr', 'Dataset', 'ID', 'SORTE', 'PLZ_x', 'KALTMIETE', 'WARMMIETE', 'NEBENKOSTEN', 'KAUTION', 'HEIZUNGSKOSTEN', 'ZIMMER', 'PARKPLAETZE', 'WOHNFLAECHE', 'BAUJAHR', 'ZUSTAND', 'VERfÜGBAR AB', 'ENERGIEEFFIZIENSKLASSE', 'ENERGIEBEDARF/kWh/(m²*a)', 'ENERGIEASUWEIS', 'Etagenheizung', 'Zentralheizung', 'Ofenheizung', 'offener Kamin', 'Luft-/Wasser-Wärmepumpe', 'Gas', 'Öl', 'Solar', 'Strom', 'Holz', 'Fernwärme', 'Erdwärme', 'Pellets', 'Kohle', 'Flüssiggas', 'KfW 55', 'Niedrigenergie', 'KfW 40', 'KfW 60', 'KfW 70', 'Neubaustandard', 'möbliert', 'teilweise möbliert', 'Alarmanlage', 'Garage', 'Carport', 'Tiefgarage', 'Duplex', 'Stellplatz', 'Klimaanlage', 'Sauna', 'Schwimmbad', 'See', 'Berge', 'Personenaufzug', 'Lastenaufzug', 'Keller', 'Waschraum', 'Bibliothek', 'Terrasse', 'Balkon', 'Garten', 'Einbauküche', 'Dusche', 'Badewanne', 'Bad mit Fenster', 'Gäste-WC', 'Fliesen', 'Parkett', 'Holz/Dielen', 'Laminat', 'Teppich', 'PVC/Linoleum', 'Stein', 'Marmor', 'Doppelboden', 'Terracotta', 'Sonstiges', 'PLZ_str', 'PLZ_y', 'Bezirk', 'title', 'price', 'size', 'address', 'link', 'is_split_from_multi', 'original_multi_count']\n",
      "\n",
      "Einzelne bereinigte Datensätze:\n",
      "Dataset 2025 bereinigt: 6,423 Zeilen, 7 Spalten\n",
      "Dataset 2018-2019 bereinigt: 10,406 Zeilen, 9 Spalten\n",
      "Dataset 2022 bereinigt: 2,950 Zeilen, 78 Spalten\n",
      "PLZ-Mapping: 181 Einträge\n",
      "\n",
      "Gesamtdatenpunkte (bereinigt): 19,779\n",
      "Verfügbare Bezirke: 12\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'<=' not supported between instances of 'str' and 'int'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 34\u001b[39m\n\u001b[32m     32\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mGesamtdatenpunkte (bereinigt): \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcombined_df.shape[\u001b[32m0\u001b[39m]\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m,\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     33\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mVerfügbare Bezirke: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcombined_df[\u001b[33m'\u001b[39m\u001b[33mBezirk\u001b[39m\u001b[33m'\u001b[39m].nunique()\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m34\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mZeitraum: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[43mcombined_df\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mJahr\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmin\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m - \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcombined_df[\u001b[33m'\u001b[39m\u001b[33mJahr\u001b[39m\u001b[33m'\u001b[39m].max()\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Python311\\Lib\\site-packages\\pandas\\core\\series.py:6518\u001b[39m, in \u001b[36mSeries.min\u001b[39m\u001b[34m(self, axis, skipna, numeric_only, **kwargs)\u001b[39m\n\u001b[32m   6510\u001b[39m \u001b[38;5;129m@doc\u001b[39m(make_doc(\u001b[33m\"\u001b[39m\u001b[33mmin\u001b[39m\u001b[33m\"\u001b[39m, ndim=\u001b[32m1\u001b[39m))\n\u001b[32m   6511\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mmin\u001b[39m(\n\u001b[32m   6512\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   6516\u001b[39m     **kwargs,\n\u001b[32m   6517\u001b[39m ):\n\u001b[32m-> \u001b[39m\u001b[32m6518\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mNDFrame\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmin\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskipna\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnumeric_only\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Python311\\Lib\\site-packages\\pandas\\core\\generic.py:12407\u001b[39m, in \u001b[36mNDFrame.min\u001b[39m\u001b[34m(self, axis, skipna, numeric_only, **kwargs)\u001b[39m\n\u001b[32m  12400\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mmin\u001b[39m(\n\u001b[32m  12401\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m  12402\u001b[39m     axis: Axis | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[32m0\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m  12405\u001b[39m     **kwargs,\n\u001b[32m  12406\u001b[39m ):\n\u001b[32m> \u001b[39m\u001b[32m12407\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_stat_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m  12408\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmin\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m  12409\u001b[39m \u001b[43m        \u001b[49m\u001b[43mnanops\u001b[49m\u001b[43m.\u001b[49m\u001b[43mnanmin\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m  12410\u001b[39m \u001b[43m        \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m  12411\u001b[39m \u001b[43m        \u001b[49m\u001b[43mskipna\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m  12412\u001b[39m \u001b[43m        \u001b[49m\u001b[43mnumeric_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m  12413\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m  12414\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Python311\\Lib\\site-packages\\pandas\\core\\generic.py:12396\u001b[39m, in \u001b[36mNDFrame._stat_function\u001b[39m\u001b[34m(self, name, func, axis, skipna, numeric_only, **kwargs)\u001b[39m\n\u001b[32m  12392\u001b[39m nv.validate_func(name, (), kwargs)\n\u001b[32m  12394\u001b[39m validate_bool_kwarg(skipna, \u001b[33m\"\u001b[39m\u001b[33mskipna\u001b[39m\u001b[33m\"\u001b[39m, none_allowed=\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m> \u001b[39m\u001b[32m12396\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_reduce\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m  12397\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m=\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m=\u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskipna\u001b[49m\u001b[43m=\u001b[49m\u001b[43mskipna\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnumeric_only\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnumeric_only\u001b[49m\n\u001b[32m  12398\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Python311\\Lib\\site-packages\\pandas\\core\\series.py:6468\u001b[39m, in \u001b[36mSeries._reduce\u001b[39m\u001b[34m(self, op, name, axis, skipna, numeric_only, filter_type, **kwds)\u001b[39m\n\u001b[32m   6463\u001b[39m     \u001b[38;5;66;03m# GH#47500 - change to TypeError to match other methods\u001b[39;00m\n\u001b[32m   6464\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[32m   6465\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mSeries.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m does not allow \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkwd_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnumeric_only\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   6466\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mwith non-numeric dtypes.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   6467\u001b[39m     )\n\u001b[32m-> \u001b[39m\u001b[32m6468\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdelegate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskipna\u001b[49m\u001b[43m=\u001b[49m\u001b[43mskipna\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Python311\\Lib\\site-packages\\pandas\\core\\nanops.py:147\u001b[39m, in \u001b[36mbottleneck_switch.__call__.<locals>.f\u001b[39m\u001b[34m(values, axis, skipna, **kwds)\u001b[39m\n\u001b[32m    145\u001b[39m         result = alt(values, axis=axis, skipna=skipna, **kwds)\n\u001b[32m    146\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m147\u001b[39m     result = \u001b[43malt\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m=\u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskipna\u001b[49m\u001b[43m=\u001b[49m\u001b[43mskipna\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    149\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Python311\\Lib\\site-packages\\pandas\\core\\nanops.py:404\u001b[39m, in \u001b[36m_datetimelike_compat.<locals>.new_func\u001b[39m\u001b[34m(values, axis, skipna, mask, **kwargs)\u001b[39m\n\u001b[32m    401\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m datetimelike \u001b[38;5;129;01mand\u001b[39;00m mask \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    402\u001b[39m     mask = isna(values)\n\u001b[32m--> \u001b[39m\u001b[32m404\u001b[39m result = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m=\u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskipna\u001b[49m\u001b[43m=\u001b[49m\u001b[43mskipna\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    406\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m datetimelike:\n\u001b[32m    407\u001b[39m     result = _wrap_results(result, orig_values.dtype, fill_value=iNaT)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Python311\\Lib\\site-packages\\pandas\\core\\nanops.py:1098\u001b[39m, in \u001b[36m_nanminmax.<locals>.reduction\u001b[39m\u001b[34m(values, axis, skipna, mask)\u001b[39m\n\u001b[32m   1093\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m _na_for_min_count(values, axis)\n\u001b[32m   1095\u001b[39m values, mask = _get_values(\n\u001b[32m   1096\u001b[39m     values, skipna, fill_value_typ=fill_value_typ, mask=mask\n\u001b[32m   1097\u001b[39m )\n\u001b[32m-> \u001b[39m\u001b[32m1098\u001b[39m result = \u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmeth\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1099\u001b[39m result = _maybe_null_out(result, axis, mask, values.shape)\n\u001b[32m   1100\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Python311\\Lib\\site-packages\\numpy\\_core\\_methods.py:47\u001b[39m, in \u001b[36m_amin\u001b[39m\u001b[34m(a, axis, out, keepdims, initial, where)\u001b[39m\n\u001b[32m     45\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_amin\u001b[39m(a, axis=\u001b[38;5;28;01mNone\u001b[39;00m, out=\u001b[38;5;28;01mNone\u001b[39;00m, keepdims=\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m     46\u001b[39m           initial=_NoValue, where=\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[32m---> \u001b[39m\u001b[32m47\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mumr_minimum\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeepdims\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minitial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwhere\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mTypeError\u001b[39m: '<=' not supported between instances of 'str' and 'int'"
     ]
    }
   ],
   "source": [
    "# Lade die bereinigten Datensätze aus dem Preprocessing\n",
    "print(\"=\" * 60)\n",
    "print(\"LADEN DER BEREINIGTEN DATENSÄTZE\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Lade das kombinierte und bereinigte Dataset\n",
    "print(\"\\nKombiniertes bereinigtes Dataset:\")\n",
    "combined_df = pd.read_csv('data/processed/berlin_housing_combined_clean.csv')\n",
    "print(f\"Zeilen: {combined_df.shape[0]:,}\")\n",
    "print(f\"Spalten: {combined_df.shape[1]}\")\n",
    "print(f\"Spalten: {list(combined_df.columns)}\")\n",
    "\n",
    "# Lade auch die einzelnen bereinigten Datensätze für detaillierte Analyse\n",
    "print(\"\\nEinzelne bereinigte Datensätze:\")\n",
    "\n",
    "# Dataset 2025 bereinigt\n",
    "df_2025 = pd.read_csv('data/processed/dataset_2025_clean.csv')\n",
    "print(f\"Dataset 2025 bereinigt: {df_2025.shape[0]:,} Zeilen, {df_2025.shape[1]} Spalten\")\n",
    "\n",
    "# Dataset 2018-2019 bereinigt\n",
    "df_2018_2019 = pd.read_csv('data/processed/dataset_2018_2019_clean.csv')\n",
    "print(f\"Dataset 2018-2019 bereinigt: {df_2018_2019.shape[0]:,} Zeilen, {df_2018_2019.shape[1]} Spalten\")\n",
    "\n",
    "# Dataset 2022 bereinigt\n",
    "df_2022 = pd.read_csv('data/processed/dataset_2022_clean.csv')\n",
    "print(f\"Dataset 2022 bereinigt: {df_2022.shape[0]:,} Zeilen, {df_2022.shape[1]} Spalten\")\n",
    "\n",
    "# PLZ-Mapping als Referenz\n",
    "plz_mapping_df = pd.read_csv('data/processed/berlin_plz_mapping.csv')\n",
    "print(f\"PLZ-Mapping: {plz_mapping_df.shape[0]:,} Einträge\")\n",
    "\n",
    "print(f\"\\nGesamtdatenpunkte (bereinigt): {combined_df.shape[0]:,}\")\n",
    "print(f\"Verfügbare Bezirke: {combined_df['Bezirk'].nunique()}\")\n",
    "print(f\"Zeitraum: {combined_df['Jahr'].min()} - {combined_df['Jahr'].max()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0eb4242",
   "metadata": {},
   "source": [
    "### 2.2 Datenstruktur und Qualität der bereinigten Daten\n",
    "Analysiere die Struktur und Qualität der bereinigten Datensätze."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d0cfcba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detaillierte Analyse der bereinigten Datensätze\n",
    "print(\"=\" * 80)\n",
    "print(\"DATENQUALITÄTSANALYSE - BEREINIGTE DATENSÄTZE\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Analyse des kombinierten Datasets\n",
    "print(f\"\\n{'='*25} KOMBINIERTES DATASET {'='*25}\")\n",
    "print(f\"Shape: {combined_df.shape}\")\n",
    "print(f\"Memory usage: {combined_df.memory_usage(deep=True).sum() / 1024**2:.2f} MB\")\n",
    "\n",
    "# Fehlende Werte prüfen\n",
    "missing_info = combined_df.isnull().sum()\n",
    "missing_pct = (missing_info / len(combined_df) * 100).round(2)\n",
    "\n",
    "if missing_info.sum() > 0:\n",
    "    print(f\"\\nFehlende Werte:\")\n",
    "    for col in missing_info[missing_info > 0].index:\n",
    "        print(f\"  {col}: {missing_info[col]} ({missing_pct[col]}%)\")\n",
    "else:\n",
    "    print(\"\\nKeine fehlenden Werte gefunden ✓\")\n",
    "\n",
    "# Datentypen\n",
    "print(f\"\\nDatentypen:\")\n",
    "print(combined_df.dtypes.value_counts())\n",
    "\n",
    "# Einzigartige Werte in Schlüsselspalten\n",
    "print(f\"\\nSchlüsselspalten:\")\n",
    "print(f\"  Bezirke: {combined_df['Bezirk'].nunique()} - {sorted(combined_df['Bezirk'].unique())}\")\n",
    "print(f\"  Jahre: {combined_df['Year'].nunique()} - {sorted(combined_df['Year'].unique())}\")\n",
    "print(f\"  Datenquellen: {combined_df['Datenquelle'].nunique()} - {sorted(combined_df['Datenquelle'].unique())}\")\n",
    "\n",
    "# Numerische Spalten Statistik\n",
    "print(f\"\\nNumerische Spalten Statistik:\")\n",
    "numeric_cols = combined_df.select_dtypes(include=[np.number]).columns\n",
    "if len(numeric_cols) > 0:\n",
    "    print(combined_df[numeric_cols].describe())\n",
    "\n",
    "# Analyse der einzelnen bereinigten Datensätze\n",
    "datasets_clean = {\n",
    "    '2025': df_2025,\n",
    "    '2018_2019': df_2018_2019, \n",
    "    '2022': df_2022\n",
    "}\n",
    "\n",
    "for year, df in datasets_clean.items():\n",
    "    print(f\"\\n{'='*20} DATASET {year} (BEREINIGT) {'='*20}\")\n",
    "    print(f\"Shape: {df.shape}\")\n",
    "    print(f\"Spalten: {list(df.columns)}\")\n",
    "    \n",
    "    # Fehlende Werte\n",
    "    missing = df.isnull().sum()\n",
    "    if missing.sum() > 0:\n",
    "        print(f\"Fehlende Werte: {missing[missing > 0].to_dict()}\")\n",
    "    else:\n",
    "        print(\"Keine fehlenden Werte ✓\")\n",
    "    \n",
    "    # Preisstatistik\n",
    "    if 'Price' in df.columns:\n",
    "        print(f\"Preis-Statistik:\")\n",
    "        print(f\"  Min: {df['Price'].min():.2f} €\")\n",
    "        print(f\"  Max: {df['Price'].max():.2f} €\")\n",
    "        print(f\"  Median: {df['Price'].median():.2f} €\")\n",
    "        print(f\"  Mean: {df['Price'].mean():.2f} €\")\n",
    "\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(\"ZUSAMMENFASSUNG DER BEREINIGTEN DATEN\")\n",
    "print(f\"{'='*80}\")\n",
    "print(f\"Kombiniertes Dataset: {combined_df.shape[0]:,} Zeilen, {combined_df.shape[1]} Spalten\")\n",
    "print(f\"Zeitraum: {combined_df['Year'].min()} - {combined_df['Year'].max()}\")\n",
    "print(f\"Bezirke: {combined_df['Bezirk'].nunique()}\")\n",
    "print(f\"Datenquellen: {combined_df['Datenquelle'].nunique()}\")\n",
    "print(f\"Preisspanne: {combined_df['Price'].min():.0f} - {combined_df['Price'].max():.0f} €\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c09965b",
   "metadata": {},
   "source": [
    "## 3. Explorative Datenanalyse (EDA)\n",
    "### 3.1 Zeitliche Entwicklung der Mietpreise\n",
    "\n",
    "Analysiere die Entwicklung der Mietpreise über die verfügbaren Zeiträume hinweg."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06772b9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Zeitliche Entwicklung der Mietpreise analysieren\n",
    "print(\"=\" * 60)\n",
    "print(\"ZEITLICHE ENTWICKLUNG DER MIETPREISE\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Grundlegende Zeitreihenstatistik\n",
    "print(\"\\nPreisstatistik nach Jahren:\")\n",
    "yearly_stats = combined_df.groupby('Jahr')['price'].agg(['count', 'mean', 'median', 'std', 'min', 'max']).round(2)\n",
    "print(yearly_stats)\n",
    "\n",
    "# Durchschnittspreis pro Jahr und Bezirk\n",
    "print(\"\\nDurchschnittspreis pro Jahr und Bezirk (Top 5 Bezirke):\")\n",
    "yearly_district_prices = combined_df.groupby(['Jahr', 'Bezirk'])['price'].mean().round(2)\n",
    "top_districts = combined_df.groupby('Bezirk')['price'].mean().nlargest(5).index\n",
    "\n",
    "for district in top_districts:\n",
    "    district_data = yearly_district_prices[yearly_district_prices.index.get_level_values('Bezirk') == district]\n",
    "    print(f\"\\n{district}:\")\n",
    "    for year, price in district_data.items():\n",
    "        print(f\"  {year[0]}: {price:.2f} €\")\n",
    "\n",
    "# Visualisierung der Preisentwicklung\n",
    "plt.figure(figsize=(15, 10))\n",
    "\n",
    "# Subplot 1: Durchschnittspreis pro Jahr\n",
    "plt.subplot(2, 2, 1)\n",
    "yearly_avg = combined_df.groupby('Jahr')['price'].mean()\n",
    "plt.plot(yearly_avg.index, yearly_avg.values, marker='o', linewidth=2, markersize=8)\n",
    "plt.title('Durchschnittliche Mietpreise über die Jahre', fontsize=14, fontweight='bold')\n",
    "plt.xlabel('Jahr')\n",
    "plt.ylabel('Durchschnittspreis (€)')\n",
    "plt.grid(True, alpha=0.3)\n",
    "for year, price in yearly_avg.items():\n",
    "    plt.annotate(f'{price:.0f}€', (year, price), textcoords=\"offset points\", xytext=(0,10), ha='center')\n",
    "\n",
    "# Subplot 2: Boxplot der Preisverteilung pro Jahr\n",
    "plt.subplot(2, 2, 2)\n",
    "combined_df.boxplot(column='price', by='Jahr', ax=plt.gca())\n",
    "plt.title('Preisverteilung pro Jahr')\n",
    "plt.xlabel('Jahr')\n",
    "plt.ylabel('Preis (€)')\n",
    "plt.suptitle('')  # Entfernt den automatischen Titel\n",
    "\n",
    "# Subplot 3: Anzahl Einträge pro Jahr\n",
    "plt.subplot(2, 2, 3)\n",
    "yearly_counts = combined_df.groupby('Jahr').size()\n",
    "plt.bar(yearly_counts.index, yearly_counts.values, alpha=0.7)\n",
    "plt.title('Anzahl Immobilienangebote pro Jahr')\n",
    "plt.xlabel('Jahr')\n",
    "plt.ylabel('Anzahl Angebote')\n",
    "for year, count in yearly_counts.items():\n",
    "    plt.annotate(f'{count}', (year, count), textcoords=\"offset points\", xytext=(0,5), ha='center')\n",
    "\n",
    "# Subplot 4: Preisentwicklung nach Datenquelle\n",
    "plt.subplot(2, 2, 4)\n",
    "for source in combined_df['Dataset'].unique():\n",
    "    source_data = combined_df[combined_df['Dataset'] == source]\n",
    "    yearly_source_avg = source_data.groupby('Jahr')['price'].mean()\n",
    "    plt.plot(yearly_source_avg.index, yearly_source_avg.values, marker='o', label=source, linewidth=2)\n",
    "\n",
    "plt.title('Preisentwicklung nach Datenquelle')\n",
    "plt.xlabel('Jahr')\n",
    "plt.ylabel('Durchschnittspreis (€)')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Preissteigerungsraten berechnen\n",
    "print(\"\\nPreissteigerungsraten:\")\n",
    "years = sorted(combined_df['Jahr'].unique())\n",
    "for i in range(1, len(years)):\n",
    "    prev_year = years[i-1]\n",
    "    curr_year = years[i]\n",
    "    \n",
    "    prev_price = combined_df[combined_df['Jahr'] == prev_year]['price'].mean()\n",
    "    curr_price = combined_df[combined_df['Jahr'] == curr_year]['price'].mean()\n",
    "    \n",
    "    change_pct = ((curr_price - prev_price) / prev_price) * 100\n",
    "    print(f\"{prev_year} → {curr_year}: {change_pct:+.1f}% ({prev_price:.0f}€ → {curr_price:.0f}€)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c50f0178",
   "metadata": {},
   "source": [
    "### 3.2 Bezirksvergleiche und geografische Analyse\n",
    "Analysiere die Mietpreise nach Berliner Bezirken und identifiziere Trends."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eaf3866",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bezirksvergleiche und geografische Analyse\n",
    "print(\"=\" * 60)\n",
    "print(\"BEZIRKSVERGLEICHE UND GEOGRAFISCHE ANALYSE\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Statistik pro Bezirk\n",
    "print(\"\\nMietpreisstatistik nach Bezirken:\")\n",
    "district_stats = combined_df.groupby('Bezirk')['price'].agg(['count', 'mean', 'median', 'std', 'min', 'max']).round(2)\n",
    "district_stats = district_stats.sort_values('mean', ascending=False)\n",
    "print(district_stats)\n",
    "\n",
    "# Top 10 teuerste und günstigste Bezirke\n",
    "print(\"\\nTop 10 teuerste Bezirke (Durchschnitt):\")\n",
    "top_expensive = district_stats.head(10)\n",
    "for district, stats in top_expensive.iterrows():\n",
    "    print(f\"  {district}: {stats['mean']:.2f} € (Median: {stats['median']:.2f} €, n={stats['count']})\")\n",
    "\n",
    "print(\"\\nTop 10 günstigste Bezirke (Durchschnitt):\")\n",
    "top_cheap = district_stats.tail(10)\n",
    "for district, stats in top_cheap.iterrows():\n",
    "    print(f\"  {district}: {stats['mean']:.2f} € (Median: {stats['median']:.2f} €, n={stats['count']})\")\n",
    "\n",
    "# Visualisierung der Bezirkspreise\n",
    "plt.figure(figsize=(20, 12))\n",
    "\n",
    "# Subplot 1: Durchschnittspreis pro Bezirk (Balkendiagramm)\n",
    "plt.subplot(2, 2, 1)\n",
    "district_avg = combined_df.groupby('Bezirk')['price'].mean().sort_values(ascending=False)\n",
    "bars = plt.bar(range(len(district_avg)), district_avg.values, alpha=0.7)\n",
    "plt.title('Durchschnittliche Mietpreise pro Bezirk', fontsize=14, fontweight='bold')\n",
    "plt.xlabel('Bezirk')\n",
    "plt.ylabel('Durchschnittspreis (€)')\n",
    "plt.xticks(range(len(district_avg)), district_avg.index, rotation=45, ha='right')\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# Farbkodierung nach Preis\n",
    "colors = plt.cm.RdYlBu_r(np.linspace(0, 1, len(bars)))\n",
    "for bar, color in zip(bars, colors):\n",
    "    bar.set_color(color)\n",
    "\n",
    "# Subplot 2: Boxplot der Preisverteilung pro Bezirk\n",
    "plt.subplot(2, 2, 2)\n",
    "combined_df.boxplot(column='price', by='Bezirk', ax=plt.gca(), rot=45)\n",
    "plt.title('Preisverteilung pro Bezirk')\n",
    "plt.xlabel('Bezirk')\n",
    "plt.ylabel('Preis (€)')\n",
    "plt.suptitle('')  # Entfernt den automatischen Titel\n",
    "\n",
    "# Subplot 3: Anzahl Angebote pro Bezirk\n",
    "plt.subplot(2, 2, 3)\n",
    "district_counts = combined_df.groupby('Bezirk').size().sort_values(ascending=False)\n",
    "plt.bar(range(len(district_counts)), district_counts.values, alpha=0.7)\n",
    "plt.title('Anzahl Immobilienangebote pro Bezirk')\n",
    "plt.xlabel('Bezirk')\n",
    "plt.ylabel('Anzahl Angebote')\n",
    "plt.xticks(range(len(district_counts)), district_counts.index, rotation=45, ha='right')\n",
    "\n",
    "# Subplot 4: Preisentwicklung der Top 6 Bezirke über die Jahre\n",
    "plt.subplot(2, 2, 4)\n",
    "top_6_districts = district_avg.head(6).index\n",
    "\n",
    "for district in top_6_districts:\n",
    "    district_data = combined_df[combined_df['Bezirk'] == district]\n",
    "    yearly_district_avg = district_data.groupby('Jahr')['price'].mean()\n",
    "    plt.plot(yearly_district_avg.index, yearly_district_avg.values, marker='o', label=district, linewidth=2)\n",
    "\n",
    "plt.title('Preisentwicklung Top 6 Bezirke')\n",
    "plt.xlabel('Jahr')\n",
    "plt.ylabel('Durchschnittspreis (€)')\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Statistische Signifikanz zwischen Bezirken testen\n",
    "print(\"\\nStatistische Signifikanz zwischen teuersten und günstigsten Bezirken:\")\n",
    "expensive_district = district_avg.index[0]\n",
    "cheap_district = district_avg.index[-1]\n",
    "\n",
    "expensive_prices = combined_df[combined_df['Bezirk'] == expensive_district]['price']\n",
    "cheap_prices = combined_df[combined_df['Bezirk'] == cheap_district]['price']\n",
    "\n",
    "t_stat, p_value = stats.ttest_ind(expensive_prices, cheap_prices)\n",
    "print(f\"T-Test zwischen {expensive_district} und {cheap_district}:\")\n",
    "print(f\"  T-Statistik: {t_stat:.3f}\")\n",
    "print(f\"  P-Wert: {p_value:.6f}\")\n",
    "print(f\"  Signifikant (p < 0.05): {'Ja' if p_value < 0.05 else 'Nein'}\")\n",
    "\n",
    "# Korrelationsanalyse\n",
    "print(\"\\nKorrelationsanalyse numerischer Variablen:\")\n",
    "numeric_columns = combined_df.select_dtypes(include=[np.number]).columns\n",
    "if len(numeric_columns) > 1:\n",
    "    correlation_matrix = combined_df[numeric_columns].corr()\n",
    "    print(correlation_matrix.round(3))\n",
    "    \n",
    "    # Heatmap der Korrelationen\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', center=0, \n",
    "                square=True, fmt='.2f', cbar_kws={'label': 'Korrelation'})\n",
    "    plt.title('Korrelationsmatrix numerischer Variablen')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"Nicht genügend numerische Variablen für Korrelationsanalyse\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f643133a",
   "metadata": {},
   "source": [
    "### 3.3 Wohnungsgrößen und Preis-pro-Quadratmeter-Analyse\n",
    "Analysiere die Beziehung zwischen Wohnungsgröße und Mietpreis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57b95be5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wohnungsgrößen und Preis-pro-Quadratmeter-Analyse\n",
    "print(\"=\" * 60)\n",
    "print(\"WOHNUNGSGRÖSSENS- UND PREIS-PRO-QUADRATMETER-ANALYSE\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Prüfe welche Spalten für Größenanalyse verfügbar sind\n",
    "print(\"Verfügbare Spalten für Größenanalyse:\")\n",
    "size_columns = [col for col in combined_df.columns if any(keyword in col.lower() for keyword in ['size', 'größe', 'sqm', 'm2', 'area', 'fläche'])]\n",
    "print(f\"Größen-relevante Spalten: {size_columns}\")\n",
    "\n",
    "# Prüfe ob Preis-pro-Quadratmeter bereits berechnet wurde\n",
    "price_per_sqm_columns = [col for col in combined_df.columns if any(keyword in col.lower() for keyword in ['price_per_sqm', 'preis_pro_m2', 'qm_preis'])]\n",
    "print(f\"Preis-pro-Quadratmeter Spalten: {price_per_sqm_columns}\")\n",
    "\n",
    "# Analysiere verfügbare Größendaten\n",
    "if size_columns:\n",
    "    for col in size_columns:\n",
    "        print(f\"\\nAnalyse von {col}:\")\n",
    "        non_null_count = combined_df[col].notna().sum()\n",
    "        print(f\"  Verfügbare Werte: {non_null_count}/{len(combined_df)} ({non_null_count/len(combined_df)*100:.1f}%)\")\n",
    "        \n",
    "        if non_null_count > 0:\n",
    "            print(f\"  Statistik: Min={combined_df[col].min():.1f}, Max={combined_df[col].max():.1f}, Median={combined_df[col].median():.1f}\")\n",
    "            \n",
    "            # Visualisierung der Größenverteilung\n",
    "            plt.figure(figsize=(12, 4))\n",
    "            \n",
    "            plt.subplot(1, 2, 1)\n",
    "            plt.hist(combined_df[col].dropna(), bins=30, alpha=0.7, edgecolor='black')\n",
    "            plt.title(f'Verteilung von {col}')\n",
    "            plt.xlabel(col)\n",
    "            plt.ylabel('Häufigkeit')\n",
    "            \n",
    "            plt.subplot(1, 2, 2)\n",
    "            plt.boxplot(combined_df[col].dropna())\n",
    "            plt.title(f'Boxplot von {col}')\n",
    "            plt.ylabel(col)\n",
    "            \n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "\n",
    "# Preis-pro-Quadratmeter-Analyse falls verfügbar\n",
    "if price_per_sqm_columns:\n",
    "    for col in price_per_sqm_columns:\n",
    "        print(f\"\\nAnalyse von {col}:\")\n",
    "        non_null_count = combined_df[col].notna().sum()\n",
    "        print(f\"  Verfügbare Werte: {non_null_count}/{len(combined_df)} ({non_null_count/len(combined_df)*100:.1f}%)\")\n",
    "        \n",
    "        if non_null_count > 0:\n",
    "            print(f\"  Statistik: Min={combined_df[col].min():.2f}€, Max={combined_df[col].max():.2f}€, Median={combined_df[col].median():.2f}€\")\n",
    "            \n",
    "            # Preis-pro-Quadratmeter nach Bezirk\n",
    "            print(f\"\\nDurchschnittlicher {col} nach Bezirk:\")\n",
    "            price_per_sqm_by_district = combined_df.groupby('Bezirk')[col].mean().sort_values(ascending=False)\n",
    "            for district, price in price_per_sqm_by_district.head(10).items():\n",
    "                print(f\"  {district}: {price:.2f} €/m²\")\n",
    "            \n",
    "            # Visualisierung\n",
    "            plt.figure(figsize=(15, 10))\n",
    "            \n",
    "            # Subplot 1: Preis-pro-Quadratmeter Verteilung\n",
    "            plt.subplot(2, 2, 1)\n",
    "            plt.hist(combined_df[col].dropna(), bins=30, alpha=0.7, edgecolor='black')\n",
    "            plt.title(f'Verteilung von {col}')\n",
    "            plt.xlabel(f'{col} (€/m²)')\n",
    "            plt.ylabel('Häufigkeit')\n",
    "            \n",
    "            # Subplot 2: Preis-pro-Quadratmeter nach Bezirk\n",
    "            plt.subplot(2, 2, 2)\n",
    "            district_prices = combined_df.groupby('Bezirk')[col].mean().sort_values(ascending=False)\n",
    "            plt.bar(range(len(district_prices)), district_prices.values, alpha=0.7)\n",
    "            plt.title(f'Durchschnittlicher {col} nach Bezirk')\n",
    "            plt.xlabel('Bezirk')\n",
    "            plt.ylabel(f'{col} (€/m²)')\n",
    "            plt.xticks(range(len(district_prices)), district_prices.index, rotation=45, ha='right')\n",
    "            \n",
    "            # Subplot 3: Preis-pro-Quadratmeter über die Jahre\n",
    "            plt.subplot(2, 2, 3)\n",
    "            yearly_price_per_sqm = combined_df.groupby('Year')[col].mean()\n",
    "            plt.plot(yearly_price_per_sqm.index, yearly_price_per_sqm.values, marker='o', linewidth=2)\n",
    "            plt.title(f'Entwicklung von {col} über die Jahre')\n",
    "            plt.xlabel('Jahr')\n",
    "            plt.ylabel(f'{col} (€/m²)')\n",
    "            plt.grid(True, alpha=0.3)\n",
    "            \n",
    "            # Subplot 4: Boxplot nach Jahren\n",
    "            plt.subplot(2, 2, 4)\n",
    "            combined_df.boxplot(column=col, by='Year', ax=plt.gca())\n",
    "            plt.title(f'{col} Verteilung nach Jahren')\n",
    "            plt.xlabel('Jahr')\n",
    "            plt.ylabel(f'{col} (€/m²)')\n",
    "            plt.suptitle('')\n",
    "            \n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "\n",
    "# Korrelation zwischen Größe und Preis analysieren\n",
    "if size_columns and 'price' in combined_df.columns:\n",
    "    print(\"\\nKorrelation zwischen Wohnungsgröße und Gesamtpreis:\")\n",
    "    \n",
    "    for size_col in size_columns:\n",
    "        # Nur Zeilen mit beiden Werten\n",
    "        subset = combined_df[[size_col, 'price']].dropna()\n",
    "        \n",
    "        if len(subset) > 10:  # Mindestens 10 Datenpunkte\n",
    "            correlation = subset[size_col].corr(subset['price'])\n",
    "            print(f\"  {size_col} vs. price: {correlation:.3f}\")\n",
    "            \n",
    "            # Streudiagramm\n",
    "            plt.figure(figsize=(10, 6))\n",
    "            plt.scatter(subset[size_col], subset['price'], alpha=0.6)\n",
    "            plt.xlabel(f'{size_col}')\n",
    "            plt.ylabel('Price (€)')\n",
    "            plt.title(f'Korrelation: {size_col} vs. Preis (r={correlation:.3f})')\n",
    "            \n",
    "            # Trendlinie hinzufügen\n",
    "            z = np.polyfit(subset[size_col], subset['price'], 1)\n",
    "            p = np.poly1d(z)\n",
    "            plt.plot(subset[size_col], p(subset[size_col]), \"r--\", alpha=0.8)\n",
    "            \n",
    "            plt.grid(True, alpha=0.3)\n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "\n",
    "# Zusammenfassung der Größenanalyse\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"ZUSAMMENFASSUNG DER GRÖSSENANALYSE\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "if size_columns:\n",
    "    print(f\"Verfügbare Größeninformationen: {len(size_columns)} Spalten\")\n",
    "    for col in size_columns:\n",
    "        coverage = combined_df[col].notna().sum() / len(combined_df) * 100\n",
    "        print(f\"  {col}: {coverage:.1f}% Abdeckung\")\n",
    "else:\n",
    "    print(\"Keine Größeninformationen verfügbar\")\n",
    "\n",
    "if price_per_sqm_columns:\n",
    "    print(f\"Verfügbare Preis-pro-Quadratmeter-Informationen: {len(price_per_sqm_columns)} Spalten\")\n",
    "    for col in price_per_sqm_columns:\n",
    "        coverage = combined_df[col].notna().sum() / len(combined_df) * 100\n",
    "        print(f\"  {col}: {coverage:.1f}% Abdeckung\")\n",
    "else:\n",
    "    print(\"Keine Preis-pro-Quadratmeter-Informationen verfügbar\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
