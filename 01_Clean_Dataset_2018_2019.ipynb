{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a70f42e6",
   "metadata": {},
   "source": [
    "# Dataset 2018-2019 Bereinigung und Normalisierung\n",
    "## Spezialisiertes Modul f√ºr Kaggle/Immobilienscout24 Dataset\n",
    "\n",
    "### Ziel\n",
    "Bereinigung und Normalisierung des historischen Datasets (2018-2019) in ein standardisiertes Format f√ºr die gemeinsame Analyse.\n",
    "\n",
    "### Input\n",
    "- `data/raw/Dataset_2018_2019.csv`\n",
    "\n",
    "### Output\n",
    "- `data/processed/dataset_2018_2019_normalized.csv`\n",
    "\n",
    "### Standardisierte Ausgabespalten\n",
    "- `price`: Normalisierter Preis (Kaltmiete in ‚Ç¨)\n",
    "- `size`: Normalisierte Gr√∂√üe (m¬≤)\n",
    "- `district`: Berliner Bezirk (standardisiert)\n",
    "- `rooms`: Anzahl Zimmer\n",
    "- `year`: Jahr des Datasets (2019)\n",
    "- `dataset_id`: Eindeutige Dataset-Kennzeichnung (historical)\n",
    "- `source`: Datenquelle\n",
    "\n",
    "---\n",
    "**Teil der modularen Preprocessing-Pipeline**  \n",
    "**Datum:** 4. Juli 2025  \n",
    "**Version:** 1.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed9ef7a1",
   "metadata": {},
   "source": [
    "## 1. Import Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f3a55584",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bibliotheken erfolgreich importiert!\n",
      "Pandas Version: 2.3.0\n",
      "Dataset: 2018-2019 (Kaggle/Immobilienscout24)\n"
     ]
    }
   ],
   "source": [
    "# Import required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Display configuration\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', 1000)\n",
    "pd.set_option('display.max_rows', 20)\n",
    "\n",
    "print(\"Bibliotheken erfolgreich importiert!\")\n",
    "print(f\"Pandas Version: {pd.__version__}\")\n",
    "print(f\"Dataset: 2018-2019 (Kaggle/Immobilienscout24)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a8e7e8f",
   "metadata": {},
   "source": [
    "## 2. Daten laden und erste Analyse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ee850b4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "DATASET 2018-2019 LADEN UND ANALYSIEREN\n",
      "============================================================\n",
      "Dataset geladen: 10,406 Zeilen, 9 Spalten\n",
      "\n",
      "Spalten: ['regio3', 'street', 'livingSpace', 'baseRent', 'totalRent', 'noRooms', 'floor', 'typeOfFlat', 'yearConstructed']\n",
      "\n",
      "Datentypen:\n",
      "regio3              object\n",
      "street              object\n",
      "livingSpace        float64\n",
      "baseRent           float64\n",
      "totalRent          float64\n",
      "noRooms            float64\n",
      "floor              float64\n",
      "typeOfFlat          object\n",
      "yearConstructed    float64\n",
      "dtype: object\n",
      "\n",
      "Fehlende Werte:\n",
      "  totalRent: 662 (6.36%)\n",
      "  floor: 1100 (10.57%)\n",
      "  typeOfFlat: 804 (7.73%)\n",
      "  yearConstructed: 1425 (13.69%)\n",
      "\n",
      "Erste 5 Zeilen:\n",
      "            regio3                      street  livingSpace  baseRent  totalRent  noRooms  floor    typeOfFlat  yearConstructed\n",
      "0  Staaken_Spandau           Metropolitan Park        77.00    820.00    1140.00      3.0    0.0  ground_floor              NaN\n",
      "1        Wei√üensee      B&ouml;rnestra&szlig;e        62.63    808.00     955.00      2.0    0.0  ground_floor           1918.0\n",
      "2            Mitte  Stallschreiberstra&szlig;e        46.40   1150.00    1300.00      2.0    3.0     apartment           2019.0\n",
      "3        Kreuzberg      Hallesche Stra&szlig;e        67.00   1200.00    1428.78      2.5    6.0     apartment           2017.0\n",
      "4       Tiergarten           Heidestra&szlig;e        73.54   1338.43    1559.05      2.0    0.0  ground_floor           2019.0\n"
     ]
    }
   ],
   "source": [
    "# Lade Dataset 2018-2019\n",
    "print(\"=\" * 60)\n",
    "print(\"DATASET 2018-2019 LADEN UND ANALYSIEREN\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Lade Rohdaten\n",
    "df_raw = pd.read_csv('data/raw/Dataset_2018_2019.csv')\n",
    "print(f\"Dataset geladen: {df_raw.shape[0]:,} Zeilen, {df_raw.shape[1]} Spalten\")\n",
    "\n",
    "# Grundlegende Informationen\n",
    "print(f\"\\nSpalten: {list(df_raw.columns)}\")\n",
    "print(f\"\\nDatentypen:\")\n",
    "print(df_raw.dtypes)\n",
    "\n",
    "# Fehlende Werte\n",
    "print(f\"\\nFehlende Werte:\")\n",
    "missing_values = df_raw.isnull().sum()\n",
    "missing_pct = (missing_values / len(df_raw) * 100).round(2)\n",
    "for col in missing_values[missing_values > 0].index:\n",
    "    print(f\"  {col}: {missing_values[col]} ({missing_pct[col]}%)\")\n",
    "\n",
    "# Erste 5 Zeilen\n",
    "print(f\"\\nErste 5 Zeilen:\")\n",
    "print(df_raw.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9fadae8",
   "metadata": {},
   "source": [
    "## 3. Spezifische Bereinigung Dataset 2018-2019"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0f6ec445",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "SPEZIFISCHE BEREINIGUNG DATASET 2018-2019\n",
      "============================================================\n",
      "Arbeitskopie erstellt: 10406 Zeilen\n",
      "\n",
      "=== PREIS-BEREINIGUNG ===\n",
      "baseRent - Statistik vor Bereinigung:\n",
      "  Typ: float64\n",
      "  Nicht-null Werte: 10406\n",
      "  Min: 0.0, Max: 20000.0\n",
      "Entfernte unrealistische Preise: 11\n",
      "\n",
      "=== GR√ñSSEN-BEREINIGUNG ===\n",
      "livingSpace - Statistik vor Bereinigung:\n",
      "  Typ: float64\n",
      "  Nicht-null Werte: 10395\n",
      "  Min: 3.0, Max: 542.53\n",
      "Entfernte unrealistische Gr√∂√üen: 7\n",
      "\n",
      "=== BEZIRKS-NORMALISIERUNG ===\n",
      "regio3 - Einzigartige Werte: 79\n",
      "Bezirke: ['Adlershof_Treptow', 'Alt_Hohensch√∂nhausen_Hohensch√∂nhausen', 'Altglienicke_Treptow', 'Baumschulenweg_Treptow', 'Biesdorf_Marzahn', 'Blankenburg_Wei√üensee', 'Bohnsdorf_Treptow', 'Britz_Neuk√∂lln', 'Buch_Pankow', 'Buckow_Neuk√∂lln', 'Charlottenburg', 'Dahlem_Zehlendorf', 'Falkenberg_Hohensch√∂nhausen', 'Franz√∂sisch_Buchholz_Pankow', 'Friedenau_Sch√∂neberg', 'Friedrichsfelde_Lichtenberg', 'Friedrichshagen_K√∂penick', 'Friedrichshain', 'Frohnau_Reinickendorf', 'Gatow_Spandau', 'Grunewald_Wilmersdorf', 'Gr√ºnau_K√∂penick', 'Haselhorst_Spandau', 'Heiligensee_Reinickendorf', 'Heinersdorf_Wei√üensee', 'Hellersdorf', 'Hermsdorf_Reinickendorf', 'Johannisthal_Treptow', 'Karlshorst_Lichtenberg', 'Karow_Wei√üensee', 'Kaulsdorf_Hellersdorf', 'Kladow_Spandau', 'Konradsh√∂he_Reinickendorf', 'Kreuzberg', 'K√∂penick', 'Lankwitz_Steglitz', 'Lichtenberg', 'Lichtenrade_Tempelhof', 'Lichterfelde_Steglitz', 'L√ºbars_Reinickendorf', 'Mahlsdorf_Hellersdorf', 'Malchow_Hohensch√∂nhausen', 'Mariendorf_Tempelhof', 'Marienfelde_Tempelhof', 'Marzahn', 'Mitte', 'M√ºggelheim_K√∂penick', 'Neu_Hohensch√∂nhausen_Hohensch√∂nhausen', 'Neuk√∂lln', 'Niedersch√∂neweide_Treptow', 'Niedersch√∂nhausen_Pankow', 'Nikolassee_Zehlendorf', 'Obersch√∂neweide_K√∂penick', 'Pankow', 'Pl√§nterwald_Treptow', 'Prenzlauer_Berg_Prenzlauer_Berg', 'Rahnsdorf_K√∂penick', 'Reinickendorf', 'Rosenthal_Pankow', 'Rudow_Neuk√∂lln', 'Rummelsburg_Lichtenberg', 'Schmargendorf_Wilmersdorf', 'Schm√∂ckwitz_K√∂penick', 'Sch√∂neberg', 'Siemensstadt_Spandau', 'Spandau', 'Staaken_Spandau', 'Steglitz', 'Tegel_Reinickendorf', 'Tempelhof', 'Tiergarten', 'Treptow', 'Waidmannslust_Reinickendorf', 'Wannsee_Zehlendorf', 'Wedding', 'Wei√üensee', 'Wilmersdorf', 'Wittenau_Reinickendorf', 'Zehlendorf']\n",
      "Normalisierte Bezirke: ['Adlershof', 'Alt', 'Altglienicke', 'Baumschulenweg', 'Biesdorf', 'Blankenburg', 'Bohnsdorf', 'Britz', 'Buch', 'Buckow', 'Charlottenburg', 'Dahlem', 'Falkenberg', 'Franz√∂sisch', 'Friedenau', 'Friedrichsfelde', 'Friedrichshagen', 'Friedrichshain', 'Frohnau', 'Gatow', 'Grunewald', 'Gr√ºnau', 'Haselhorst', 'Heiligensee', 'Heinersdorf', 'Hellersdorf', 'Hermsdorf', 'Johannisthal', 'Karlshorst', 'Karow', 'Kaulsdorf', 'Kladow', 'Konradsh√∂he', 'Kreuzberg', 'K√∂penick', 'Lankwitz', 'Lichtenberg', 'Lichtenrade', 'Lichterfelde', 'L√ºbars', 'Mahlsdorf', 'Malchow', 'Mariendorf', 'Marienfelde', 'Marzahn', 'Mitte', 'M√ºggelheim', 'Neu', 'Neuk√∂lln', 'Niedersch√∂neweide', 'Niedersch√∂nhausen', 'Nikolassee', 'Obersch√∂neweide', 'Pankow', 'Pl√§nterwald', 'Prenzlauer', 'Rahnsdorf', 'Reinickendorf', 'Rosenthal', 'Rudow', 'Rummelsburg', 'Schmargendorf', 'Schm√∂ckwitz', 'Sch√∂neberg', 'Siemensstadt', 'Spandau', 'Staaken', 'Steglitz', 'Tegel', 'Tempelhof', 'Tiergarten', 'Treptow', 'Waidmannslust', 'Wannsee', 'Wedding', 'Wei√üensee', 'Wilmersdorf', 'Wittenau', 'Zehlendorf']\n",
      "Anzahl normalisierte Bezirke: 79\n",
      "\n",
      "=== ZIMMER-BEREINIGUNG ===\n",
      "noRooms - Statistik:\n",
      "  Typ: float64\n",
      "  Nicht-null Werte: 10388\n",
      "  Einzigartige Werte: [np.float64(1.0), np.float64(1.1), np.float64(1.5), np.float64(2.0), np.float64(2.1), np.float64(2.2), np.float64(2.5), np.float64(3.0), np.float64(3.5), np.float64(4.0), np.float64(4.5), np.float64(5.0), np.float64(5.5), np.float64(6.0), np.float64(6.5), np.float64(7.0), np.float64(7.5), np.float64(8.0), np.float64(8.5), np.float64(9.0), np.float64(10.0), np.float64(11.0)]\n",
      "Entfernte unrealistische Zimmeranzahlen: 1\n",
      "\n",
      "‚úÖ Spezifische Bereinigung abgeschlossen\n",
      "Verbleibende Datens√§tze: 10387 (Verlust: 19)\n"
     ]
    }
   ],
   "source": [
    "# Spezifische Bereinigung f√ºr Dataset 2018-2019\n",
    "print(\"=\" * 60)\n",
    "print(\"SPEZIFISCHE BEREINIGUNG DATASET 2018-2019\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Erstelle Arbeitskopie\n",
    "df = df_raw.copy()\n",
    "print(f\"Arbeitskopie erstellt: {len(df)} Zeilen\")\n",
    "\n",
    "# 1. Preis-Bereinigung (baseRent)\n",
    "print(f\"\\n=== PREIS-BEREINIGUNG ===\")\n",
    "print(f\"baseRent - Statistik vor Bereinigung:\")\n",
    "print(f\"  Typ: {df['baseRent'].dtype}\")\n",
    "print(f\"  Nicht-null Werte: {df['baseRent'].notna().sum()}\")\n",
    "print(f\"  Min: {df['baseRent'].min()}, Max: {df['baseRent'].max()}\")\n",
    "\n",
    "# Preis ist bereits numerisch, nur Plausibilit√§tspr√ºfung\n",
    "# Entferne unrealistische Preise (< 100‚Ç¨ oder > 10.000‚Ç¨)\n",
    "original_count = len(df)\n",
    "df = df[(df['baseRent'] >= 100) & (df['baseRent'] <= 10000)]\n",
    "removed_price = original_count - len(df)\n",
    "print(f\"Entfernte unrealistische Preise: {removed_price}\")\n",
    "\n",
    "# 2. Gr√∂√üen-Bereinigung (livingSpace)\n",
    "print(f\"\\n=== GR√ñSSEN-BEREINIGUNG ===\")\n",
    "print(f\"livingSpace - Statistik vor Bereinigung:\")\n",
    "print(f\"  Typ: {df['livingSpace'].dtype}\")\n",
    "print(f\"  Nicht-null Werte: {df['livingSpace'].notna().sum()}\")\n",
    "print(f\"  Min: {df['livingSpace'].min()}, Max: {df['livingSpace'].max()}\")\n",
    "\n",
    "# Gr√∂√üe ist bereits numerisch, nur Plausibilit√§tspr√ºfung\n",
    "# Entferne unrealistische Gr√∂√üen (< 10m¬≤ oder > 500m¬≤)\n",
    "original_count = len(df)\n",
    "df = df[(df['livingSpace'] >= 10) & (df['livingSpace'] <= 500)]\n",
    "removed_size = original_count - len(df)\n",
    "print(f\"Entfernte unrealistische Gr√∂√üen: {removed_size}\")\n",
    "\n",
    "# 3. Bezirks-Normalisierung (regio3)\n",
    "print(f\"\\n=== BEZIRKS-NORMALISIERUNG ===\")\n",
    "print(f\"regio3 - Einzigartige Werte: {df['regio3'].nunique()}\")\n",
    "print(f\"Bezirke: {sorted(df['regio3'].unique())}\")\n",
    "\n",
    "# Bezirk-Normalisierung (entferne _Suffix)\n",
    "def normalize_district_2018_2019(district):\n",
    "    \"\"\"Normalisiert Bezirksnamen f√ºr Dataset 2018-2019\"\"\"\n",
    "    if pd.isna(district):\n",
    "        return None\n",
    "    \n",
    "    # Entferne Suffix nach Unterstrich\n",
    "    if '_' in str(district):\n",
    "        return str(district).split('_')[0]\n",
    "    \n",
    "    return str(district)\n",
    "\n",
    "df['district_normalized'] = df['regio3'].apply(normalize_district_2018_2019)\n",
    "\n",
    "print(f\"Normalisierte Bezirke: {sorted(df['district_normalized'].unique())}\")\n",
    "print(f\"Anzahl normalisierte Bezirke: {df['district_normalized'].nunique()}\")\n",
    "\n",
    "# 4. Zimmer-Bereinigung (noRooms)\n",
    "print(f\"\\n=== ZIMMER-BEREINIGUNG ===\")\n",
    "print(f\"noRooms - Statistik:\")\n",
    "print(f\"  Typ: {df['noRooms'].dtype}\")\n",
    "print(f\"  Nicht-null Werte: {df['noRooms'].notna().sum()}\")\n",
    "print(f\"  Einzigartige Werte: {sorted(df['noRooms'].dropna().unique())}\")\n",
    "\n",
    "# Zimmeranzahl ist bereits numerisch\n",
    "# Plausibilit√§tspr√ºfung (0.5 bis 10 Zimmer)\n",
    "original_count = len(df)\n",
    "df = df[(df['noRooms'] >= 0.5) & (df['noRooms'] <= 10)]\n",
    "removed_rooms = original_count - len(df)\n",
    "print(f\"Entfernte unrealistische Zimmeranzahlen: {removed_rooms}\")\n",
    "\n",
    "print(f\"\\n‚úÖ Spezifische Bereinigung abgeschlossen\")\n",
    "print(f\"Verbleibende Datens√§tze: {len(df)} (Verlust: {len(df_raw) - len(df)})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47813a15",
   "metadata": {},
   "source": [
    "## 4. Normalisierung in Standardformat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "86dc1e36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "NORMALISIERUNG IN STANDARDFORMAT\n",
      "============================================================\n",
      "Normalisiertes Dataset erstellt: 10387 Zeilen\n",
      "Standardspalten: ['price', 'size', 'district', 'rooms', 'year', 'dataset_id', 'source']\n",
      "Zus√§tzliche Spalten: ['street', 'floor', 'typeOfFlat', 'yearConstructed', 'totalRent']\n",
      "\n",
      "=== DATENQUALIT√ÑT NORMALISIERTES DATASET ===\n",
      "Zeilen mit Preis: 10387\n",
      "Zeilen mit Gr√∂√üe: 10387\n",
      "Zeilen mit Bezirk: 10387\n",
      "Zeilen mit Zimmeranzahl: 10387\n",
      "\n",
      "=== STATISTIKEN ===\n",
      "Preis - Min: 178.16‚Ç¨, Max: 9500.00‚Ç¨, Median: 945.00‚Ç¨\n",
      "Gr√∂√üe - Min: 10.0m¬≤, Max: 482.0m¬≤, Median: 72.0m¬≤\n",
      "Zimmer - Min: 1.0, Max: 10.0, Median: 2.0\n",
      "\n",
      "=== BEZIRKSVERTEILUNG ===\n",
      "Anzahl Bezirke: 79\n",
      "  Mitte: 799 Eintr√§ge\n",
      "  Tiergarten: 768 Eintr√§ge\n",
      "  Charlottenburg: 701 Eintr√§ge\n",
      "  Friedrichshain: 553 Eintr√§ge\n",
      "  Prenzlauer: 473 Eintr√§ge\n",
      "  Spandau: 415 Eintr√§ge\n",
      "  Wedding: 397 Eintr√§ge\n",
      "  Wilmersdorf: 370 Eintr√§ge\n",
      "  Neuk√∂lln: 361 Eintr√§ge\n",
      "  K√∂penick: 351 Eintr√§ge\n",
      "\n",
      "‚úÖ Normalisierung abgeschlossen!\n"
     ]
    }
   ],
   "source": [
    "# Normalisierung in Standardformat\n",
    "print(\"=\" * 60)\n",
    "print(\"NORMALISIERUNG IN STANDARDFORMAT\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Erstelle normalisiertes Dataset mit Standardspalten\n",
    "df_normalized = pd.DataFrame()\n",
    "\n",
    "# Standardspalten zuweisen\n",
    "df_normalized['price'] = df['baseRent'].astype('float64')\n",
    "df_normalized['size'] = df['livingSpace'].astype('float64')\n",
    "df_normalized['district'] = df['district_normalized'].astype('string')\n",
    "df_normalized['rooms'] = df['noRooms'].astype('float64')\n",
    "df_normalized['year'] = 2019\n",
    "df_normalized['dataset_id'] = 'historical'\n",
    "df_normalized['source'] = 'Kaggle/Immobilienscout24'\n",
    "\n",
    "# Zus√§tzliche Spalten aus Original-Dataset beibehalten\n",
    "df_normalized['street'] = df['street']\n",
    "df_normalized['floor'] = df['floor']\n",
    "df_normalized['typeOfFlat'] = df['typeOfFlat']\n",
    "df_normalized['yearConstructed'] = df['yearConstructed']\n",
    "df_normalized['totalRent'] = df['totalRent']\n",
    "\n",
    "print(f\"Normalisiertes Dataset erstellt: {len(df_normalized)} Zeilen\")\n",
    "print(f\"Standardspalten: {['price', 'size', 'district', 'rooms', 'year', 'dataset_id', 'source']}\")\n",
    "print(f\"Zus√§tzliche Spalten: {list(df_normalized.columns[7:])}\")\n",
    "\n",
    "# Datenqualit√§t pr√ºfen\n",
    "print(f\"\\n=== DATENQUALIT√ÑT NORMALISIERTES DATASET ===\")\n",
    "print(f\"Zeilen mit Preis: {df_normalized['price'].notna().sum()}\")\n",
    "print(f\"Zeilen mit Gr√∂√üe: {df_normalized['size'].notna().sum()}\")\n",
    "print(f\"Zeilen mit Bezirk: {df_normalized['district'].notna().sum()}\")\n",
    "print(f\"Zeilen mit Zimmeranzahl: {df_normalized['rooms'].notna().sum()}\")\n",
    "\n",
    "# Statistiken\n",
    "print(f\"\\n=== STATISTIKEN ===\")\n",
    "print(f\"Preis - Min: {df_normalized['price'].min():.2f}‚Ç¨, Max: {df_normalized['price'].max():.2f}‚Ç¨, Median: {df_normalized['price'].median():.2f}‚Ç¨\")\n",
    "print(f\"Gr√∂√üe - Min: {df_normalized['size'].min():.1f}m¬≤, Max: {df_normalized['size'].max():.1f}m¬≤, Median: {df_normalized['size'].median():.1f}m¬≤\")\n",
    "print(f\"Zimmer - Min: {df_normalized['rooms'].min():.1f}, Max: {df_normalized['rooms'].max():.1f}, Median: {df_normalized['rooms'].median():.1f}\")\n",
    "\n",
    "# Bezirksverteilung\n",
    "print(f\"\\n=== BEZIRKSVERTEILUNG ===\")\n",
    "district_counts = df_normalized['district'].value_counts()\n",
    "print(f\"Anzahl Bezirke: {len(district_counts)}\")\n",
    "for district, count in district_counts.head(10).items():\n",
    "    print(f\"  {district}: {count} Eintr√§ge\")\n",
    "\n",
    "print(f\"\\n‚úÖ Normalisierung abgeschlossen!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7db94d3",
   "metadata": {},
   "source": [
    "## 5. Export des normalisierten Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c728c108",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "EXPORT NORMALISIERTES DATASET\n",
      "============================================================\n",
      "‚úÖ Normalisiertes Dataset exportiert: data/processed/dataset_2018_2019_normalized.csv\n",
      "Dateigr√∂√üe: 10387 Zeilen x 12 Spalten\n",
      "‚úÖ Export-Validierung erfolgreich: 10387 Zeilen geladen\n",
      "\n",
      "=== ZUSAMMENFASSUNG DATASET 2018-2019 ===\n",
      "Input: data/raw/Dataset_2018_2019.csv (10406 Zeilen)\n",
      "Output: data/processed/dataset_2018_2019_normalized.csv (10387 Zeilen)\n",
      "Datenverlust: 19 Zeilen (0.2%)\n",
      "Standardisierte Spalten: price, size, district, rooms, year, dataset_id, source\n",
      "Zus√§tzliche Spalten: 5\n",
      "\n",
      "üéØ DATASET 2018-2019 BEREINIGUNG ABGESCHLOSSEN!\n",
      "Bereit f√ºr Kombination mit anderen normalisierten Datasets.\n"
     ]
    }
   ],
   "source": [
    "# Export des normalisierten Datasets\n",
    "print(\"=\" * 60)\n",
    "print(\"EXPORT NORMALISIERTES DATASET\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Ausgabedatei\n",
    "output_file = 'data/processed/dataset_2018_2019_normalized.csv'\n",
    "\n",
    "# Export\n",
    "df_normalized.to_csv(output_file, index=False)\n",
    "print(f\"‚úÖ Normalisiertes Dataset exportiert: {output_file}\")\n",
    "print(f\"Dateigr√∂√üe: {len(df_normalized)} Zeilen x {len(df_normalized.columns)} Spalten\")\n",
    "\n",
    "# Validierung des Exports\n",
    "test_load = pd.read_csv(output_file)\n",
    "print(f\"‚úÖ Export-Validierung erfolgreich: {len(test_load)} Zeilen geladen\")\n",
    "\n",
    "# Zusammenfassung\n",
    "print(f\"\\n=== ZUSAMMENFASSUNG DATASET 2018-2019 ===\")\n",
    "print(f\"Input: data/raw/Dataset_2018_2019.csv ({len(df_raw)} Zeilen)\")\n",
    "print(f\"Output: {output_file} ({len(df_normalized)} Zeilen)\")\n",
    "print(f\"Datenverlust: {len(df_raw) - len(df_normalized)} Zeilen ({((len(df_raw) - len(df_normalized))/len(df_raw)*100):.1f}%)\")\n",
    "print(f\"Standardisierte Spalten: price, size, district, rooms, year, dataset_id, source\")\n",
    "print(f\"Zus√§tzliche Spalten: {len(df_normalized.columns) - 7}\")\n",
    "\n",
    "print(f\"\\nüéØ DATASET 2018-2019 BEREINIGUNG ABGESCHLOSSEN!\")\n",
    "print(f\"Bereit f√ºr Kombination mit anderen normalisierten Datasets.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
