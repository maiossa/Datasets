{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dfab51b2",
   "metadata": {},
   "source": [
    "# Dataset 2022 Bereinigung und Normalisierung\n",
    "## Spezialisiertes Modul f√ºr Springer/Immowelt/Immonet Dataset\n",
    "\n",
    "### Ziel\n",
    "Bereinigung und Normalisierung des aktuellen Datasets (2022) in ein standardisiertes Format f√ºr die gemeinsame Analyse.\n",
    "\n",
    "### Input\n",
    "- `data/raw/Dataset_2022.csv`\n",
    "- `data/processed/berlin_plz_mapping.csv` (PLZ-zu-Bezirk-Mapping)\n",
    "\n",
    "### Output\n",
    "- `data/processed/dataset_2022_normalized.csv`\n",
    "\n",
    "### Besonderheiten\n",
    "- **PLZ-zu-Bezirk-Mapping erforderlich** (Dataset enth√§lt nur PLZ, keine Bezirksnamen)\n",
    "- Umfangreiche Spaltenstruktur mit vielen Features\n",
    "- Deutsche Zahlenformate\n",
    "\n",
    "### Standardisierte Ausgabespalten\n",
    "- `price`: Normalisierter Preis (KALTMIETE in ‚Ç¨)\n",
    "- `size`: Normalisierte Gr√∂√üe (WOHNFLAECHE in m¬≤)\n",
    "- `district`: Berliner Bezirk (via PLZ-Mapping)\n",
    "- `rooms`: Anzahl Zimmer (ZIMMER)\n",
    "- `year`: Jahr des Datasets (2022)\n",
    "- `dataset_id`: Eindeutige Dataset-Kennzeichnung (current)\n",
    "- `source`: Datenquelle\n",
    "\n",
    "---\n",
    "**Teil der modularen Preprocessing-Pipeline**  \n",
    "**Datum:** 4. Juli 2025  \n",
    "**Version:** 1.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1754def0",
   "metadata": {},
   "source": [
    "## 1. Import Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "102355a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bibliotheken erfolgreich importiert!\n",
      "Pandas Version: 2.2.3\n",
      "Dataset: 2022 (Springer/Immowelt/Immonet)\n"
     ]
    }
   ],
   "source": [
    "# Import required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Display configuration\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', 1000)\n",
    "pd.set_option('display.max_rows', 20)\n",
    "\n",
    "print(\"Bibliotheken erfolgreich importiert!\")\n",
    "print(f\"Pandas Version: {pd.__version__}\")\n",
    "print(f\"Dataset: 2022 (Springer/Immowelt/Immonet)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f1604fc",
   "metadata": {},
   "source": [
    "## 2. PLZ-zu-Bezirk-Mapping laden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "91d98e9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "PLZ-ZU-BEZIRK-MAPPING LADEN\n",
      "============================================================\n",
      "‚úÖ PLZ-Mapping geladen: 181 Eintr√§ge\n",
      "‚úÖ PLZ-Dictionary erstellt: 181 Zuordnungen\n",
      "\n",
      "Beispiele:\n",
      "  10115 ‚Üí Mitte\n",
      "  10117 ‚Üí Mitte\n",
      "  10119 ‚Üí Prenzlauer Berg\n",
      "  10178 ‚Üí Mitte\n",
      "  10179 ‚Üí Mitte\n",
      "\n",
      "Abgedeckte Bezirke: 19\n",
      "Bezirke: ['Charlottenburg', 'Friedrichshain', 'Kreuzberg', 'Lichtenberg', 'Marzahn-Hellersdorf', 'Mitte', 'Neuk√∂lln', 'Pankow', 'Prenzlauer Berg', 'Reinickendorf', 'Sch√∂neberg', 'Spandau', 'Steglitz', 'Tempelhof', 'Tiergarten', 'Treptow-K√∂penick', 'Wedding', 'Wilmersdorf', 'Zehlendorf']\n"
     ]
    }
   ],
   "source": [
    "# PLZ-zu-Bezirk-Mapping laden\n",
    "print(\"=\" * 60)\n",
    "print(\"PLZ-ZU-BEZIRK-MAPPING LADEN\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "try:\n",
    "    plz_mapping_df = pd.read_csv('data/processed/berlin_plz_mapping.csv')\n",
    "    print(f\"‚úÖ PLZ-Mapping geladen: {len(plz_mapping_df)} Eintr√§ge\")\n",
    "    \n",
    "    # Erstelle Dictionary f√ºr schnelles Lookup\n",
    "    plz_to_district = dict(zip(plz_mapping_df['PLZ'], plz_mapping_df['Bezirk']))\n",
    "    print(f\"‚úÖ PLZ-Dictionary erstellt: {len(plz_to_district)} Zuordnungen\")\n",
    "    \n",
    "    # Zeige einige Beispiele\n",
    "    print(f\"\\nBeispiele:\")\n",
    "    for plz, bezirk in list(plz_to_district.items())[:5]:\n",
    "        print(f\"  {plz} ‚Üí {bezirk}\")\n",
    "        \n",
    "    print(f\"\\nAbgedeckte Bezirke: {len(set(plz_to_district.values()))}\")\n",
    "    print(f\"Bezirke: {sorted(set(plz_to_district.values()))}\")\n",
    "    \n",
    "except FileNotFoundError:\n",
    "    print(\"‚ùå FEHLER: PLZ-Mapping nicht gefunden!\")\n",
    "    print(\"Bitte stellen Sie sicher, dass 'data/processed/berlin_plz_mapping.csv' existiert.\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd3f0cfe",
   "metadata": {},
   "source": [
    "## 3. Daten laden und erste Analyse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c255b68d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "DATASET 2022 LADEN UND ANALYSIEREN\n",
      "============================================================\n",
      "Dataset geladen: 2,950 Zeilen, 75 Spalten\n",
      "\n",
      "Erste 10 Spalten: ['ID', 'SORTE', 'PLZ', 'KALTMIETE', 'WARMMIETE', 'NEBENKOSTEN', 'KAUTION', 'HEIZUNGSKOSTEN', 'ZIMMER', 'PARKPLAETZE']\n",
      "Letzte 5 Spalten: ['Stein', 'Marmor', 'Doppelboden', 'Terracotta', 'Sonstiges']\n",
      "\n",
      "=== KERNFELDER ANALYSE ===\n",
      "PLZ: 2950/2950 (100.0%) nicht-null\n",
      "KALTMIETE: 2772/2950 (94.0%) nicht-null\n",
      "WOHNFLAECHE: 2950/2950 (100.0%) nicht-null\n",
      "ZIMMER: 2942/2950 (99.7%) nicht-null\n",
      "\n",
      "=== PLZ-ANALYSE ===\n",
      "Einzigartige PLZ: 183\n",
      "PLZ-Beispiele: [10115, 10117, 10119, 10178, 10179, 10243, 10245, 10247, 10249, 10315]\n",
      "\n",
      "Erste 5 Zeilen (Kernfelder):\n",
      "     PLZ  KALTMIETE  WOHNFLAECHE  ZIMMER\n",
      "0  13125     860.00        73.00     3.0\n",
      "1  13125     450.28        48.84     2.0\n",
      "2  13125     739.00        54.79     2.0\n",
      "3  13125     899.00        74.49     3.0\n",
      "4  13125     899.00        74.49     3.0\n"
     ]
    }
   ],
   "source": [
    "# Lade Dataset 2022\n",
    "print(\"=\" * 60)\n",
    "print(\"DATASET 2022 LADEN UND ANALYSIEREN\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Lade Rohdaten\n",
    "df_raw = pd.read_csv('data/raw/Dataset_2022.csv')\n",
    "print(f\"Dataset geladen: {df_raw.shape[0]:,} Zeilen, {df_raw.shape[1]} Spalten\")\n",
    "\n",
    "# Grundlegende Informationen\n",
    "print(f\"\\nErste 10 Spalten: {list(df_raw.columns[:10])}\")\n",
    "print(f\"Letzte 5 Spalten: {list(df_raw.columns[-5:])}\")\n",
    "\n",
    "# Kernfelder analysieren\n",
    "core_fields = ['PLZ', 'KALTMIETE', 'WOHNFLAECHE', 'ZIMMER']\n",
    "print(f\"\\n=== KERNFELDER ANALYSE ===\")\n",
    "for field in core_fields:\n",
    "    if field in df_raw.columns:\n",
    "        non_null = df_raw[field].notna().sum()\n",
    "        print(f\"{field}: {non_null}/{len(df_raw)} ({non_null/len(df_raw)*100:.1f}%) nicht-null\")\n",
    "    else:\n",
    "        print(f\"‚ùå {field}: Spalte nicht gefunden!\")\n",
    "\n",
    "# PLZ-Analyse\n",
    "print(f\"\\n=== PLZ-ANALYSE ===\")\n",
    "unique_plz = df_raw['PLZ'].dropna().unique()\n",
    "print(f\"Einzigartige PLZ: {len(unique_plz)}\")\n",
    "print(f\"PLZ-Beispiele: {sorted(unique_plz)[:10]}\")\n",
    "\n",
    "# Erste 5 Zeilen der Kernfelder\n",
    "print(f\"\\nErste 5 Zeilen (Kernfelder):\")\n",
    "print(df_raw[core_fields].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ee2f21d",
   "metadata": {},
   "source": [
    "## 4. Spezifische Bereinigung Dataset 2022"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5f3a6a5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "SPEZIFISCHE BEREINIGUNG DATASET 2022\n",
      "============================================================\n",
      "Arbeitskopie erstellt: 2950 Zeilen\n",
      "\n",
      "=== PREIS-BEREINIGUNG (KALTMIETE) ===\n",
      "KALTMIETE - Typ: float64\n",
      "Nicht-null Werte: 2772\n",
      "Nach Entfernung NaN-Preise: 2772 Zeilen\n",
      "G√ºltige Preise nach Bereinigung: 2772/2772 (100.0%)\n",
      "Preisspanne: 163.31‚Ç¨ - 3000.00‚Ç¨\n",
      "Entfernte unrealistische Preise: 0\n",
      "\n",
      "=== GR√ñSSEN-BEREINIGUNG (WOHNFLAECHE) ===\n",
      "WOHNFLAECHE - Typ: float64\n",
      "Nicht-null Werte: 2772\n",
      "G√ºltige Gr√∂√üen nach Bereinigung: 2772/2772 (100.0%)\n",
      "Gr√∂√üenspanne: 13.0m¬≤ - 230.0m¬≤\n",
      "Entfernte unrealistische Gr√∂√üen: 0\n",
      "\n",
      "=== PLZ-ZU-BEZIRK-ZUORDNUNG ===\n",
      "PLZ - Typ: int64\n",
      "Nicht-null PLZ: 2772\n",
      "\n",
      "=== ERWEITERUNG DES PLZ-MAPPINGS ===\n",
      "PLZ-Mapping erweitert: 188 Zuordnungen\n",
      "Erfolgreiche PLZ-zu-Bezirk-Zuordnungen: 2681/2772 (96.7%)\n",
      "\n",
      "Verbleibende nicht zugeordnete PLZ (10 einzigartige):\n",
      "  12247: 16 Eintr√§ge\n",
      "  12207: 16 Eintr√§ge\n",
      "  13627: 12 Eintr√§ge\n",
      "  12203: 11 Eintr√§ge\n",
      "  12209: 9 Eintr√§ge\n",
      "  12279: 7 Eintr√§ge\n",
      "  12277: 7 Eintr√§ge\n",
      "  12249: 6 Eintr√§ge\n",
      "  10551: 4 Eintr√§ge\n",
      "  12205: 3 Eintr√§ge\n",
      "Entfernte Eintr√§ge ohne Bezirk: 91\n",
      "\n",
      "=== ZIMMER-BEREINIGUNG (ZIMMER) ===\n",
      "ZIMMER - Typ: float64\n",
      "Nicht-null Werte: 2676\n",
      "G√ºltige Zimmerzahlen nach Bereinigung: 2676/2681 (99.8%)\n",
      "Zimmerspanne: 1.0 - 5.0\n",
      "Entfernte unrealistische Zimmerzahlen: 5\n",
      "\n",
      "‚úÖ Spezifische Bereinigung abgeschlossen\n",
      "Verbleibende Datens√§tze: 2676 (Verlust: 274)\n"
     ]
    }
   ],
   "source": [
    "# Spezifische Bereinigung f√ºr Dataset 2022\n",
    "print(\"=\" * 60)\n",
    "print(\"SPEZIFISCHE BEREINIGUNG DATASET 2022\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Erstelle Arbeitskopie\n",
    "df_clean = df_raw.copy()\n",
    "print(f\"Arbeitskopie erstellt: {len(df_clean)} Zeilen\")\n",
    "\n",
    "# === PREIS-BEREINIGUNG (KALTMIETE) ===\n",
    "print(\"\\n=== PREIS-BEREINIGUNG (KALTMIETE) ===\")\n",
    "print(f\"KALTMIETE - Typ: {df_clean['KALTMIETE'].dtype}\")\n",
    "print(f\"Nicht-null Werte: {df_clean['KALTMIETE'].notna().sum()}\")\n",
    "\n",
    "# Nur Zeilen mit g√ºltigen Preisen behalten\n",
    "df_clean = df_clean[df_clean['KALTMIETE'].notna()]\n",
    "print(f\"Nach Entfernung NaN-Preise: {len(df_clean)} Zeilen\")\n",
    "\n",
    "# Unrealistische Preise entfernen (< 100‚Ç¨ oder > 10000‚Ç¨) - Konsistent mit anderen Datasets\n",
    "initial_count = len(df_clean)\n",
    "df_clean = df_clean[(df_clean['KALTMIETE'] >= 100) & (df_clean['KALTMIETE'] <= 10000)]\n",
    "removed_prices = initial_count - len(df_clean)\n",
    "print(f\"G√ºltige Preise nach Bereinigung: {len(df_clean)}/{initial_count} ({100*len(df_clean)/initial_count:.1f}%)\")\n",
    "print(f\"Preisspanne: {df_clean['KALTMIETE'].min():.2f}‚Ç¨ - {df_clean['KALTMIETE'].max():.2f}‚Ç¨\")\n",
    "print(f\"Entfernte unrealistische Preise: {removed_prices}\")\n",
    "\n",
    "# === GR√ñSSEN-BEREINIGUNG (WOHNFLAECHE) ===\n",
    "print(\"\\n=== GR√ñSSEN-BEREINIGUNG (WOHNFLAECHE) ===\")\n",
    "print(f\"WOHNFLAECHE - Typ: {df_clean['WOHNFLAECHE'].dtype}\")\n",
    "print(f\"Nicht-null Werte: {df_clean['WOHNFLAECHE'].notna().sum()}\")\n",
    "\n",
    "# Unrealistische Gr√∂√üen entfernen (< 10m¬≤ oder > 500m¬≤) - Konsistent mit anderen Datasets\n",
    "initial_count = len(df_clean)\n",
    "df_clean = df_clean[(df_clean['WOHNFLAECHE'] >= 10) & (df_clean['WOHNFLAECHE'] <= 500)]\n",
    "removed_sizes = initial_count - len(df_clean)\n",
    "print(f\"G√ºltige Gr√∂√üen nach Bereinigung: {len(df_clean)}/{initial_count} ({100*len(df_clean)/initial_count:.1f}%)\")\n",
    "print(f\"Gr√∂√üenspanne: {df_clean['WOHNFLAECHE'].min():.1f}m¬≤ - {df_clean['WOHNFLAECHE'].max():.1f}m¬≤\")\n",
    "print(f\"Entfernte unrealistische Gr√∂√üen: {removed_sizes}\")\n",
    "\n",
    "# === PLZ-ZU-BEZIRK-ZUORDNUNG ===\n",
    "print(\"\\n=== PLZ-ZU-BEZIRK-ZUORDNUNG ===\")\n",
    "print(f\"PLZ - Typ: {df_clean['PLZ'].dtype}\")\n",
    "print(f\"Nicht-null PLZ: {df_clean['PLZ'].notna().sum()}\")\n",
    "\n",
    "# WICHTIG: Erweitere das PLZ-Mapping BEVOR die Zuordnung gemacht wird\n",
    "print(\"\\n=== ERWEITERUNG DES PLZ-MAPPINGS ===\")\n",
    "# Erweitere das PLZ-Dictionary um fehlende PLZ-Codes\n",
    "additional_plz_mapping = {\n",
    "    12627: 'Marzahn-Hellersdorf',\n",
    "    12629: 'Marzahn-Hellersdorf',\n",
    "    13593: 'Spandau',\n",
    "    13595: 'Spandau',\n",
    "    13597: 'Spandau',\n",
    "    13599: 'Spandau',\n",
    "    14052: 'Charlottenburg-Wilmersdorf',\n",
    "    14055: 'Charlottenburg-Wilmersdorf',\n",
    "    14057: 'Charlottenburg-Wilmersdorf',\n",
    "    14059: 'Charlottenburg-Wilmersdorf',\n",
    "    10315: 'Lichtenberg',\n",
    "    10317: 'Lichtenberg',\n",
    "    10318: 'Lichtenberg',\n",
    "    10319: 'Lichtenberg',\n",
    "    10365: 'Lichtenberg',\n",
    "    10367: 'Lichtenberg',\n",
    "    10369: 'Lichtenberg',\n",
    "    13125: 'Pankow',\n",
    "    13127: 'Pankow',\n",
    "    13129: 'Pankow',\n",
    "    13156: 'Pankow',\n",
    "    13158: 'Pankow',\n",
    "    13159: 'Pankow',\n",
    "    13187: 'Pankow',\n",
    "    13189: 'Pankow',\n",
    "    12305: 'Tempelhof-Sch√∂neberg',\n",
    "    12307: 'Tempelhof-Sch√∂neberg',\n",
    "    12309: 'Tempelhof-Sch√∂neberg',\n",
    "    12347: 'Neuk√∂lln',\n",
    "    12349: 'Neuk√∂lln',\n",
    "    12351: 'Neuk√∂lln',\n",
    "    12353: 'Neuk√∂lln',\n",
    "    12355: 'Neuk√∂lln',\n",
    "    12357: 'Neuk√∂lln',\n",
    "    12359: 'Neuk√∂lln',\n",
    "    12681: 'Marzahn-Hellersdorf',\n",
    "    12683: 'Marzahn-Hellersdorf',\n",
    "    12685: 'Marzahn-Hellersdorf',\n",
    "    12687: 'Marzahn-Hellersdorf',\n",
    "    12689: 'Marzahn-Hellersdorf',\n",
    "    12679: 'Marzahn-Hellersdorf',\n",
    "    13051: 'Pankow',\n",
    "    13053: 'Pankow',\n",
    "    13055: 'Pankow',\n",
    "    13057: 'Pankow',\n",
    "    13059: 'Pankow',\n",
    "    13086: 'Pankow',\n",
    "    13088: 'Pankow',\n",
    "    13089: 'Pankow',\n",
    "    13403: 'Reinickendorf',\n",
    "    13405: 'Reinickendorf',\n",
    "    13407: 'Reinickendorf',\n",
    "    13409: 'Reinickendorf',\n",
    "    13435: 'Reinickendorf',\n",
    "    13437: 'Reinickendorf',\n",
    "    13439: 'Reinickendorf',\n",
    "    13465: 'Reinickendorf',\n",
    "    13467: 'Reinickendorf',\n",
    "    13469: 'Reinickendorf',\n",
    "    13503: 'Reinickendorf',\n",
    "    13505: 'Reinickendorf',\n",
    "    13507: 'Reinickendorf',\n",
    "    13509: 'Reinickendorf',\n",
    "    13581: 'Spandau',\n",
    "    13583: 'Spandau',\n",
    "    13585: 'Spandau',\n",
    "    13587: 'Spandau',\n",
    "    13589: 'Spandau',\n",
    "    13591: 'Spandau',\n",
    "    14195: 'Steglitz-Zehlendorf',\n",
    "    14197: 'Steglitz-Zehlendorf',\n",
    "    14199: 'Steglitz-Zehlendorf',\n",
    "    14163: 'Steglitz-Zehlendorf',\n",
    "    14165: 'Steglitz-Zehlendorf',\n",
    "    14167: 'Steglitz-Zehlendorf',\n",
    "    14169: 'Steglitz-Zehlendorf',\n",
    "    14129: 'Steglitz-Zehlendorf',\n",
    "    14109: 'Steglitz-Zehlendorf',\n",
    "}\n",
    "\n",
    "# Erweitere das urspr√ºngliche PLZ-Dictionary\n",
    "plz_to_district.update(additional_plz_mapping)\n",
    "print(f\"PLZ-Mapping erweitert: {len(plz_to_district)} Zuordnungen\")\n",
    "\n",
    "# Jetzt PLZ zu Bezirk zuordnen\n",
    "df_clean['district'] = df_clean['PLZ'].map(plz_to_district)\n",
    "successful_mappings = df_clean['district'].notna().sum()\n",
    "print(f\"Erfolgreiche PLZ-zu-Bezirk-Zuordnungen: {successful_mappings}/{len(df_clean)} ({100*successful_mappings/len(df_clean):.1f}%)\")\n",
    "\n",
    "# Zeige nicht zugeordnete PLZ\n",
    "unmapped_plz = df_clean[df_clean['district'].isna()]['PLZ'].value_counts().head(10)\n",
    "if len(unmapped_plz) > 0:\n",
    "    unique_unmapped = df_clean[df_clean['district'].isna()]['PLZ'].nunique()\n",
    "    print(f\"\\nVerbleibende nicht zugeordnete PLZ ({unique_unmapped} einzigartige):\")\n",
    "    for plz, count in unmapped_plz.items():\n",
    "        print(f\"  {plz}: {count} Eintr√§ge\")\n",
    "\n",
    "# Nur Zeilen mit g√ºltigen Bezirken behalten\n",
    "initial_count = len(df_clean)\n",
    "df_clean = df_clean[df_clean['district'].notna()]\n",
    "removed_no_district = initial_count - len(df_clean)\n",
    "print(f\"Entfernte Eintr√§ge ohne Bezirk: {removed_no_district}\")\n",
    "\n",
    "# === ZIMMER-BEREINIGUNG (ZIMMER) ===\n",
    "print(\"\\n=== ZIMMER-BEREINIGUNG (ZIMMER) ===\")\n",
    "print(f\"ZIMMER - Typ: {df_clean['ZIMMER'].dtype}\")\n",
    "print(f\"Nicht-null Werte: {df_clean['ZIMMER'].notna().sum()}\")\n",
    "\n",
    "# Unrealistische Zimmerzahlen entfernen\n",
    "if len(df_clean) > 0:\n",
    "    initial_count = len(df_clean)\n",
    "    df_clean = df_clean[(df_clean['ZIMMER'] >= 1) & (df_clean['ZIMMER'] <= 10)]\n",
    "    removed_rooms = initial_count - len(df_clean)\n",
    "    print(f\"G√ºltige Zimmerzahlen nach Bereinigung: {len(df_clean)}/{initial_count} ({100*len(df_clean)/initial_count:.1f}%)\")\n",
    "    if len(df_clean) > 0:\n",
    "        print(f\"Zimmerspanne: {df_clean['ZIMMER'].min():.1f} - {df_clean['ZIMMER'].max():.1f}\")\n",
    "    print(f\"Entfernte unrealistische Zimmerzahlen: {removed_rooms}\")\n",
    "\n",
    "print(f\"\\n‚úÖ Spezifische Bereinigung abgeschlossen\")\n",
    "print(f\"Verbleibende Datens√§tze: {len(df_clean)} (Verlust: {len(df_raw) - len(df_clean)})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d7bbc0a",
   "metadata": {},
   "source": [
    "## 5. Normalisierung in Standardformat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1d678813",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "NORMALISIERUNG IN STANDARDFORMAT\n",
      "============================================================\n",
      "Normalisiertes Dataset erstellt: 2676 Zeilen\n",
      "Standardspalten: ['price', 'size', 'district', 'rooms', 'year', 'dataset_id', 'source']\n",
      "Zus√§tzliche Spalten: 16\n",
      "\n",
      "=== DATENQUALIT√ÑT NORMALISIERTES DATASET ===\n",
      "Zeilen mit Preis: 2676\n",
      "Zeilen mit Gr√∂√üe: 2676\n",
      "Zeilen mit Bezirk: 2676\n",
      "Zeilen mit Zimmeranzahl: 2676\n",
      "\n",
      "=== STATISTIKEN ===\n",
      "Preis - Min: 180.00‚Ç¨, Max: 3000.00‚Ç¨, Median: 790.60‚Ç¨\n",
      "Gr√∂√üe - Min: 13.0m¬≤, Max: 230.0m¬≤, Median: 65.1m¬≤\n",
      "Zimmer - Min: 1.0, Max: 5.0, Median: 2.0\n",
      "\n",
      "=== BEZIRKSVERTEILUNG ===\n",
      "Anzahl Bezirke: 21\n",
      "  Spandau: 329 Eintr√§ge\n",
      "  Pankow: 256 Eintr√§ge\n",
      "  Reinickendorf: 247 Eintr√§ge\n",
      "  Treptow-K√∂penick: 243 Eintr√§ge\n",
      "  Marzahn-Hellersdorf: 237 Eintr√§ge\n",
      "  Lichtenberg: 151 Eintr√§ge\n",
      "  Neuk√∂lln: 147 Eintr√§ge\n",
      "  Friedrichshain: 113 Eintr√§ge\n",
      "  Sch√∂neberg: 107 Eintr√§ge\n",
      "  Mitte: 99 Eintr√§ge\n",
      "\n",
      "‚úÖ Normalisierung abgeschlossen!\n"
     ]
    }
   ],
   "source": [
    "# Normalisierung in Standardformat\n",
    "print(\"=\" * 60)\n",
    "print(\"NORMALISIERUNG IN STANDARDFORMAT\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Erstelle normalisiertes Dataset mit Standardspalten\n",
    "df_normalized = pd.DataFrame()\n",
    "\n",
    "if len(df_clean) > 0:\n",
    "    # Standardspalten zuweisen\n",
    "    df_normalized['price'] = df_clean['KALTMIETE'].astype('float64')\n",
    "    df_normalized['size'] = df_clean['WOHNFLAECHE'].astype('float64')\n",
    "    df_normalized['district'] = df_clean['district'].astype('string')\n",
    "    df_normalized['rooms'] = df_clean['ZIMMER'].astype('float64')\n",
    "    df_normalized['year'] = 2022\n",
    "    df_normalized['dataset_id'] = 'current'\n",
    "    df_normalized['source'] = 'Springer/Immowelt/Immonet'\n",
    "\n",
    "    # Zus√§tzliche wichtige Spalten aus Original-Dataset beibehalten\n",
    "    df_normalized['plz'] = df_clean['PLZ'].astype('string')\n",
    "    if 'WARMMIETE' in df_clean.columns:\n",
    "        df_normalized['warmmiete'] = df_clean['WARMMIETE']\n",
    "    if 'NEBENKOSTEN' in df_clean.columns:\n",
    "        df_normalized['nebenkosten'] = df_clean['NEBENKOSTEN']\n",
    "    if 'KAUTION' in df_clean.columns:\n",
    "        df_normalized['kaution'] = df_clean['KAUTION']\n",
    "    if 'BAUJAHR' in df_clean.columns:\n",
    "        df_normalized['baujahr'] = df_clean['BAUJAHR']\n",
    "    if 'ZUSTAND' in df_clean.columns:\n",
    "        df_normalized['zustand'] = df_clean['ZUSTAND']\n",
    "    if 'ENERGIEEFFIZIENSKLASSE' in df_clean.columns:\n",
    "        df_normalized['energieeffiziensklasse'] = df_clean['ENERGIEEFFIZIENSKLASSE']\n",
    "\n",
    "    # Ausstattungsmerkmale (boolean)\n",
    "    ausstattung_cols = ['m√∂bliert', 'Balkon', 'Terrasse', 'Garten', 'Einbauk√ºche', \n",
    "                       'Garage', 'Stellplatz', 'Personenaufzug', 'Keller']\n",
    "    for col in ausstattung_cols:\n",
    "        if col in df_clean.columns:\n",
    "            df_normalized[f'ausstattung_{col.lower()}'] = df_clean[col]\n",
    "\n",
    "print(f\"Normalisiertes Dataset erstellt: {len(df_normalized)} Zeilen\")\n",
    "print(f\"Standardspalten: {['price', 'size', 'district', 'rooms', 'year', 'dataset_id', 'source']}\")\n",
    "print(f\"Zus√§tzliche Spalten: {len(df_normalized.columns) - 7}\")\n",
    "\n",
    "# Datenqualit√§t pr√ºfen\n",
    "print(f\"\\n=== DATENQUALIT√ÑT NORMALISIERTES DATASET ===\")\n",
    "print(f\"Zeilen mit Preis: {df_normalized['price'].notna().sum()}\")\n",
    "print(f\"Zeilen mit Gr√∂√üe: {df_normalized['size'].notna().sum()}\")\n",
    "print(f\"Zeilen mit Bezirk: {df_normalized['district'].notna().sum()}\")\n",
    "print(f\"Zeilen mit Zimmeranzahl: {df_normalized['rooms'].notna().sum()}\")\n",
    "\n",
    "# Statistiken\n",
    "if len(df_normalized) > 0:\n",
    "    print(f\"\\n=== STATISTIKEN ===\")\n",
    "    print(f\"Preis - Min: {df_normalized['price'].min():.2f}‚Ç¨, Max: {df_normalized['price'].max():.2f}‚Ç¨, Median: {df_normalized['price'].median():.2f}‚Ç¨\")\n",
    "    print(f\"Gr√∂√üe - Min: {df_normalized['size'].min():.1f}m¬≤, Max: {df_normalized['size'].max():.1f}m¬≤, Median: {df_normalized['size'].median():.1f}m¬≤\")\n",
    "    print(f\"Zimmer - Min: {df_normalized['rooms'].min():.1f}, Max: {df_normalized['rooms'].max():.1f}, Median: {df_normalized['rooms'].median():.1f}\")\n",
    "\n",
    "    # Bezirksverteilung\n",
    "    print(f\"\\n=== BEZIRKSVERTEILUNG ===\")\n",
    "    district_counts = df_normalized['district'].value_counts()\n",
    "    print(f\"Anzahl Bezirke: {len(district_counts)}\")\n",
    "    for district, count in district_counts.head(10).items():\n",
    "        print(f\"  {district}: {count} Eintr√§ge\")\n",
    "\n",
    "print(f\"\\n‚úÖ Normalisierung abgeschlossen!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31ddabaf",
   "metadata": {},
   "source": [
    "## 6. Export des normalisierten Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "be53cc50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "EXPORT NORMALISIERTES DATASET\n",
      "============================================================\n",
      "‚úÖ Normalisiertes Dataset exportiert: data/processed/dataset_2022_normalized.csv\n",
      "Dateigr√∂√üe: 2676 Zeilen x 23 Spalten\n",
      "‚úÖ Export-Validierung erfolgreich: 2676 Zeilen geladen\n",
      "\n",
      "=== ZUSAMMENFASSUNG DATASET 2022 ===\n",
      "Input: data/raw/Dataset_2022.csv (2950 Zeilen)\n",
      "Output: data/processed/dataset_2022_normalized.csv (2676 Zeilen)\n",
      "Datenverlust: 274 Zeilen (9.3%)\n",
      "PLZ-zu-Bezirk-Mapping: 2676/2676 (100.0%) erfolgreich\n",
      "Standardisierte Spalten: price, size, district, rooms, year, dataset_id, source\n",
      "Zus√§tzliche Spalten: 16\n",
      "\n",
      "üéØ DATASET 2022 BEREINIGUNG ABGESCHLOSSEN!\n",
      "Bereit f√ºr Kombination mit anderen normalisierten Datasets.\n"
     ]
    }
   ],
   "source": [
    "# Export des normalisierten Datasets\n",
    "print(\"=\" * 60)\n",
    "print(\"EXPORT NORMALISIERTES DATASET\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Ausgabedatei\n",
    "output_file = 'data/processed/dataset_2022_normalized.csv'\n",
    "\n",
    "# Export\n",
    "df_normalized.to_csv(output_file, index=False)\n",
    "print(f\"‚úÖ Normalisiertes Dataset exportiert: {output_file}\")\n",
    "print(f\"Dateigr√∂√üe: {len(df_normalized)} Zeilen x {len(df_normalized.columns)} Spalten\")\n",
    "\n",
    "# Validierung des Exports\n",
    "test_load = pd.read_csv(output_file)\n",
    "print(f\"‚úÖ Export-Validierung erfolgreich: {len(test_load)} Zeilen geladen\")\n",
    "\n",
    "# Zusammenfassung\n",
    "print(f\"\\n=== ZUSAMMENFASSUNG DATASET 2022 ===\")\n",
    "print(f\"Input: data/raw/Dataset_2022.csv ({len(df_raw)} Zeilen)\")\n",
    "print(f\"Output: {output_file} ({len(df_normalized)} Zeilen)\")\n",
    "print(f\"Datenverlust: {len(df_raw) - len(df_normalized)} Zeilen ({((len(df_raw) - len(df_normalized))/len(df_raw)*100):.1f}%)\")\n",
    "print(f\"PLZ-zu-Bezirk-Mapping: {df_normalized['district'].notna().sum()}/{len(df_normalized)} ({df_normalized['district'].notna().sum()/len(df_normalized)*100:.1f}%) erfolgreich\")\n",
    "print(f\"Standardisierte Spalten: price, size, district, rooms, year, dataset_id, source\")\n",
    "print(f\"Zus√§tzliche Spalten: {len(df_normalized.columns) - 7}\")\n",
    "\n",
    "print(f\"\\nüéØ DATASET 2022 BEREINIGUNG ABGESCHLOSSEN!\")\n",
    "print(f\"Bereit f√ºr Kombination mit anderen normalisierten Datasets.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1b2c3d5",
   "metadata": {},
   "source": [
    "## 7. Lade angereicherte Wohnlagendaten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e5f6g7h9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "ANGEREICHERTE WOHNLAGENDATEN LADEN\n",
      "============================================================\n",
      "‚úÖ Angereicherte Daten geladen: 551,249 Zeilen, 11 Spalten\n"
     ]
    }
   ],
   "source": [
    "print(\"=\"*60)\n",
    "print(\"ANGEREICHERTE WOHNLAGENDATEN LADEN\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "enriched_data_path = 'data/raw/wohnlagen_enriched.csv'\n",
    "try:\n",
    "    enriched_df = pd.read_csv(enriched_data_path)\n",
    "    print(f\"‚úÖ Angereicherte Daten geladen: {len(enriched_df):,} Zeilen, {len(enriched_df.columns)} Spalten\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"‚ùå Datei nicht gefunden: {enriched_data_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "i9j0k1l3",
   "metadata": {},
   "source": [
    "## 8. Kombiniere Datasets mit Wohnlagendaten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "m3n4o5p7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "KOMBINIERE MIT WOHNLAGENDATEN\n",
      "============================================================\n",
      "Original df_normalized: 2,676 Zeilen\n",
      "Original enriched_df: 551,249 Zeilen\n",
      "Unique PLZ mappings: 193 Zeilen\n",
      "PLZ overlap: 173 von 173 PLZ im Dataset\n",
      "‚úÖ Kombiniertes und angereichertes Dataset erstellt: 2,676 Zeilen\n",
      "Erfolgreiche Anreicherung: 2,676 von 2,676 Zeilen (100.0%)\n"
     ]
    }
   ],
   "source": [
    "print(\"=\"*60)\n",
    "print(\"KOMBINIERE MIT WOHNLAGENDATEN\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Debug: Check original data sizes\n",
    "print(f\"Original df_normalized: {len(df_normalized):,} Zeilen\")\n",
    "print(f\"Original enriched_df: {len(enriched_df):,} Zeilen\")\n",
    "\n",
    "# Create a unique mapping of PLZ to avoid cartesian product\n",
    "enriched_df_subset = enriched_df[['plz', 'wol', 'ortsteil_neu']].drop_duplicates(subset=['plz'])\n",
    "print(f\"Unique PLZ mappings: {len(enriched_df_subset):,} Zeilen\")\n",
    "\n",
    "# Convert PLZ to string for consistent merge\n",
    "df_normalized['plz'] = df_normalized['plz'].astype(str)\n",
    "enriched_df_subset['plz'] = enriched_df_subset['plz'].astype(str)\n",
    "\n",
    "# Debug: Check PLZ overlap\n",
    "df_plz_unique = set(df_normalized['plz'].unique())\n",
    "enriched_plz_unique = set(enriched_df_subset['plz'].unique())\n",
    "overlap = df_plz_unique.intersection(enriched_plz_unique)\n",
    "print(f\"PLZ overlap: {len(overlap)} von {len(df_plz_unique)} PLZ im Dataset\")\n",
    "\n",
    "# Perform the merge\n",
    "df_enriched = pd.merge(df_normalized, enriched_df_subset, how='left', on=['plz'])\n",
    "\n",
    "print(f\"‚úÖ Kombiniertes und angereichertes Dataset erstellt: {len(df_enriched):,} Zeilen\")\n",
    "\n",
    "# Check merge success\n",
    "successful_enrichment = df_enriched['ortsteil_neu'].notna().sum()\n",
    "print(f\"Erfolgreiche Anreicherung: {successful_enrichment:,} von {len(df_enriched):,} Zeilen ({successful_enrichment/len(df_enriched)*100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "q7r8s9t1",
   "metadata": {},
   "source": [
    "## 9. Export des finalen angereicherten Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "u1v2w3x5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "EXPORT FINALES ANGEREICHERTES DATASET\n",
      "============================================================\n",
      "‚úÖ Finales angereichertes Dataset exportiert: data/processed/dataset_2022_enriched.csv\n",
      "Dateigr√∂√üe: 2,676 Zeilen x 25 Spalten\n",
      "‚úÖ Export-Validierung erfolgreich: 2,676 Zeilen geladen\n",
      "‚úÖ Export-Validierung erfolgreich: 2,676 Zeilen geladen\n"
     ]
    }
   ],
   "source": [
    "print(\"=\"*60)\n",
    "print(\"EXPORT FINALES ANGEREICHERTES DATASET\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Export\n",
    "output_file_enriched = 'data/processed/dataset_2022_enriched.csv'\n",
    "df_enriched.to_csv(output_file_enriched, index=False)\n",
    "\n",
    "print(f\"‚úÖ Finales angereichertes Dataset exportiert: {output_file_enriched}\")\n",
    "print(f\"Dateigr√∂√üe: {len(df_enriched):,} Zeilen x {len(df_enriched.columns)} Spalten\")\n",
    "\n",
    "# Validierung durch Wiedereinlesen\n",
    "test_df_enriched = pd.read_csv(output_file_enriched)\n",
    "print(f\"‚úÖ Export-Validierung erfolgreich: {len(test_df_enriched):,} Zeilen geladen\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
