{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1fbce55e",
   "metadata": {},
   "source": [
    "# Berlin Housing Market Analysis - Data Preprocessing\n",
    "## Datenbereinigung und Normalisierung\n",
    "\n",
    "### Projektziel\n",
    "Dieses Notebook dokumentiert die Bereinigung und Normalisierung von drei verschiedenen Datensätzen des Berliner Wohnungsmarktes aus den Jahren 2018-2019, 2022 und 2025.\n",
    "\n",
    "### Identifizierte Herausforderungen\n",
    "1. **PLZ-zu-Bezirk Mapping**: Dataset 2022 enthält nur Postleitzahlen\n",
    "2. **Heterogene Datenstrukturen**: Unterschiedliche Spaltenformate\n",
    "3. **Datenqualität**: Fehlende Werte, inkonsistente Formate\n",
    "\n",
    "### Lösungsansatz\n",
    "- Vollständige PLZ-zu-Bezirk Mapping-Tabelle erstellen\n",
    "- Einheitliche Datenstruktur entwickeln\n",
    "- Systematische Bereinigung implementieren\n",
    "- Bereinigte Daten exportieren für weitere Analyse\n",
    "\n",
    "---\n",
    "\n",
    "**Autor**: Berlin Housing Market Analysis Team  \n",
    "**Datum**: 4. Juli 2025  \n",
    "**Version**: 1.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22eccb68",
   "metadata": {},
   "source": [
    "## 1. Import Required Libraries\n",
    "Importieren der erforderlichen Python-Bibliotheken für die Datenverarbeitung."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "267ad950",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alle Bibliotheken erfolgreich importiert!\n",
      "Pandas Version: 2.3.0\n",
      "NumPy Version: 2.3.0\n",
      "Verarbeitung gestartet am: 2025-07-04 03:25:58\n"
     ]
    }
   ],
   "source": [
    "# Datenmanipulation und -analyse\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Visualisierung für Qualitätskontrolle\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Textverarbeitung und Regex\n",
    "import re\n",
    "from collections import Counter\n",
    "\n",
    "# Datum und Zeit\n",
    "from datetime import datetime\n",
    "\n",
    "# Konfiguration\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', 1000)\n",
    "plt.style.use('seaborn-v0_8')\n",
    "\n",
    "print(\"Alle Bibliotheken erfolgreich importiert!\")\n",
    "print(f\"Pandas Version: {pd.__version__}\")\n",
    "print(f\"NumPy Version: {np.__version__}\")\n",
    "print(f\"Verarbeitung gestartet am: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a110bf4",
   "metadata": {},
   "source": [
    "## 2. Berlin PLZ-zu-Bezirk Mapping\n",
    "### Problem: Dataset 2022 enthält nur Postleitzahlen\n",
    "\n",
    "**Herausforderung**: Das wertvollste Dataset (2022) mit 2.952 Einträgen nutzt nur PLZ-Codes, keine Bezirksnamen direkt.\n",
    "\n",
    "**Lösung**: Vollständige Mapping-Tabelle aller Berliner Postleitzahlen zu ihren entsprechenden Bezirken erstellen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2373b488",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PLZ-zu-Bezirk Mapping erstellt!\n",
      "Anzahl gemappter PLZ: 181\n",
      "Anzahl einzigartiger Bezirke: 19\n",
      "Bezirke: ['Charlottenburg', 'Friedrichshain', 'Kreuzberg', 'Lichtenberg', 'Marzahn-Hellersdorf', 'Mitte', 'Neukölln', 'Pankow', 'Prenzlauer Berg', 'Reinickendorf', 'Schöneberg', 'Spandau', 'Steglitz', 'Tempelhof', 'Tiergarten', 'Treptow-Köpenick', 'Wedding', 'Wilmersdorf', 'Zehlendorf']\n"
     ]
    }
   ],
   "source": [
    "# Vollständige Berlin PLZ-zu-Bezirk Mapping-Tabelle\n",
    "# Basierend auf offiziellen Berliner Postleitzahlen-Verzeichnissen\n",
    "\n",
    "berlin_plz_to_district = {\n",
    "    # Mitte\n",
    "    '10115': 'Mitte', '10117': 'Mitte', '10119': 'Mitte', '10178': 'Mitte', '10179': 'Mitte',\n",
    "    '10115': 'Mitte', '10117': 'Mitte', '10119': 'Mitte', '10178': 'Mitte', '10179': 'Mitte',\n",
    "    \n",
    "    # Tiergarten\n",
    "    '10553': 'Tiergarten', '10555': 'Tiergarten', '10557': 'Tiergarten', '10559': 'Tiergarten',\n",
    "    '10785': 'Tiergarten', '10787': 'Tiergarten', '10963': 'Tiergarten',\n",
    "    \n",
    "    # Wedding\n",
    "    '13347': 'Wedding', '13349': 'Wedding', '13351': 'Wedding', '13353': 'Wedding', '13355': 'Wedding',\n",
    "    '13357': 'Wedding', '13359': 'Wedding', '13405': 'Wedding', '13407': 'Wedding', '13409': 'Wedding',\n",
    "    \n",
    "    # Friedrichshain\n",
    "    '10243': 'Friedrichshain', '10245': 'Friedrichshain', '10247': 'Friedrichshain', '10249': 'Friedrichshain',\n",
    "    \n",
    "    # Kreuzberg\n",
    "    '10961': 'Kreuzberg', '10963': 'Kreuzberg', '10965': 'Kreuzberg', '10967': 'Kreuzberg',\n",
    "    '10969': 'Kreuzberg', '10997': 'Kreuzberg', '10999': 'Kreuzberg',\n",
    "    \n",
    "    # Prenzlauer Berg\n",
    "    '10119': 'Prenzlauer Berg', '10405': 'Prenzlauer Berg', '10407': 'Prenzlauer Berg', \n",
    "    '10409': 'Prenzlauer Berg', '10435': 'Prenzlauer Berg', '10437': 'Prenzlauer Berg', '10439': 'Prenzlauer Berg',\n",
    "    \n",
    "    # Charlottenburg\n",
    "    '10585': 'Charlottenburg', '10587': 'Charlottenburg', '10589': 'Charlottenburg', '10623': 'Charlottenburg',\n",
    "    '10625': 'Charlottenburg', '10627': 'Charlottenburg', '10629': 'Charlottenburg', '14050': 'Charlottenburg',\n",
    "    '14052': 'Charlottenburg', '14055': 'Charlottenburg', '14057': 'Charlottenburg', '14059': 'Charlottenburg',\n",
    "    \n",
    "    # Wilmersdorf\n",
    "    '10707': 'Wilmersdorf', '10709': 'Wilmersdorf', '10711': 'Wilmersdorf', '10713': 'Wilmersdorf',\n",
    "    '10715': 'Wilmersdorf', '10717': 'Wilmersdorf', '10719': 'Wilmersdorf', '14193': 'Wilmersdorf',\n",
    "    '14195': 'Wilmersdorf', '14197': 'Wilmersdorf', '14199': 'Wilmersdorf',\n",
    "    \n",
    "    # Schöneberg\n",
    "    '10777': 'Schöneberg', '10779': 'Schöneberg', '10781': 'Schöneberg', '10783': 'Schöneberg',\n",
    "    '10785': 'Schöneberg', '10787': 'Schöneberg', '10789': 'Schöneberg', '10823': 'Schöneberg',\n",
    "    '10825': 'Schöneberg', '10827': 'Schöneberg', '10829': 'Schöneberg',\n",
    "    \n",
    "    # Steglitz\n",
    "    '12157': 'Steglitz', '12159': 'Steglitz', '12161': 'Steglitz', '12163': 'Steglitz',\n",
    "    '12165': 'Steglitz', '12167': 'Steglitz', '12169': 'Steglitz',\n",
    "    \n",
    "    # Zehlendorf\n",
    "    '14109': 'Zehlendorf', '14129': 'Zehlendorf', '14163': 'Zehlendorf', '14165': 'Zehlendorf',\n",
    "    '14167': 'Zehlendorf', '14169': 'Zehlendorf', '14195': 'Zehlendorf',\n",
    "    \n",
    "    # Tempelhof\n",
    "    '12099': 'Tempelhof', '12101': 'Tempelhof', '12103': 'Tempelhof', '12105': 'Tempelhof',\n",
    "    '12107': 'Tempelhof', '12109': 'Tempelhof', '12111': 'Tempelhof',\n",
    "    \n",
    "    # Neukölln\n",
    "    '12043': 'Neukölln', '12045': 'Neukölln', '12047': 'Neukölln', '12049': 'Neukölln',\n",
    "    '12051': 'Neukölln', '12053': 'Neukölln', '12055': 'Neukölln', '12057': 'Neukölln',\n",
    "    '12059': 'Neukölln', '12347': 'Neukölln', '12349': 'Neukölln', '12351': 'Neukölln',\n",
    "    '12353': 'Neukölln', '12355': 'Neukölln', '12357': 'Neukölln', '12359': 'Neukölln',\n",
    "    \n",
    "    # Treptow-Köpenick\n",
    "    '12435': 'Treptow-Köpenick', '12437': 'Treptow-Köpenick', '12439': 'Treptow-Köpenick',\n",
    "    '12459': 'Treptow-Köpenick', '12487': 'Treptow-Köpenick', '12489': 'Treptow-Köpenick',\n",
    "    '12524': 'Treptow-Köpenick', '12526': 'Treptow-Köpenick', '12527': 'Treptow-Köpenick',\n",
    "    '12555': 'Treptow-Köpenick', '12557': 'Treptow-Köpenick', '12559': 'Treptow-Köpenick',\n",
    "    '12587': 'Treptow-Köpenick', '12589': 'Treptow-Köpenick', '12623': 'Treptow-Köpenick',\n",
    "    \n",
    "    # Marzahn-Hellersdorf\n",
    "    '12679': 'Marzahn-Hellersdorf', '12681': 'Marzahn-Hellersdorf', '12683': 'Marzahn-Hellersdorf',\n",
    "    '12685': 'Marzahn-Hellersdorf', '12687': 'Marzahn-Hellersdorf', '12689': 'Marzahn-Hellersdorf',\n",
    "    '12619': 'Marzahn-Hellersdorf', '12621': 'Marzahn-Hellersdorf', '12623': 'Marzahn-Hellersdorf',\n",
    "    \n",
    "    # Lichtenberg\n",
    "    '10315': 'Lichtenberg', '10317': 'Lichtenberg', '10318': 'Lichtenberg', '10319': 'Lichtenberg',\n",
    "    '10365': 'Lichtenberg', '10367': 'Lichtenberg', '10369': 'Lichtenberg',\n",
    "    '13055': 'Lichtenberg', '13057': 'Lichtenberg', '13059': 'Lichtenberg',\n",
    "    \n",
    "    # Pankow\n",
    "    '13086': 'Pankow', '13088': 'Pankow', '13089': 'Pankow', '13125': 'Pankow', '13127': 'Pankow',\n",
    "    '13129': 'Pankow', '13156': 'Pankow', '13158': 'Pankow', '13159': 'Pankow', '13161': 'Pankow',\n",
    "    '13187': 'Pankow', '13189': 'Pankow', '13403': 'Pankow',\n",
    "    \n",
    "    # Reinickendorf\n",
    "    '13403': 'Reinickendorf', '13405': 'Reinickendorf', '13407': 'Reinickendorf', '13409': 'Reinickendorf',\n",
    "    '13435': 'Reinickendorf', '13437': 'Reinickendorf', '13439': 'Reinickendorf', '13465': 'Reinickendorf',\n",
    "    '13467': 'Reinickendorf', '13469': 'Reinickendorf', '13503': 'Reinickendorf', '13505': 'Reinickendorf',\n",
    "    '13507': 'Reinickendorf', '13509': 'Reinickendorf', '13591': 'Reinickendorf', '13593': 'Reinickendorf',\n",
    "    '13595': 'Reinickendorf', '13597': 'Reinickendorf', '13599': 'Reinickendorf',\n",
    "    \n",
    "    # Spandau\n",
    "    '13581': 'Spandau', '13583': 'Spandau', '13585': 'Spandau', '13587': 'Spandau', '13589': 'Spandau',\n",
    "    '13591': 'Spandau', '13593': 'Spandau', '13595': 'Spandau', '13597': 'Spandau', '13599': 'Spandau',\n",
    "    '13629': 'Spandau', '13631': 'Spandau', '13633': 'Spandau', '13635': 'Spandau', '13637': 'Spandau',\n",
    "    '13639': 'Spandau', '14089': 'Spandau', '14641': 'Spandau', '14669': 'Spandau'\n",
    "}\n",
    "\n",
    "print(\"PLZ-zu-Bezirk Mapping erstellt!\")\n",
    "print(f\"Anzahl gemappter PLZ: {len(berlin_plz_to_district)}\")\n",
    "print(f\"Anzahl einzigartiger Bezirke: {len(set(berlin_plz_to_district.values()))}\")\n",
    "print(\"Bezirke:\", sorted(set(berlin_plz_to_district.values())))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "873948ed",
   "metadata": {},
   "source": [
    "## 3. Load and Analyze Original Datasets\n",
    "### 3.1 Dataset Overview\n",
    "Laden und erste Analyse der drei originalen Datensätze mit Fokus auf Datenqualität."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9fde2ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "LADEN DER ORIGINALEN DATENSÄTZE\n",
      "============================================================\n",
      "\n",
      "Dataset 2025 (Immobilienscout24)\n",
      "Zeilen: 6,109\n",
      "Spalten: 5\n",
      "Spalten: ['title', 'price', 'size', 'address', 'link']\n",
      "\n",
      "Dataset 2018-2019 (Kaggle)\n",
      "Zeilen: 10,406\n",
      "Spalten: 9\n",
      "Spalten: ['regio3', 'street', 'livingSpace', 'baseRent', 'totalRent', 'noRooms', 'floor', 'typeOfFlat', 'yearConstructed']\n",
      "\n",
      "Dataset 2022 (Springer/Immowelt/Immonet)\n",
      "Zeilen: 2,950\n",
      "Spalten: 75\n",
      "Erste 5 Spalten: ['ID', 'SORTE', 'PLZ', 'KALTMIETE', 'WARMMIETE']\n",
      "\n",
      "Alle Datensätze erfolgreich geladen!\n",
      "Gesamt Zeilen: 19,465\n",
      "\n",
      "PLZ-Analyse Dataset 2022:\n",
      "Anzahl einzigartiger PLZ: 183\n",
      "PLZ-Bereich: 10115 - 14199\n",
      "Beispiel PLZ: [np.int64(10115), np.int64(10117), np.int64(10119), np.int64(10178), np.int64(10179), np.int64(10243), np.int64(10245), np.int64(10247), np.int64(10249), np.int64(10315)]\n",
      "\n",
      "PLZ-Mapping Coverage:\n",
      "PLZ im Dataset 2022: 183\n",
      "PLZ in unserem Mapping: 167\n",
      "Coverage: 91.3%\n"
     ]
    }
   ],
   "source": [
    "# Laden der originalen Datensätze aus dem data/raw/ Verzeichnis\n",
    "print(\"=\" * 60)\n",
    "print(\"LADEN DER ORIGINALEN DATENSÄTZE\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Nur Dataset 2022 für PLZ-Analyse laden (das ist unser Hauptproblem)\n",
    "print(\"\\nDataset 2022 (Springer/Immowelt/Immonet) - PLZ-Analyse\")\n",
    "df_2022 = pd.read_csv('data/raw/Dataset_2022.csv')\n",
    "print(f\"Zeilen: {df_2022.shape[0]:,}\")\n",
    "print(f\"Spalten: {df_2022.shape[1]}\")\n",
    "print(f\"Erste 5 Spalten: {list(df_2022.columns[:5])}\")\n",
    "\n",
    "# PLZ-Analyse für Mapping-Entwicklung\n",
    "unique_plz_2022 = df_2022['PLZ'].unique()\n",
    "print(f\"\\nPLZ-Problem-Analyse:\")\n",
    "print(f\"Anzahl einzigartiger PLZ: {len(unique_plz_2022)}\")\n",
    "print(f\"PLZ-Bereich: {min(unique_plz_2022)} - {max(unique_plz_2022)}\")\n",
    "print(f\"Beispiel PLZ: {sorted(unique_plz_2022)[:10]}\")\n",
    "\n",
    "print(f\"\\nPROBLEM IDENTIFIZIERT:\")\n",
    "print(f\"Dataset 2022 hat {len(unique_plz_2022)} verschiedene PLZ, aber keine Bezirkszuordnung!\")\n",
    "print(f\"Das bedeutet: {df_2022.shape[0]} wertvolle Datenpunkte können ohne PLZ-Mapping nicht verwendet werden!\")\n",
    "\n",
    "# Kurze Übersicht der anderen Datasets (nur für Vollständigkeit)\n",
    "print(f\"\\n\" + \"=\"*60)\n",
    "print(\"ÜBERSICHT ANDERE DATASETS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(\"\\nDataset 2025:\")\n",
    "df_2025 = pd.read_csv('data/raw/Dataset_2025.csv')\n",
    "print(f\"Zeilen: {df_2025.shape[0]:,}, Spalten: {df_2025.shape[1]}\")\n",
    "print(f\"Spalten: {list(df_2025.columns)}\")\n",
    "\n",
    "print(\"\\nDataset 2018-2019:\")\n",
    "df_2018_2019 = pd.read_csv('data/raw/Dataset_2018_2019.csv')\n",
    "print(f\"Zeilen: {df_2018_2019.shape[0]:,}, Spalten: {df_2018_2019.shape[1]}\")\n",
    "print(f\"Spalten: {list(df_2018_2019.columns)}\")\n",
    "\n",
    "print(f\"\\nGESAMT: {df_2025.shape[0] + df_2018_2019.shape[0] + df_2022.shape[0]:,} Datenpunkte\")\n",
    "print(\"ZIEL: PLZ-zu-Bezirk-Mapping für Dataset 2022 erstellen\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12018fd9",
   "metadata": {},
   "source": [
    "# Berlin Housing Market Analysis - Data Preprocessing\n",
    "## Datenvorverarbeitung und PLZ-Mapping\n",
    "\n",
    "### Projektübersicht\n",
    "Dieses Notebook behandelt die Datenvorverarbeitung für die Berlin Housing Market Analysis. Der Fokus liegt auf der Lösung des **PLZ-zu-Bezirk Mapping Problems** im 2022er Dataset.\n",
    "\n",
    "### Identifizierte Herausforderungen\n",
    "1. **Hauptproblem**: Dataset 2022 enthält nur Postleitzahlen, keine direkten Bezirksnamen\n",
    "2. **Auswirkung**: Wertvolles Dataset mit 2.952 Einträgen wird nicht optimal genutzt\n",
    "3. **Lösung**: Vollständige Berliner PLZ-zu-Bezirk Mapping-Tabelle erstellen\n",
    "\n",
    "### Ziele dieses Notebooks\n",
    "- Vollständige PLZ-zu-Bezirk Zuordnung für alle Berliner Postleitzahlen\n",
    "- Datenbereinigung und Normalisierung aller drei Datasets\n",
    "- Zusammenführung in ein einheitliches, analysefreundliches Format\n",
    "- Qualitätsprüfung und Validierung der Ergebnisse\n",
    "\n",
    "### Struktur\n",
    "1. **Datenanalyse**: Verstehen der vorhandenen Daten\n",
    "2. **PLZ-Mapping**: Entwicklung der vollständigen Zuordnungstabelle\n",
    "3. **Datenbereinigung**: Standardisierung und Normalisierung\n",
    "4. **Zusammenführung**: Einheitliches Dataset erstellen\n",
    "5. **Validierung**: Qualitätsprüfung der Ergebnisse"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "738b8853",
   "metadata": {},
   "source": [
    "## 1. Bibliotheken und Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a5205457",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bibliotheken erfolgreich importiert!\n",
      "Pandas Version: 2.3.0\n",
      "NumPy Version: 2.3.0\n",
      "Matplotlib Version: 3.10.3\n",
      "Seaborn Version: 0.13.2\n",
      "\n",
      "Arbeitsverzeichnis: c:\\Users\\Gamer\\Desktop\\Datasets\n",
      "Verfügbare Dateien: ['Berlin_Housing_Market_Cleaned.csv', 'Berlin_Housing_Summary.csv', 'berlin_plz_mapping.csv', 'Berlin_Top_Districts.csv', 'Dataset_2018_2019.csv', 'Dataset_2022.csv', 'Dataset_2025.csv']\n"
     ]
    }
   ],
   "source": [
    "# Importiere benötigte Bibliotheken\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Für Visualisierung\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Für Text und Regex\n",
    "import re\n",
    "from collections import Counter\n",
    "\n",
    "# Pandas Konfiguration\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', 1000)\n",
    "pd.set_option('display.max_rows', 50)\n",
    "\n",
    "print(\"Bibliotheken erfolgreich importiert!\")\n",
    "print(f\"Pandas Version: {pd.__version__}\")\n",
    "print(f\"NumPy Version: {np.__version__}\")\n",
    "print(f\"Matplotlib Version: {plt.matplotlib.__version__}\")\n",
    "print(f\"Seaborn Version: {sns.__version__}\")\n",
    "\n",
    "# Arbeitsverzeichnis bestätigen\n",
    "import os\n",
    "print(f\"\\nArbeitsverzeichnis: {os.getcwd()}\")\n",
    "print(f\"Verfügbare Dateien: {[f for f in os.listdir('.') if f.endswith('.csv')]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bde169a",
   "metadata": {},
   "source": [
    "## 2. Datenanalyse - Verstehen der vorhandenen Daten\n",
    "\n",
    "### Problem: Heterogene Datenstrukturen\n",
    "Wir haben drei Datasets mit unterschiedlichen Strukturen:\n",
    "- **Dataset 2025**: title, price, size, address, link\n",
    "- **Dataset 2018-2019**: regio3, street, livingSpace, baseRent, totalRent, noRooms, etc.\n",
    "- **Dataset 2022**: PLZ, KALTMIETE, WARMMIETE, WOHNFLAECHE, etc. (**Hier ist unser PLZ-Problem**)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6fab2f2",
   "metadata": {},
   "source": [
    "### **Kritische Analyse: PLZ-Problem im Dataset 2022**\n",
    "\n",
    "Das Dataset 2022 ist unser wertvollstes Dataset mit 2.952 Einträgen, aber es enthält nur Postleitzahlen statt Bezirksnamen. Das ist ein **kritisches Problem** für unsere Analyse, da wir Bezirksvergleiche durchführen wollen."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7841bd11",
   "metadata": {},
   "source": [
    "## 3. Lösung: Vollständige Berliner PLZ-zu-Bezirk Mapping-Tabelle\n",
    "\n",
    "### Lösungsansatz\n",
    "Wir erstellen eine **vollständige Mapping-Tabelle** für alle Berliner Postleitzahlen zu ihren entsprechenden Bezirken. Dies ist essentiell für eine korrekte Analyse.\n",
    "\n",
    "### Warum ist das wichtig?\n",
    "- **Datenqualität**: Ohne korrekte Bezirk-Zuordnung verlieren wir 2.952 Datenpunkte\n",
    "- **Analysefähigkeit**: Bezirksvergleiche sind ein Kernbestandteil unserer Analyse\n",
    "- **Präzision**: Genaue geografische Zuordnung für bessere Erkenntnisse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4378c340",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERSTELLE VOLLSTÄNDIGE BERLINER PLZ-ZU-BEZIRK MAPPING-TABELLE\n",
      "======================================================================\n",
      "PLZ-Mapping-Tabelle erstellt!\n",
      "Anzahl PLZ-Zuordnungen: 208\n",
      "Anzahl Bezirke: 12\n",
      "\n",
      "Bezirke in der Mapping-Tabelle:\n",
      "  Charlottenburg-Wilmersdorf: 20 PLZ\n",
      "  Friedrichshain-Kreuzberg: 11 PLZ\n",
      "  Lichtenberg: 27 PLZ\n",
      "  Marzahn-Hellersdorf: 16 PLZ\n",
      "  Mitte: 13 PLZ\n",
      "  Neukölln: 18 PLZ\n",
      "  Pankow: 6 PLZ\n",
      "  Reinickendorf: 21 PLZ\n",
      "  Spandau: 16 PLZ\n",
      "  Steglitz-Zehlendorf: 19 PLZ\n",
      "  Tempelhof-Schöneberg: 27 PLZ\n",
      "  Treptow-Köpenick: 14 PLZ\n",
      "\n",
      "Mapping-Tabelle gespeichert als 'berlin_plz_mapping.csv'\n"
     ]
    }
   ],
   "source": [
    "# Vollständige Berliner PLZ-zu-Bezirk Mapping-Tabelle\n",
    "print(\"ERSTELLE VOLLSTÄNDIGE BERLINER PLZ-ZU-BEZIRK MAPPING-TABELLE\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Vollständige Mapping-Tabelle für alle Berliner PLZ\n",
    "berlin_plz_mapping = {\n",
    "    # Mitte\n",
    "    '10115': 'Mitte', '10117': 'Mitte', '10119': 'Mitte', '10178': 'Mitte', '10179': 'Mitte',\n",
    "    '10435': 'Mitte', '10557': 'Mitte', '10559': 'Mitte', '10623': 'Mitte', '10785': 'Mitte',\n",
    "    '10787': 'Mitte', '10963': 'Mitte', '10969': 'Mitte', '13347': 'Mitte', '13349': 'Mitte',\n",
    "    '13353': 'Mitte', '13355': 'Mitte', '13357': 'Mitte', '13359': 'Mitte', '13407': 'Mitte',\n",
    "    \n",
    "    # Friedrichshain-Kreuzberg\n",
    "    '10243': 'Friedrichshain-Kreuzberg', '10245': 'Friedrichshain-Kreuzberg', \n",
    "    '10247': 'Friedrichshain-Kreuzberg', '10249': 'Friedrichshain-Kreuzberg',\n",
    "    '10961': 'Friedrichshain-Kreuzberg', '10963': 'Friedrichshain-Kreuzberg',\n",
    "    '10965': 'Friedrichshain-Kreuzberg', '10967': 'Friedrichshain-Kreuzberg',\n",
    "    '10969': 'Friedrichshain-Kreuzberg', '10997': 'Friedrichshain-Kreuzberg',\n",
    "    '10999': 'Friedrichshain-Kreuzberg',\n",
    "    \n",
    "    # Pankow\n",
    "    '10405': 'Pankow', '10407': 'Pankow', '10409': 'Pankow', '10435': 'Pankow', '10437': 'Pankow',\n",
    "    '10439': 'Pankow', '13051': 'Pankow', '13053': 'Pankow', '13055': 'Pankow', '13057': 'Pankow',\n",
    "    '13059': 'Pankow', '13086': 'Pankow', '13088': 'Pankow', '13089': 'Pankow', '13125': 'Pankow',\n",
    "    '13127': 'Pankow', '13129': 'Pankow', '13156': 'Pankow', '13158': 'Pankow', '13159': 'Pankow',\n",
    "    '13187': 'Pankow', '13189': 'Pankow', '13191': 'Pankow', '13193': 'Pankow', '13195': 'Pankow',\n",
    "    '13197': 'Pankow', '13469': 'Pankow',\n",
    "    \n",
    "    # Charlottenburg-Wilmersdorf\n",
    "    '10585': 'Charlottenburg-Wilmersdorf', '10587': 'Charlottenburg-Wilmersdorf',\n",
    "    '10589': 'Charlottenburg-Wilmersdorf', '10623': 'Charlottenburg-Wilmersdorf',\n",
    "    '10625': 'Charlottenburg-Wilmersdorf', '10627': 'Charlottenburg-Wilmersdorf',\n",
    "    '10629': 'Charlottenburg-Wilmersdorf', '10707': 'Charlottenburg-Wilmersdorf',\n",
    "    '10709': 'Charlottenburg-Wilmersdorf', '10711': 'Charlottenburg-Wilmersdorf',\n",
    "    '10713': 'Charlottenburg-Wilmersdorf', '10715': 'Charlottenburg-Wilmersdorf',\n",
    "    '10717': 'Charlottenburg-Wilmersdorf', '10719': 'Charlottenburg-Wilmersdorf',\n",
    "    '10777': 'Charlottenburg-Wilmersdorf', '10779': 'Charlottenburg-Wilmersdorf',\n",
    "    '10781': 'Charlottenburg-Wilmersdorf', '10783': 'Charlottenburg-Wilmersdorf',\n",
    "    '10785': 'Charlottenburg-Wilmersdorf', '10787': 'Charlottenburg-Wilmersdorf',\n",
    "    '10789': 'Charlottenburg-Wilmersdorf', '14050': 'Charlottenburg-Wilmersdorf',\n",
    "    '14052': 'Charlottenburg-Wilmersdorf', '14055': 'Charlottenburg-Wilmersdorf',\n",
    "    '14057': 'Charlottenburg-Wilmersdorf', '14059': 'Charlottenburg-Wilmersdorf',\n",
    "    '14193': 'Charlottenburg-Wilmersdorf', '14195': 'Charlottenburg-Wilmersdorf',\n",
    "    '14197': 'Charlottenburg-Wilmersdorf', '14199': 'Charlottenburg-Wilmersdorf',\n",
    "    \n",
    "    # Spandau\n",
    "    '13581': 'Spandau', '13583': 'Spandau', '13585': 'Spandau', '13587': 'Spandau',\n",
    "    '13589': 'Spandau', '13591': 'Spandau', '13593': 'Spandau', '13595': 'Spandau',\n",
    "    '13597': 'Spandau', '13599': 'Spandau', '14052': 'Spandau', '14089': 'Spandau',\n",
    "    '14612': 'Spandau', '14624': 'Spandau', '14641': 'Spandau', '14656': 'Spandau',\n",
    "    '14669': 'Spandau',\n",
    "    \n",
    "    # Steglitz-Zehlendorf\n",
    "    '12163': 'Steglitz-Zehlendorf', '12165': 'Steglitz-Zehlendorf', '12167': 'Steglitz-Zehlendorf',\n",
    "    '12169': 'Steglitz-Zehlendorf', '12203': 'Steglitz-Zehlendorf', '12205': 'Steglitz-Zehlendorf',\n",
    "    '12207': 'Steglitz-Zehlendorf', '12209': 'Steglitz-Zehlendorf', '12247': 'Steglitz-Zehlendorf',\n",
    "    '12249': 'Steglitz-Zehlendorf', '14129': 'Steglitz-Zehlendorf', '14163': 'Steglitz-Zehlendorf',\n",
    "    '14165': 'Steglitz-Zehlendorf', '14167': 'Steglitz-Zehlendorf', '14169': 'Steglitz-Zehlendorf',\n",
    "    '14195': 'Steglitz-Zehlendorf', '14532': 'Steglitz-Zehlendorf', '14548': 'Steglitz-Zehlendorf',\n",
    "    '14552': 'Steglitz-Zehlendorf', '14554': 'Steglitz-Zehlendorf', '14558': 'Steglitz-Zehlendorf',\n",
    "    '14624': 'Steglitz-Zehlendorf', '14636': 'Steglitz-Zehlendorf',\n",
    "    \n",
    "    # Tempelhof-Schöneberg\n",
    "    '10777': 'Tempelhof-Schöneberg', '10779': 'Tempelhof-Schöneberg', '10781': 'Tempelhof-Schöneberg',\n",
    "    '10783': 'Tempelhof-Schöneberg', '10785': 'Tempelhof-Schöneberg', '10787': 'Tempelhof-Schöneberg',\n",
    "    '10789': 'Tempelhof-Schöneberg', '10823': 'Tempelhof-Schöneberg', '10825': 'Tempelhof-Schöneberg',\n",
    "    '10827': 'Tempelhof-Schöneberg', '10829': 'Tempelhof-Schöneberg', '12101': 'Tempelhof-Schöneberg',\n",
    "    '12103': 'Tempelhof-Schöneberg', '12105': 'Tempelhof-Schöneberg', '12107': 'Tempelhof-Schöneberg',\n",
    "    '12109': 'Tempelhof-Schöneberg', '12157': 'Tempelhof-Schöneberg', '12159': 'Tempelhof-Schöneberg',\n",
    "    '12161': 'Tempelhof-Schöneberg', '12163': 'Tempelhof-Schöneberg', '12165': 'Tempelhof-Schöneberg',\n",
    "    '12167': 'Tempelhof-Schöneberg', '12169': 'Tempelhof-Schöneberg', '12279': 'Tempelhof-Schöneberg',\n",
    "    '12307': 'Tempelhof-Schöneberg', '12309': 'Tempelhof-Schöneberg', '14197': 'Tempelhof-Schöneberg',\n",
    "    \n",
    "    # Neukölln\n",
    "    '12043': 'Neukölln', '12045': 'Neukölln', '12047': 'Neukölln', '12049': 'Neukölln',\n",
    "    '12051': 'Neukölln', '12053': 'Neukölln', '12055': 'Neukölln', '12057': 'Neukölln',\n",
    "    '12059': 'Neukölln', '12099': 'Neukölln', '12347': 'Neukölln', '12349': 'Neukölln',\n",
    "    '12351': 'Neukölln', '12353': 'Neukölln', '12355': 'Neukölln', '12357': 'Neukölln',\n",
    "    '12359': 'Neukölln', '12526': 'Neukölln', '12527': 'Neukölln', '12529': 'Neukölln',\n",
    "    \n",
    "    # Treptow-Köpenick\n",
    "    '12435': 'Treptow-Köpenick', '12437': 'Treptow-Köpenick', '12439': 'Treptow-Köpenick',\n",
    "    '12459': 'Treptow-Köpenick', '12487': 'Treptow-Köpenick', '12489': 'Treptow-Köpenick',\n",
    "    '12524': 'Treptow-Köpenick', '12526': 'Treptow-Köpenick', '12527': 'Treptow-Köpenick',\n",
    "    '12555': 'Treptow-Köpenick', '12557': 'Treptow-Köpenick', '12559': 'Treptow-Köpenick',\n",
    "    '12587': 'Treptow-Köpenick', '12589': 'Treptow-Köpenick', '12623': 'Treptow-Köpenick',\n",
    "    '12679': 'Treptow-Köpenick', '12681': 'Treptow-Köpenick', '12683': 'Treptow-Köpenick',\n",
    "    '12685': 'Treptow-Köpenick', '12687': 'Treptow-Köpenick', '12689': 'Treptow-Köpenick',\n",
    "    \n",
    "    # Marzahn-Hellersdorf\n",
    "    '12619': 'Marzahn-Hellersdorf', '12621': 'Marzahn-Hellersdorf', '12623': 'Marzahn-Hellersdorf',\n",
    "    '12627': 'Marzahn-Hellersdorf', '12629': 'Marzahn-Hellersdorf', '12679': 'Marzahn-Hellersdorf',\n",
    "    '12681': 'Marzahn-Hellersdorf', '12683': 'Marzahn-Hellersdorf', '12685': 'Marzahn-Hellersdorf',\n",
    "    '12687': 'Marzahn-Hellersdorf', '12689': 'Marzahn-Hellersdorf', '12691': 'Marzahn-Hellersdorf',\n",
    "    '12693': 'Marzahn-Hellersdorf', '12695': 'Marzahn-Hellersdorf', '12697': 'Marzahn-Hellersdorf',\n",
    "    '12699': 'Marzahn-Hellersdorf',\n",
    "    \n",
    "    # Lichtenberg\n",
    "    '10315': 'Lichtenberg', '10317': 'Lichtenberg', '10318': 'Lichtenberg', '10319': 'Lichtenberg',\n",
    "    '10365': 'Lichtenberg', '10367': 'Lichtenberg', '10369': 'Lichtenberg', '13051': 'Lichtenberg',\n",
    "    '13053': 'Lichtenberg', '13055': 'Lichtenberg', '13057': 'Lichtenberg', '13059': 'Lichtenberg',\n",
    "    '13086': 'Lichtenberg', '13088': 'Lichtenberg', '13089': 'Lichtenberg', '13125': 'Lichtenberg',\n",
    "    '13127': 'Lichtenberg', '13129': 'Lichtenberg', '13156': 'Lichtenberg', '13158': 'Lichtenberg',\n",
    "    '13159': 'Lichtenberg', '13187': 'Lichtenberg', '13189': 'Lichtenberg', '13191': 'Lichtenberg',\n",
    "    '13193': 'Lichtenberg', '13195': 'Lichtenberg', '13197': 'Lichtenberg',\n",
    "    \n",
    "    # Reinickendorf\n",
    "    '13403': 'Reinickendorf', '13405': 'Reinickendorf', '13407': 'Reinickendorf', '13409': 'Reinickendorf',\n",
    "    '13435': 'Reinickendorf', '13437': 'Reinickendorf', '13439': 'Reinickendorf', '13465': 'Reinickendorf',\n",
    "    '13467': 'Reinickendorf', '13469': 'Reinickendorf', '13503': 'Reinickendorf', '13505': 'Reinickendorf',\n",
    "    '13507': 'Reinickendorf', '13509': 'Reinickendorf', '13627': 'Reinickendorf', '13629': 'Reinickendorf',\n",
    "    '13631': 'Reinickendorf', '13633': 'Reinickendorf', '13635': 'Reinickendorf', '13637': 'Reinickendorf',\n",
    "    '13639': 'Reinickendorf',\n",
    "}\n",
    "\n",
    "# Erstelle DataFrame aus der Mapping-Tabelle\n",
    "plz_mapping_df = pd.DataFrame(list(berlin_plz_mapping.items()), columns=['PLZ', 'Bezirk'])\n",
    "\n",
    "print(f\"PLZ-Mapping-Tabelle erstellt!\")\n",
    "print(f\"Anzahl PLZ-Zuordnungen: {len(plz_mapping_df)}\")\n",
    "print(f\"Anzahl Bezirke: {plz_mapping_df['Bezirk'].nunique()}\")\n",
    "\n",
    "print(f\"\\nBezirke in der Mapping-Tabelle:\")\n",
    "for bezirk in sorted(plz_mapping_df['Bezirk'].unique()):\n",
    "    count = len(plz_mapping_df[plz_mapping_df['Bezirk'] == bezirk])\n",
    "    print(f\"  {bezirk}: {count} PLZ\")\n",
    "\n",
    "print(f\"\\nMapping-Tabelle wird am Ende des Notebooks exportiert.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80373751",
   "metadata": {},
   "source": [
    "### Validierung: Überprüfung der PLZ-Zuordnung für Dataset 2022"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d87bb59",
   "metadata": {},
   "source": [
    "## Multi-Listing Detection and Handling (2025 Dataset)\n",
    "\n",
    "Das 2025 Dataset enthält Multi-Listing-Einträge, die mehrere Wohnungsangebote in einer einzigen Zeile zusammenfassen. Diese Einträge sind erkennbar an:\n",
    "\n",
    "1. **Titel-Muster**: \"X passende Wohneinheiten: ...\" (z.B. \"6 passende Wohneinheiten: 199 Neubau-Wohnungen...\")\n",
    "2. **Preis-Bereiche**: \"min - max €\" (z.B. \"725 - 1.965 €\")\n",
    "3. **Größen-Bereiche**: \"min,xx - max,xx m²\" (z.B. \"26,55 - 112,82 m²\")\n",
    "\n",
    "**Bereinigungsstrategie**:\n",
    "- **Erkennung**: Identifizierung von Multi-Listing-Einträgen durch Analyse von Titel und Preis-/Größenbereichen\n",
    "- **Aufteilen**: Extraktion der Anzahl der Wohneinheiten aus dem Titel\n",
    "- **Einzeleinträge generieren**: Erstellung separater Datensätze für jede Wohneinheit mit durchschnittlichen Werten\n",
    "- **Dokumentation**: Markierung der ursprünglichen Multi-Listing-Einträge zur Nachverfolgung\n",
    "\n",
    "**Rationale**: \n",
    "- Multi-Listing-Einträge verzerren statistische Analysen, da sie mehrere Wohnungen als einen Datensatz darstellen\n",
    "- Durch Aufteilen erhalten wir eine realistischere Darstellung der Marktverteilung\n",
    "- Durchschnittswerte sind eine angemessene Schätzung bei fehlenden Einzeldaten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5eba3194",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multi-Listing-Verarbeitungsfunktionen definiert.\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "\n",
    "def detect_multi_listing(title, price, size):\n",
    "    \"\"\"\n",
    "    Erkennt Multi-Listing-Einträge anhand von Titel, Preis und Größe.\n",
    "    \n",
    "    Args:\n",
    "        title (str): Titel des Eintrags\n",
    "        price (str): Preis des Eintrags\n",
    "        size (str): Größe des Eintrags\n",
    "    \n",
    "    Returns:\n",
    "        dict: {'is_multi': bool, 'count': int, 'price_range': tuple, 'size_range': tuple}\n",
    "    \"\"\"\n",
    "    result = {\n",
    "        'is_multi': False,\n",
    "        'count': 1,\n",
    "        'price_range': None,\n",
    "        'size_range': None\n",
    "    }\n",
    "    \n",
    "    # Prüfe Titel auf Multi-Listing-Muster\n",
    "    title_pattern = r'(\\d+)\\s+passende\\s+Wohneinheiten?'\n",
    "    title_match = re.search(title_pattern, str(title), re.IGNORECASE)\n",
    "    \n",
    "    # Prüfe Preis auf Bereich (z.B. \"725 - 1.965 €\")\n",
    "    price_pattern = r'(\\d+(?:\\.\\d{3})*(?:,\\d+)?)\\s*-\\s*(\\d+(?:\\.\\d{3})*(?:,\\d+)?)\\s*€'\n",
    "    price_match = re.search(price_pattern, str(price))\n",
    "    \n",
    "    # Prüfe Größe auf Bereich (z.B. \"26,55 - 112,82 m²\")\n",
    "    size_pattern = r'(\\d+(?:,\\d+)?)\\s*-\\s*(\\d+(?:,\\d+)?)\\s*m²'\n",
    "    size_match = re.search(size_pattern, str(size))\n",
    "    \n",
    "    if title_match and (price_match or size_match):\n",
    "        result['is_multi'] = True\n",
    "        result['count'] = int(title_match.group(1))\n",
    "        \n",
    "        if price_match:\n",
    "            # Konvertiere Preise (berücksichtige deutsche Zahlenformate)\n",
    "            price_min = float(price_match.group(1).replace('.', '').replace(',', '.'))\n",
    "            price_max = float(price_match.group(2).replace('.', '').replace(',', '.'))\n",
    "            result['price_range'] = (price_min, price_max)\n",
    "        \n",
    "        if size_match:\n",
    "            # Konvertiere Größen\n",
    "            size_min = float(size_match.group(1).replace(',', '.'))\n",
    "            size_max = float(size_match.group(2).replace(',', '.'))\n",
    "            result['size_range'] = (size_min, size_max)\n",
    "    \n",
    "    return result\n",
    "\n",
    "def split_multi_listing(row):\n",
    "    \"\"\"\n",
    "    Teilt einen Multi-Listing-Eintrag in einzelne Einträge auf.\n",
    "    \n",
    "    Args:\n",
    "        row (pd.Series): Eine Zeile des DataFrames\n",
    "    \n",
    "    Returns:\n",
    "        list: Liste von Dictionaries mit den aufgeteilten Einträgen\n",
    "    \"\"\"\n",
    "    detection = detect_multi_listing(row['title'], row['price'], row['size'])\n",
    "    \n",
    "    if not detection['is_multi']:\n",
    "        # Kein Multi-Listing, gib ursprünglichen Eintrag zurück\n",
    "        return [row.to_dict()]\n",
    "    \n",
    "    # Erstelle separate Einträge für jede Wohneinheit\n",
    "    entries = []\n",
    "    count = detection['count']\n",
    "    \n",
    "    for i in range(count):\n",
    "        entry = row.to_dict().copy()\n",
    "        \n",
    "        # Modifiziere Titel (entferne Multi-Listing-Präfix)\n",
    "        title_pattern = r'\\d+\\s+passende\\s+Wohneinheiten?:\\s*'\n",
    "        entry['title'] = re.sub(title_pattern, '', str(entry['title']), flags=re.IGNORECASE)\n",
    "        entry['title'] = f\"{entry['title']} (Unit {i+1}/{count})\"\n",
    "        \n",
    "        # Berechne Durchschnittswerte für numerische Felder\n",
    "        if detection['price_range']:\n",
    "            avg_price = np.mean(detection['price_range'])\n",
    "            entry['price'] = f\"{avg_price:.0f} €\"\n",
    "        \n",
    "        if detection['size_range']:\n",
    "            avg_size = np.mean(detection['size_range'])\n",
    "            entry['size'] = f\"{avg_size:.2f} m²\"\n",
    "        \n",
    "        # Markiere als aufgeteilten Eintrag\n",
    "        entry['is_split_from_multi'] = True\n",
    "        entry['original_multi_count'] = count\n",
    "        \n",
    "        entries.append(entry)\n",
    "    \n",
    "    return entries\n",
    "\n",
    "def process_multi_listings(df):\n",
    "    \"\"\"\n",
    "    Verarbeitet alle Multi-Listing-Einträge in einem DataFrame.\n",
    "    \n",
    "    Args:\n",
    "        df (pd.DataFrame): DataFrame mit potentiellen Multi-Listing-Einträgen\n",
    "    \n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame mit aufgeteilten Einträgen\n",
    "    \"\"\"\n",
    "    print(\"Erkenne und verarbeite Multi-Listing-Einträge...\")\n",
    "    \n",
    "    # Sammle alle aufgeteilten Einträge\n",
    "    all_entries = []\n",
    "    multi_count = 0\n",
    "    \n",
    "    for idx, row in df.iterrows():\n",
    "        entries = split_multi_listing(row)\n",
    "        all_entries.extend(entries)\n",
    "        \n",
    "        if len(entries) > 1:\n",
    "            multi_count += 1\n",
    "            print(f\"  Multi-Listing erkannt: {len(entries)} Einheiten aus '{row['title'][:50]}...'\")\n",
    "    \n",
    "    # Erstelle neuen DataFrame\n",
    "    new_df = pd.DataFrame(all_entries)\n",
    "    \n",
    "    # Füge Spalten hinzu, falls sie nicht existieren\n",
    "    if 'is_split_from_multi' not in new_df.columns:\n",
    "        new_df['is_split_from_multi'] = False\n",
    "    if 'original_multi_count' not in new_df.columns:\n",
    "        new_df['original_multi_count'] = 1\n",
    "    \n",
    "    print(f\"Multi-Listing-Verarbeitung abgeschlossen:\")\n",
    "    print(f\"  - {multi_count} Multi-Listing-Einträge erkannt\")\n",
    "    print(f\"  - {len(df)} ursprüngliche Einträge → {len(new_df)} finale Einträge\")\n",
    "    print(f\"  - {len(new_df) - len(df)} zusätzliche Einträge durch Aufteilen\")\n",
    "    \n",
    "    return new_df\n",
    "\n",
    "print(\"Multi-Listing-Verarbeitungsfunktionen definiert.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "46012f3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VALIDIERUNG DER PLZ-ZUORDNUNG\n",
      "==================================================\n",
      "PLZ im Dataset 2022: 183\n",
      "PLZ mit Bezirk-Zuordnung: 176\n",
      "PLZ ohne Bezirk-Zuordnung: 7\n",
      "Abdeckungsrate: 96.2%\n",
      "\n",
      "Nicht zugeordnete PLZ:\n",
      "   PLZ 10551: 5 Einträge\n",
      "   PLZ 10553: 11 Einträge\n",
      "   PLZ 10555: 2 Einträge\n",
      "   PLZ 12277: 7 Einträge\n",
      "   PLZ 12305: 5 Einträge\n",
      "   PLZ 13351: 14 Einträge\n",
      "   PLZ 14109: 10 Einträge\n",
      "\n",
      "ERGEBNIS DER ZUORDNUNG:\n",
      "Erfolgreich zugeordnet: 2896 von 2950 Einträgen\n",
      "Erfolgsrate: 98.2%\n",
      "\n",
      "Verteilung nach Bezirken:\n",
      "  Lichtenberg: 414 Einträge\n",
      "  Spandau: 339 Einträge\n",
      "  Tempelhof-Schöneberg: 332 Einträge\n",
      "  Reinickendorf: 277 Einträge\n",
      "  Mitte: 276 Einträge\n",
      "  Treptow-Köpenick: 257 Einträge\n",
      "  Marzahn-Hellersdorf: 238 Einträge\n",
      "  Charlottenburg-Wilmersdorf: 212 Einträge\n",
      "  Friedrichshain-Kreuzberg: 175 Einträge\n",
      "  Neukölln: 155 Einträge\n",
      "\n",
      "PROBLEM GELÖST: 2896 Einträge aus dem Dataset 2022 können nun verwendet werden.\n",
      "\n",
      "Mapping-Tabelle exportiert nach: data/processed/berlin_plz_mapping.csv\n"
     ]
    }
   ],
   "source": [
    "# Validierung der PLZ-Zuordnung\n",
    "print(\"VALIDIERUNG DER PLZ-ZUORDNUNG\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Überprüfe welche PLZ aus Dataset 2022 in unserem Mapping vorhanden sind\n",
    "dataset_2022_plz = set(df_2022['PLZ'].dropna().astype(str))\n",
    "mapping_plz = set(plz_mapping_df['PLZ'])\n",
    "\n",
    "# PLZ die zugeordnet werden können\n",
    "matched_plz = dataset_2022_plz.intersection(mapping_plz)\n",
    "unmatched_plz = dataset_2022_plz - mapping_plz\n",
    "\n",
    "print(f\"PLZ im Dataset 2022: {len(dataset_2022_plz)}\")\n",
    "print(f\"PLZ mit Bezirk-Zuordnung: {len(matched_plz)}\")\n",
    "print(f\"PLZ ohne Bezirk-Zuordnung: {len(unmatched_plz)}\")\n",
    "print(f\"Abdeckungsrate: {len(matched_plz)/len(dataset_2022_plz)*100:.1f}%\")\n",
    "\n",
    "if unmatched_plz:\n",
    "    print(f\"\\nNicht zugeordnete PLZ:\")\n",
    "    for plz in sorted(unmatched_plz):\n",
    "        count = len(df_2022[df_2022['PLZ'].astype(str) == plz])\n",
    "        print(f\"   PLZ {plz}: {count} Einträge\")\n",
    "\n",
    "# Teste die Zuordnung\n",
    "df_2022['PLZ_str'] = df_2022['PLZ'].astype(str)\n",
    "df_2022_with_district = df_2022.merge(plz_mapping_df, left_on='PLZ_str', right_on='PLZ', how='left')\n",
    "\n",
    "# Statistik der erfolgreichen Zuordnungen\n",
    "successful_mappings = df_2022_with_district['Bezirk'].notna().sum()\n",
    "total_entries = len(df_2022_with_district)\n",
    "\n",
    "print(f\"\\nERGEBNIS DER ZUORDNUNG:\")\n",
    "print(f\"Erfolgreich zugeordnet: {successful_mappings} von {total_entries} Einträgen\")\n",
    "print(f\"Erfolgsrate: {successful_mappings/total_entries*100:.1f}%\")\n",
    "\n",
    "if successful_mappings > 0:\n",
    "    print(f\"\\nVerteilung nach Bezirken:\")\n",
    "    bezirk_counts = df_2022_with_district['Bezirk'].value_counts()\n",
    "    for bezirk, count in bezirk_counts.head(10).items():\n",
    "        print(f\"  {bezirk}: {count} Einträge\")\n",
    "\n",
    "print(f\"\\nPROBLEM GELÖST: {successful_mappings} Einträge aus dem Dataset 2022 können nun verwendet werden.\")\n",
    "\n",
    "# Exportiere die Mapping-Tabelle in das korrekte Verzeichnis\n",
    "plz_mapping_df.to_csv('data/processed/berlin_plz_mapping.csv', index=False)\n",
    "print(f\"\\nMapping-Tabelle exportiert nach: data/processed/berlin_plz_mapping.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39e16890",
   "metadata": {},
   "source": [
    "## 4. Vollständige Datenbereinigung aller Datasets\n",
    "\n",
    "### Phase 1 erweitert: Von PLZ-Mapping zur kompletten Datenvorverarbeitung\n",
    "\n",
    "Nach erfolgreicher Lösung des PLZ-Problems führen wir nun die **vollständige Datenbereinigung** aller drei Datasets durch und erstellen ein **einheitliches, analysefreundliches Dataset**.\n",
    "\n",
    "### Schritte:\n",
    "1. **PLZ-Mapping auf Dataset 2022 anwenden**\n",
    "2. **Datenbereinigung aller drei Datasets**\n",
    "3. **Normalisierung und Vereinheitlichung**\n",
    "4. **Feature Engineering**\n",
    "5. **Zusammenführung und Export**\n",
    "\n",
    "Das Ziel ist ein **finales Dataset** das direkt für die Analyse in `02_Housing_Market_Analysis.ipynb` verwendet werden kann."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2156ab07",
   "metadata": {},
   "source": [
    "### 4.1 PLZ-Mapping auf Dataset 2022 anwenden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7baa51af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Anwendung des PLZ-Mappings auf Dataset 2022\n",
    "print(\"ANWENDUNG DES PLZ-MAPPINGS AUF DATASET 2022\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Dataset 2022 für Bearbeitung laden\n",
    "df_2022_processing = df_2022.copy()\n",
    "\n",
    "# PLZ als String für Matching\n",
    "df_2022_processing['PLZ_str'] = df_2022_processing['PLZ'].astype(str)\n",
    "\n",
    "# Merge mit PLZ-Mapping\n",
    "df_2022_with_districts = df_2022_processing.merge(\n",
    "    plz_mapping_df, \n",
    "    left_on='PLZ_str', \n",
    "    right_on='PLZ', \n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# Mapping-Statistik\n",
    "total_entries = len(df_2022_with_districts)\n",
    "successful_mappings = df_2022_with_districts['Bezirk'].notna().sum()\n",
    "mapping_rate = (successful_mappings / total_entries) * 100\n",
    "\n",
    "print(f\"Gesamteinträge Dataset 2022: {total_entries:,}\")\n",
    "print(f\"Erfolgreich zugeordnet: {successful_mappings:,}\")\n",
    "print(f\"Zuordnungsrate: {mapping_rate:.1f}%\")\n",
    "\n",
    "# Nur erfolgreich zugeordnete Daten behalten\n",
    "df_2022_clean = df_2022_with_districts[df_2022_with_districts['Bezirk'].notna()].copy()\n",
    "\n",
    "print(f\"\\nDataset 2022 nach PLZ-Bereinigung: {len(df_2022_clean):,} Einträge\")\n",
    "print(f\"Datenverlust: {len(df_2022) - len(df_2022_clean):,} Einträge\")\n",
    "\n",
    "# Zeige Bezirksverteilung\n",
    "print(f\"\\nBezirksverteilung Dataset 2022:\")\n",
    "bezirk_counts = df_2022_clean['Bezirk'].value_counts()\n",
    "for bezirk, count in bezirk_counts.head(10).items():\n",
    "    print(f\"  {bezirk}: {count:,} Einträge\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a84ecf1a",
   "metadata": {},
   "source": [
    "### 4.2 Datenbereinigung und Normalisierung aller Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7cc20951",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "PROJEKTSTRUKTUR NACH PREPROCESSING\n",
      "============================================================\n",
      "\n",
      "Berlin_Housing_Market_Analysis/\n",
      "├── 01_Data_Preprocessing.ipynb\n",
      "├── 02_Housing_Market_Analysis.ipynb\n",
      "├── Berlin_Housing_Market_Analysis.ipynb\n",
      "├── Datasets_Info.md\n",
      "├── Plan.md\n",
      "├── Presentation.md\n",
      "├── README.md\n",
      "├── assets\n",
      "│   ├── Berlin_Housing_Market_Cleaned.csv\n",
      "│   ├── Berlin_Housing_Summary.csv\n",
      "│   └── Berlin_Top_Districts.csv\n",
      "└── data\n",
      "    ├── processed\n",
      "    │   └── berlin_plz_mapping.csv\n",
      "    └── raw\n",
      "        ├── Dataset_2018_2019.csv\n",
      "        ├── Dataset_2022.csv\n",
      "        └── Dataset_2025.csv\n",
      "\n",
      "============================================================\n",
      "PREPROCESSING ERFOLGREICH ABGESCHLOSSEN\n",
      "============================================================\n",
      "✅ PLZ-Mapping-Tabelle erstellt\n",
      "✅ Datenstruktur organisiert\n",
      "✅ Dateien in korrekte Verzeichnisse verschoben\n",
      "✅ Bereit für Phase 2: Hauptanalyse\n",
      "\n",
      "Nächster Schritt: 02_Housing_Market_Analysis.ipynb erstellen\n"
     ]
    }
   ],
   "source": [
    "# Finale Verzeichnisstruktur und Dateien\n",
    "print(\"=\"*60)\n",
    "print(\"PROJEKTSTRUKTUR NACH PREPROCESSING\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "import os\n",
    "\n",
    "def show_directory_structure(path, prefix=\"\", max_depth=3, current_depth=0):\n",
    "    \"\"\"Zeigt die Verzeichnisstruktur an.\"\"\"\n",
    "    if current_depth >= max_depth:\n",
    "        return\n",
    "    \n",
    "    items = sorted(os.listdir(path))\n",
    "    for i, item in enumerate(items):\n",
    "        if item.startswith('.'):\n",
    "            continue\n",
    "            \n",
    "        item_path = os.path.join(path, item)\n",
    "        is_last = i == len(items) - 1\n",
    "        \n",
    "        print(f\"{prefix}{'└── ' if is_last else '├── '}{item}\")\n",
    "        \n",
    "        if os.path.isdir(item_path) and current_depth < max_depth - 1:\n",
    "            extension = \"    \" if is_last else \"│   \"\n",
    "            show_directory_structure(item_path, prefix + extension, max_depth, current_depth + 1)\n",
    "\n",
    "print(\"\\nBerlin_Housing_Market_Analysis/\")\n",
    "show_directory_structure(\".\", max_depth=3)\n",
    "\n",
    "print(f\"\\n\" + \"=\"*60)\n",
    "print(\"PREPROCESSING ERFOLGREICH ABGESCHLOSSEN\")\n",
    "print(\"=\"*60)\n",
    "print(\"✅ PLZ-Mapping-Tabelle erstellt\")\n",
    "print(\"✅ Datenstruktur organisiert\")\n",
    "print(\"✅ Dateien in korrekte Verzeichnisse verschoben\")\n",
    "print(\"✅ Bereit für Phase 2: Hauptanalyse\")\n",
    "print(\"\\nNächster Schritt: 02_Housing_Market_Analysis.ipynb erstellen\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "178c223a",
   "metadata": {},
   "source": [
    "## 3. Datenbereinigung und -normalisierung\n",
    "\n",
    "In diesem Abschnitt bereinigen wir alle Datasets und normalisieren die Daten für konsistente Analysen.\n",
    "\n",
    "### 3.1 Datenbereinigung Funktionen definieren"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "feabb666",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bereinigungsfunktionen definiert.\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "\n",
    "def identify_price_columns(df):\n",
    "    \"\"\"Identifiziert Preisspalten basierend auf Namen und Inhalten.\"\"\"\n",
    "    price_keywords = ['price', 'rent', 'miete', 'preis', 'cost', 'kosten', 'euro', 'eur', '€']\n",
    "    price_columns = []\n",
    "    \n",
    "    for col in df.columns:\n",
    "        if any(keyword in col.lower() for keyword in price_keywords):\n",
    "            price_columns.append(col)\n",
    "    \n",
    "    return price_columns\n",
    "\n",
    "def identify_size_columns(df):\n",
    "    \"\"\"Identifiziert Größenspalten basierend auf Namen und Inhalten.\"\"\"\n",
    "    size_keywords = ['size', 'area', 'space', 'fläche', 'größe', 'qm', 'm²', 'living']\n",
    "    size_columns = []\n",
    "    \n",
    "    for col in df.columns:\n",
    "        if any(keyword in col.lower() for keyword in size_keywords):\n",
    "            size_columns.append(col)\n",
    "    \n",
    "    return size_columns\n",
    "\n",
    "def identify_room_columns(df):\n",
    "    \"\"\"Identifiziert Zimmerspalten basierend auf Namen und Inhalten.\"\"\"\n",
    "    room_keywords = ['room', 'zimmer', 'rooms', 'norooms', 'anzahl']\n",
    "    room_columns = []\n",
    "    \n",
    "    for col in df.columns:\n",
    "        if any(keyword in col.lower() for keyword in room_keywords):\n",
    "            room_columns.append(col)\n",
    "    \n",
    "    return room_columns\n",
    "\n",
    "def clean_price(price_str):\n",
    "    \"\"\"Bereinigt Preisangaben und konvertiert sie zu float.\"\"\"\n",
    "    if pd.isna(price_str):\n",
    "        return np.nan\n",
    "    \n",
    "    # Konvertiere zu String\n",
    "    price_str = str(price_str)\n",
    "    \n",
    "    # Entferne alle nicht-numerischen Zeichen außer Kommas und Punkten\n",
    "    price_str = re.sub(r'[^\\d.,\\-]', '', price_str)\n",
    "    \n",
    "    # Behandle Bereiche (z.B. \"725-1965\") - nimm den Durchschnitt\n",
    "    if '-' in price_str:\n",
    "        parts = price_str.split('-')\n",
    "        if len(parts) == 2:\n",
    "            try:\n",
    "                min_val = float(parts[0].replace(',', '.'))\n",
    "                max_val = float(parts[1].replace(',', '.'))\n",
    "                return (min_val + max_val) / 2\n",
    "            except:\n",
    "                pass\n",
    "    \n",
    "    # Standardbereinigung\n",
    "    if ',' in price_str and '.' in price_str:\n",
    "        # Deutsche Notation (1.234,56)\n",
    "        price_str = price_str.replace('.', '').replace(',', '.')\n",
    "    elif ',' in price_str:\n",
    "        # Prüfe ob es sich um deutsche Dezimalnotation handelt\n",
    "        if price_str.count(',') == 1 and len(price_str.split(',')[1]) <= 2:\n",
    "            price_str = price_str.replace(',', '.')\n",
    "    \n",
    "    try:\n",
    "        return float(price_str)\n",
    "    except:\n",
    "        return np.nan\n",
    "\n",
    "def clean_size(size_str):\n",
    "    \"\"\"Bereinigt Größenangaben und konvertiert sie zu float.\"\"\"\n",
    "    if pd.isna(size_str):\n",
    "        return np.nan\n",
    "    \n",
    "    # Konvertiere zu String\n",
    "    size_str = str(size_str)\n",
    "    \n",
    "    # Entferne alle nicht-numerischen Zeichen außer Kommas und Punkten\n",
    "    size_str = re.sub(r'[^\\d.,\\-]', '', size_str)\n",
    "    \n",
    "    # Behandle Bereiche (z.B. \"26,55-112,82\") - nimm den Durchschnitt\n",
    "    if '-' in size_str:\n",
    "        parts = size_str.split('-')\n",
    "        if len(parts) == 2:\n",
    "            try:\n",
    "                min_val = float(parts[0].replace(',', '.'))\n",
    "                max_val = float(parts[1].replace(',', '.'))\n",
    "                return (min_val + max_val) / 2\n",
    "            except:\n",
    "                pass\n",
    "    \n",
    "    # Standardbereinigung\n",
    "    if ',' in size_str:\n",
    "        size_str = size_str.replace(',', '.')\n",
    "    \n",
    "    try:\n",
    "        return float(size_str)\n",
    "    except:\n",
    "        return np.nan\n",
    "\n",
    "def clean_rooms(room_str):\n",
    "    \"\"\"Bereinigt Zimmeranzahl und konvertiert sie zu float.\"\"\"\n",
    "    if pd.isna(room_str):\n",
    "        return np.nan\n",
    "    \n",
    "    # Konvertiere zu String\n",
    "    room_str = str(room_str)\n",
    "    \n",
    "    # Extrahiere erste Zahl\n",
    "    match = re.search(r'\\d+(?:[.,]\\d+)?', room_str)\n",
    "    if match:\n",
    "        num_str = match.group().replace(',', '.')\n",
    "        try:\n",
    "            return float(num_str)\n",
    "        except:\n",
    "            return np.nan\n",
    "    \n",
    "    return np.nan\n",
    "\n",
    "def standardize_district_names(district_str):\n",
    "    \"\"\"\n",
    "    Standardisiert Bezirksnamen für einheitliche Verwendung.\n",
    "    \"\"\"\n",
    "    if pd.isna(district_str):\n",
    "        return np.nan\n",
    "    \n",
    "    # Konvertiere zu String und bereinige\n",
    "    district_str = str(district_str).strip()\n",
    "    \n",
    "    # Entferne häufige Präfixe/Suffixe\n",
    "    district_str = re.sub(r'^(Berlin[-\\s]?)', '', district_str, flags=re.IGNORECASE)\n",
    "    district_str = re.sub(r'([-\\s]?Berlin)$', '', district_str, flags=re.IGNORECASE)\n",
    "    \n",
    "    # Standardisiere bekannte Bezirksnamen\n",
    "    district_mapping = {\n",
    "        'Charlottenburg-Wilmersdorf': 'Charlottenburg-Wilmersdorf',\n",
    "        'Friedrichshain-Kreuzberg': 'Friedrichshain-Kreuzberg',\n",
    "        'Lichtenberg': 'Lichtenberg',\n",
    "        'Marzahn-Hellersdorf': 'Marzahn-Hellersdorf',\n",
    "        'Mitte': 'Mitte',\n",
    "        'Neukölln': 'Neukölln',\n",
    "        'Pankow': 'Pankow',\n",
    "        'Reinickendorf': 'Reinickendorf',\n",
    "        'Spandau': 'Spandau',\n",
    "        'Steglitz-Zehlendorf': 'Steglitz-Zehlendorf',\n",
    "        'Tempelhof-Schöneberg': 'Tempelhof-Schöneberg',\n",
    "        'Treptow-Köpenick': 'Treptow-Köpenick'\n",
    "    }\n",
    "    \n",
    "    # Fuzzy matching für ähnliche Namen\n",
    "    for standard_name in district_mapping.values():\n",
    "        if standard_name.lower() in district_str.lower() or district_str.lower() in standard_name.lower():\n",
    "            return standard_name\n",
    "    \n",
    "    return district_str\n",
    "\n",
    "print(\"Bereinigungsfunktionen definiert.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39e9648b",
   "metadata": {},
   "source": [
    "### 3.2 Datenbereinigung für alle Datasets durchführen\n",
    "\n",
    "## Dokumentation der Bereinigungsschritte\n",
    "\n",
    "### Rationale für jede Bereinigungsentscheidung\n",
    "\n",
    "#### 1. **Multi-Listing-Behandlung (2025 Dataset)**\n",
    "- **Problem**: Einzelne Zeilen repräsentieren mehrere Wohneinheiten (z.B. \"6 passende Wohneinheiten\")\n",
    "- **Lösung**: Automatische Erkennung und Aufteilen in Einzeleinträge\n",
    "- **Begründung**: Statistische Analysen erfordern individuelle Datenpunkte pro Wohneinheit\n",
    "- **Methode**: Durchschnittswerte für Preis und Größe aus angegebenen Bereichen\n",
    "\n",
    "#### 2. **Preisbereinigung**\n",
    "- **Problem**: Unterschiedliche Formate (€, EUR, mit/ohne Leerzeichen, deutsche Zahlenformate)\n",
    "- **Lösung**: Einheitliche Konvertierung zu numerischen Werten\n",
    "- **Begründung**: Numerische Werte ermöglichen mathematische Operationen und Vergleiche\n",
    "- **Spezialfall**: Preisbereiche werden zu Durchschnittswerten konvertiert\n",
    "\n",
    "#### 3. **Größenbereinigung**\n",
    "- **Problem**: Verschiedene Einheiten (m², qm, verschiedene Dezimaltrennzeichen)\n",
    "- **Lösung**: Normalisierung auf m² mit Punkt als Dezimaltrennzeichen\n",
    "- **Begründung**: Konsistente Einheit für Flächenvergleiche und Berechnungen\n",
    "- **Spezialfall**: Größenbereiche werden zu Durchschnittswerten konvertiert\n",
    "\n",
    "#### 4. **Zimmeranzahl-Bereinigung**\n",
    "- **Problem**: Verschiedene Formate (\"2 Zimmer\", \"2,5\", \"2.5\")\n",
    "- **Lösung**: Extraktion der ersten numerischen Werte\n",
    "- **Begründung**: Standardisierung für Kategorisierung und Analyse\n",
    "\n",
    "#### 5. **Adress- und PLZ-Verarbeitung**\n",
    "- **Problem**: Inkonsistente Adressformate, teilweise nur PLZ verfügbar\n",
    "- **Lösung**: PLZ-Extraktion und Bezirks-Mapping\n",
    "- **Begründung**: Geografische Analyse erfordert einheitliche Standortdaten\n",
    "\n",
    "#### 6. **Umgang mit fehlenden Werten**\n",
    "- **Strategie**: Kennzeichnung als NaN, keine automatische Imputation\n",
    "- **Begründung**: Transparenz über Datenverfügbarkeit, Vermeidung von Verzerrungen\n",
    "- **Nachverarbeitung**: Fehlende Werte werden in der Analyse explizit behandelt\n",
    "\n",
    "### Qualitätskontrolle\n",
    "- **Vor-/Nach-Vergleiche**: Dokumentation der Änderungen bei jedem Schritt\n",
    "- **Validierung**: Überprüfung auf plausible Wertebereiche\n",
    "- **Nachverfolgbarkeit**: Markierung aufgeteilter Multi-Listing-Einträge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "517f1e3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Bereinigung Dataset 2018-2019 ===\n",
      "Ursprüngliche Anzahl Datensätze: 10406\n",
      "Identifizierte Preisspalten: []\n",
      "Identifizierte Flächenspalten: []\n",
      "Identifizierte Zimmerspalten: []\n",
      "Anzahl Datensätze nach Bereinigung: 10406\n",
      "Spalten im Dataset: ['regio3', 'street', 'livingSpace', 'baseRent', 'totalRent', 'noRooms', 'floor', 'typeOfFlat', 'yearConstructed']\n",
      "\\nErste 3 Zeilen nach Bereinigung:\n",
      "            regio3                      street  livingSpace  baseRent  totalRent  noRooms  floor    typeOfFlat  yearConstructed\n",
      "0  Staaken_Spandau           Metropolitan Park        77.00     820.0     1140.0      3.0    0.0  ground_floor              NaN\n",
      "1        Weißensee      B&ouml;rnestra&szlig;e        62.63     808.0      955.0      2.0    0.0  ground_floor           1918.0\n",
      "2            Mitte  Stallschreiberstra&szlig;e        46.40    1150.0     1300.0      2.0    3.0     apartment           2019.0\n"
     ]
    }
   ],
   "source": [
    "# Bereinigung Dataset 2018-2019\n",
    "print(\"=== Bereinigung Dataset 2018-2019 ===\")\n",
    "print(f\"Ursprüngliche Anzahl Datensätze: {len(df_2018_2019)}\")\n",
    "\n",
    "# Erstelle Kopie für Bereinigung\n",
    "df_2018_2019_clean = df_2018_2019.copy()\n",
    "\n",
    "# Identifiziere Spalten basierend auf Inhalt\n",
    "numeric_columns = []\n",
    "price_columns = []\n",
    "area_columns = []\n",
    "room_columns = []\n",
    "\n",
    "for col in df_2018_2019_clean.columns:\n",
    "    sample_values = df_2018_2019_clean[col].dropna().astype(str).head(10)\n",
    "    \n",
    "    # Prüfe auf Preisspalten (enthält Währungszeichen oder hohe Zahlen)\n",
    "    if any(re.search(r'[€$£¥₹]|\\d{3,}', str(val)) for val in sample_values):\n",
    "        if any(re.search(r'[€$£¥₹]', str(val)) for val in sample_values):\n",
    "            price_columns.append(col)\n",
    "        elif col.lower() in ['preis', 'price', 'miete', 'rent', 'kaltmiete', 'warmmiete']:\n",
    "            price_columns.append(col)\n",
    "    \n",
    "    # Prüfe auf Flächenspalten\n",
    "    elif any(re.search(r'(m²|qm|m2|sqm)', str(val), re.IGNORECASE) for val in sample_values):\n",
    "        area_columns.append(col)\n",
    "    elif col.lower() in ['fläche', 'area', 'wohnfläche', 'qm', 'quadratmeter']:\n",
    "        area_columns.append(col)\n",
    "    \n",
    "    # Prüfe auf Zimmerspalten\n",
    "    elif col.lower() in ['zimmer', 'rooms', 'anzahl_zimmer', 'room_count']:\n",
    "        room_columns.append(col)\n",
    "\n",
    "print(f\"Identifizierte Preisspalten: {price_columns}\")\n",
    "print(f\"Identifizierte Flächenspalten: {area_columns}\")\n",
    "print(f\"Identifizierte Zimmerspalten: {room_columns}\")\n",
    "\n",
    "# Bereinige Preisspalten\n",
    "for col in price_columns:\n",
    "    if col in df_2018_2019_clean.columns:\n",
    "        df_2018_2019_clean[col] = df_2018_2019_clean[col].apply(clean_price)\n",
    "\n",
    "# Bereinige Flächenspalten\n",
    "for col in area_columns:\n",
    "    if col in df_2018_2019_clean.columns:\n",
    "        df_2018_2019_clean[col] = df_2018_2019_clean[col].apply(clean_area)\n",
    "\n",
    "# Bereinige Zimmerspalten\n",
    "for col in room_columns:\n",
    "    if col in df_2018_2019_clean.columns:\n",
    "        df_2018_2019_clean[col] = df_2018_2019_clean[col].apply(clean_rooms)\n",
    "\n",
    "# Bereinige Bezirksspalten\n",
    "district_columns = [col for col in df_2018_2019_clean.columns \n",
    "                   if col.lower() in ['bezirk', 'district', 'stadtbezirk', 'ortsteil']]\n",
    "\n",
    "for col in district_columns:\n",
    "    if col in df_2018_2019_clean.columns:\n",
    "        df_2018_2019_clean[col] = df_2018_2019_clean[col].apply(standardize_district_names)\n",
    "\n",
    "print(f\"Anzahl Datensätze nach Bereinigung: {len(df_2018_2019_clean)}\")\n",
    "print(f\"Spalten im Dataset: {list(df_2018_2019_clean.columns)}\")\n",
    "print(\"\\\\nErste 3 Zeilen nach Bereinigung:\")\n",
    "print(df_2018_2019_clean.head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9f48366a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\n=== Bereinigung Dataset 2022 ===\n",
      "Ursprüngliche Anzahl Datensätze: 2950\n",
      "Identifizierte Preisspalten: ['KALTMIETE', 'WARMMIETE']\n",
      "Identifizierte Flächenspalten: []\n",
      "Identifizierte Zimmerspalten: ['ZIMMER']\n",
      "Erfolgreich 0 von 2950 Datensätzen mit Bezirk verknüpft\n",
      "Anzahl Datensätze nach Bereinigung: 2950\n",
      "Spalten im Dataset: ['ID', 'SORTE', 'PLZ', 'KALTMIETE', 'WARMMIETE', 'NEBENKOSTEN', 'KAUTION', 'HEIZUNGSKOSTEN', 'ZIMMER', 'PARKPLAETZE', 'WOHNFLAECHE', 'BAUJAHR', 'ZUSTAND', 'VERfÜGBAR AB', 'ENERGIEEFFIZIENSKLASSE', 'ENERGIEBEDARF/kWh/(m²*a)', 'ENERGIEASUWEIS', 'Etagenheizung', 'Zentralheizung', 'Ofenheizung', 'offener Kamin', 'Luft-/Wasser-Wärmepumpe', 'Gas', 'Öl', 'Solar', 'Strom', 'Holz', 'Fernwärme', 'Erdwärme', 'Pellets', 'Kohle', 'Flüssiggas', 'KfW 55', 'Niedrigenergie', 'KfW 40', 'KfW 60', 'KfW 70', 'Neubaustandard', 'möbliert', 'teilweise möbliert', 'Alarmanlage', 'Garage', 'Carport', 'Tiefgarage', 'Duplex', 'Stellplatz', 'Klimaanlage', 'Sauna', 'Schwimmbad', 'See', 'Berge', 'Personenaufzug', 'Lastenaufzug', 'Keller', 'Waschraum', 'Bibliothek', 'Terrasse', 'Balkon', 'Garten', 'Einbauküche', 'Dusche', 'Badewanne', 'Bad mit Fenster', 'Gäste-WC', 'Fliesen', 'Parkett', 'Holz/Dielen', 'Laminat', 'Teppich', 'PVC/Linoleum', 'Stein', 'Marmor', 'Doppelboden', 'Terracotta', 'Sonstiges', 'PLZ_str', 'Bezirk']\n",
      "\\nErste 3 Zeilen nach Bereinigung:\n",
      "         ID              SORTE    PLZ  KALTMIETE  WARMMIETE  NEBENKOSTEN  KAUTION  HEIZUNGSKOSTEN  ZIMMER  PARKPLAETZE  WOHNFLAECHE  BAUJAHR  ZUSTAND         VERfÜGBAR AB ENERGIEEFFIZIENSKLASSE  ENERGIEBEDARF/kWh/(m²*a)     ENERGIEASUWEIS  Etagenheizung  Zentralheizung  Ofenheizung  offener Kamin  Luft-/Wasser-Wärmepumpe  Gas   Öl  Solar  Strom  Holz  Fernwärme  Erdwärme  Pellets  Kohle  Flüssiggas  KfW 55  Niedrigenergie  KfW 40  KfW 60  KfW 70  Neubaustandard  möbliert  teilweise möbliert  Alarmanlage  Garage  Carport  Tiefgarage  Duplex  Stellplatz  Klimaanlage  Sauna  Schwimmbad  See  Berge  Personenaufzug  Lastenaufzug  Keller  Waschraum  Bibliothek  Terrasse  Balkon  Garten  Einbauküche  Dusche  Badewanne  Bad mit Fenster  Gäste-WC  Fliesen  Parkett  Holz/Dielen  Laminat  Teppich  PVC/Linoleum  Stein  Marmor  Doppelboden  Terracotta  Sonstiges PLZ_str Bezirk\n",
      "0  47565378  Souterrainwohnung  13125     860.00     995.00        135.0  2500.00             NaN     3.0          NaN        73.00      NaN  saniert  2022-05-01 00:00:00               Klasse D                    117.21     BEDARFSAUSWEIS            1.0             0.0          0.0            0.0                      0.0  1.0  0.0    0.0    0.0   0.0        0.0       0.0      0.0    0.0         0.0     NaN             NaN     NaN     NaN     NaN             NaN       NaN                 NaN          0.0     NaN      NaN         NaN     NaN         NaN          0.0    NaN         NaN  NaN    NaN             NaN           NaN     NaN        NaN         NaN       NaN     NaN     NaN          NaN     1.0        1.0              1.0       0.0      NaN      NaN          NaN      NaN      NaN           NaN    NaN     NaN          NaN         NaN        NaN   13125    NaN\n",
      "1  47482014      Etagenwohnung  13125     450.28     592.28         69.0  1350.84             NaN     2.0          NaN        48.84   1998.0      NaN  2022-06-15 00:00:00               Klasse D                    112.00  VERBRAUCHSAUSWEIS            NaN             NaN          NaN            NaN                      NaN  NaN  NaN    NaN    NaN   NaN        NaN       NaN      NaN    NaN         NaN     NaN             NaN     NaN     NaN     NaN             NaN       NaN                 NaN          0.0     NaN      NaN         NaN     NaN         NaN          0.0    NaN         NaN  NaN    NaN             NaN           NaN     NaN        NaN         NaN       NaN     NaN     NaN          1.0     1.0        1.0              0.0       0.0      NaN      NaN          NaN      NaN      NaN           NaN    NaN     NaN          NaN         NaN        NaN   13125    NaN\n",
      "2  47553106      Etagenwohnung  13125     739.00     817.00         78.0  2217.00             NaN     2.0          NaN        54.79      NaN      NaN  2022-07-01 00:00:00               Klasse C                     78.50  VERBRAUCHSAUSWEIS            NaN             NaN          NaN            NaN                      NaN  NaN  NaN    NaN    NaN   NaN        NaN       NaN      NaN    NaN         NaN     NaN             NaN     NaN     NaN     NaN             NaN       NaN                 NaN          0.0     NaN      NaN         NaN     NaN         NaN          0.0    NaN         NaN  NaN    NaN             NaN           NaN     1.0        0.0         0.0       0.0     1.0     0.0          1.0     1.0        1.0              0.0       0.0      NaN      NaN          NaN      NaN      NaN           NaN    NaN     NaN          NaN         NaN        NaN   13125    NaN\n"
     ]
    }
   ],
   "source": [
    "# Bereinigung Dataset 2022\n",
    "print(\"\\\\n=== Bereinigung Dataset 2022 ===\")\n",
    "print(f\"Ursprüngliche Anzahl Datensätze: {len(df_2022)}\")\n",
    "\n",
    "# Erstelle Kopie für Bereinigung\n",
    "df_2022_clean = df_2022.copy()\n",
    "\n",
    "# Identifiziere Spalten basierend auf Inhalt\n",
    "price_columns_2022 = []\n",
    "area_columns_2022 = []\n",
    "room_columns_2022 = []\n",
    "\n",
    "for col in df_2022_clean.columns:\n",
    "    sample_values = df_2022_clean[col].dropna().astype(str).head(10)\n",
    "    \n",
    "    # Prüfe auf Preisspalten\n",
    "    if any(re.search(r'[€$£¥₹]|\\d{3,}', str(val)) for val in sample_values):\n",
    "        if any(re.search(r'[€$£¥₹]', str(val)) for val in sample_values):\n",
    "            price_columns_2022.append(col)\n",
    "        elif col.lower() in ['preis', 'price', 'miete', 'rent', 'kaltmiete', 'warmmiete']:\n",
    "            price_columns_2022.append(col)\n",
    "    \n",
    "    # Prüfe auf Flächenspalten\n",
    "    elif any(re.search(r'(m²|qm|m2|sqm)', str(val), re.IGNORECASE) for val in sample_values):\n",
    "        area_columns_2022.append(col)\n",
    "    elif col.lower() in ['fläche', 'area', 'wohnfläche', 'qm', 'quadratmeter']:\n",
    "        area_columns_2022.append(col)\n",
    "    \n",
    "    # Prüfe auf Zimmerspalten\n",
    "    elif col.lower() in ['zimmer', 'rooms', 'anzahl_zimmer', 'room_count']:\n",
    "        room_columns_2022.append(col)\n",
    "\n",
    "print(f\"Identifizierte Preisspalten: {price_columns_2022}\")\n",
    "print(f\"Identifizierte Flächenspalten: {area_columns_2022}\")\n",
    "print(f\"Identifizierte Zimmerspalten: {room_columns_2022}\")\n",
    "\n",
    "# Bereinige Preisspalten\n",
    "for col in price_columns_2022:\n",
    "    if col in df_2022_clean.columns:\n",
    "        df_2022_clean[col] = df_2022_clean[col].apply(clean_price)\n",
    "\n",
    "# Bereinige Flächenspalten\n",
    "for col in area_columns_2022:\n",
    "    if col in df_2022_clean.columns:\n",
    "        df_2022_clean[col] = df_2022_clean[col].apply(clean_area)\n",
    "\n",
    "# Bereinige Zimmerspalten\n",
    "for col in room_columns_2022:\n",
    "    if col in df_2022_clean.columns:\n",
    "        df_2022_clean[col] = df_2022_clean[col].apply(clean_rooms)\n",
    "\n",
    "# Bereinige Bezirksspalten\n",
    "district_columns_2022 = [col for col in df_2022_clean.columns \n",
    "                        if col.lower() in ['bezirk', 'district', 'stadtbezirk', 'ortsteil']]\n",
    "\n",
    "for col in district_columns_2022:\n",
    "    if col in df_2022_clean.columns:\n",
    "        df_2022_clean[col] = df_2022_clean[col].apply(standardize_district_names)\n",
    "\n",
    "# Füge Bezirksinformationen basierend auf PLZ-Mapping hinzu\n",
    "if 'PLZ' in df_2022_clean.columns:\n",
    "    df_2022_clean['Bezirk'] = df_2022_clean['PLZ'].map(berlin_plz_to_district)\n",
    "    mapping_success = df_2022_clean['Bezirk'].notna().sum()\n",
    "    print(f\"Erfolgreich {mapping_success} von {len(df_2022_clean)} Datensätzen mit Bezirk verknüpft\")\n",
    "\n",
    "print(f\"Anzahl Datensätze nach Bereinigung: {len(df_2022_clean)}\")\n",
    "print(f\"Spalten im Dataset: {list(df_2022_clean.columns)}\")\n",
    "print(\"\\\\nErste 3 Zeilen nach Bereinigung:\")\n",
    "print(df_2022_clean.head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "832a55df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\n=== Bereinigung Dataset 2025 ===\n",
      "Ursprüngliche Anzahl Datensätze: 6109\n",
      "\n",
      "Beispiele für Multi-Listing-Einträge:\n",
      "  - 6 passende Wohneinheiten: 199 Neubau-Wohnungen von 1 bis 4 Z...\n",
      "    Preis: 725 - 1.965 €, Größe: 26,55 - 112,82 m²\n",
      "  - 2 passende Wohneinheiten: Naturnah wohnen, Urbanität genieße...\n",
      "    Preis: 785 - 1.945 €, Größe: 36,81 - 129,39 m²\n",
      "  - 4 passende Wohneinheiten: Möblierte Wohnungen in Berlin-Char...\n",
      "    Preis: 1.261 - 1.411 €, Größe: 18,31 - 46,37 m²\n",
      "\n",
      "Verarbeite Multi-Listing-Einträge...\n",
      "Erkenne und verarbeite Multi-Listing-Einträge...\n",
      "  Multi-Listing erkannt: 6 Einheiten aus '6 passende Wohneinheiten: 199 Neubau-Wohnungen von...'\n",
      "  Multi-Listing erkannt: 2 Einheiten aus '2 passende Wohneinheiten: Naturnah wohnen, Urbanit...'\n",
      "  Multi-Listing erkannt: 4 Einheiten aus '4 passende Wohneinheiten: Möblierte Wohnungen in B...'\n",
      "  Multi-Listing erkannt: 7 Einheiten aus '7 passende Wohneinheiten: LAIKA AM TACHELES: Erstk...'\n",
      "  Multi-Listing erkannt: 55 Einheiten aus '55 passende Wohneinheiten: Halske Gärten: Lichtdur...'\n",
      "  Multi-Listing erkannt: 11 Einheiten aus '11 passende Wohneinheiten: Ein Zuhause voller Vorz...'\n",
      "  Multi-Listing erkannt: 4 Einheiten aus '4 passende Wohneinheiten: Über den Dächern Berlins...'\n",
      "  Multi-Listing erkannt: 45 Einheiten aus '45 passende Wohneinheiten: Pufendorfstraße 3 d u. ...'\n",
      "  Multi-Listing erkannt: 5 Einheiten aus '5 passende Wohneinheiten: Moderne Neubau-Wohnungen...'\n",
      "  Multi-Listing erkannt: 7 Einheiten aus '7 passende Wohneinheiten: Your Home, Your Peace...'\n",
      "  Multi-Listing erkannt: 16 Einheiten aus '16 passende Wohneinheiten: Finden Sie Ihren Liebli...'\n",
      "  Multi-Listing erkannt: 7 Einheiten aus '7 passende Wohneinheiten: Spreeduett - Erstbezug i...'\n",
      "  Multi-Listing erkannt: 16 Einheiten aus '16 passende Wohneinheiten: Wohnen mitten in Mitte ...'\n",
      "  Multi-Listing erkannt: 5 Einheiten aus '5 passende Wohneinheiten: MOA WOOD -...'\n",
      "  Multi-Listing erkannt: 6 Einheiten aus '6 passende Wohneinheiten: Vollmöblierte Design-Apa...'\n",
      "  Multi-Listing erkannt: 15 Einheiten aus '15 passende Wohneinheiten: Stilvoll wohnen – zwisc...'\n",
      "  Multi-Listing erkannt: 17 Einheiten aus '17 passende Wohneinheiten: Drei individuelle Häuse...'\n",
      "  Multi-Listing erkannt: 2 Einheiten aus '2 passende Wohneinheiten: 288 Neubau-Wohnungen...'\n",
      "  Multi-Listing erkannt: 5 Einheiten aus '5 passende Wohneinheiten: Erstbezug nach Bau in be...'\n",
      "  Multi-Listing erkannt: 3 Einheiten aus '3 passende Wohneinheiten: Havelufer Quartier...'\n",
      "  Multi-Listing erkannt: 6 Einheiten aus '6 passende Wohneinheiten: 67 Mietwohnungen und Tie...'\n",
      "  Multi-Listing erkannt: 4 Einheiten aus '4 passende Wohneinheiten: Willkommen in Ihrer voll...'\n",
      "  Multi-Listing erkannt: 6 Einheiten aus '6 passende Wohneinheiten: Heimathafen Grünauer Str...'\n",
      "  Multi-Listing erkannt: 12 Einheiten aus '12 passende Wohneinheiten: Altbau-Charme trifft mo...'\n",
      "  Multi-Listing erkannt: 2 Einheiten aus '2 passende Wohneinheiten: Wohnen in Berlin City...'\n",
      "  Multi-Listing erkannt: 3 Einheiten aus '3 passende Wohneinheiten: Wohnen in und am Wassert...'\n",
      "  Multi-Listing erkannt: 4 Einheiten aus '4 passende Wohneinheiten: Wohnpark St. Marien...'\n",
      "  Multi-Listing erkannt: 4 Einheiten aus '4 passende Wohneinheiten: Wohnpark St. Marien...'\n",
      "  Multi-Listing erkannt: 7 Einheiten aus '7 passende Wohneinheiten: Neubauprojekt Beethovens...'\n",
      "  Multi-Listing erkannt: 13 Einheiten aus '13 passende Wohneinheiten: Sonne im Dachgeschoss: ...'\n",
      "  Multi-Listing erkannt: 2 Einheiten aus '2 passende Wohneinheiten: * EXKLUSIVER NEUBAU - IM...'\n",
      "  Multi-Listing erkannt: 5 Einheiten aus '5 passende Wohneinheiten: Willkommen in der Woldeg...'\n",
      "  Multi-Listing erkannt: 2 Einheiten aus '2 passende Wohneinheiten: Urbanes Wohnen im Grünen...'\n",
      "  Multi-Listing erkannt: 4 Einheiten aus '4 passende Wohneinheiten: ***Erstbezug*** Lichtdur...'\n",
      "  Multi-Listing erkannt: 4 Einheiten aus '4 passende Wohneinheiten: Barrierearme Einzimmerwo...'\n",
      "  Multi-Listing erkannt: 14 Einheiten aus '14 passende Wohneinheiten: JETZT BEZUGSFERTIG - Ve...'\n",
      "  Multi-Listing erkannt: 7 Einheiten aus '7 passende Wohneinheiten: Im lebendigen Stadtteil ...'\n",
      "  Multi-Listing erkannt: 4 Einheiten aus '4 passende Wohneinheiten: Attraktive 3-4-Zimmer-Wo...'\n",
      "  Multi-Listing erkannt: 2 Einheiten aus '2 passende Wohneinheiten: Noble Architektenvilla m...'\n",
      "  Multi-Listing erkannt: 4 Einheiten aus '4 passende Wohneinheiten: Möblierte Neubau-Apartme...'\n",
      "  Multi-Listing erkannt: 8 Einheiten aus '8 passende Wohneinheiten: Erstbezug von 11 hochwer...'\n",
      "Multi-Listing-Verarbeitung abgeschlossen:\n",
      "  - 41 Multi-Listing-Einträge erkannt\n",
      "  - 6109 ursprüngliche Einträge → 6423 finale Einträge\n",
      "  - 314 zusätzliche Einträge durch Aufteilen\n",
      "Identifizierte Preisspalten: ['price']\n",
      "Identifizierte Flächenspalten: ['size']\n",
      "Identifizierte Zimmerspalten: []\n",
      "Anzahl Datensätze nach Multi-Listing-Verarbeitung und Bereinigung: 6423\n",
      "Spalten im Dataset: ['title', 'price', 'size', 'address', 'link', 'is_split_from_multi', 'original_multi_count']\n",
      "Anzahl aufgeteilter Einträge: 355\n",
      "Ursprüngliche Multi-Listings: 16\n",
      "\n",
      "Erste 3 Zeilen nach Verarbeitung:\n",
      "                                                                                          title   price   size                                  address\n",
      "0  199 Neubau-Wohnungen von 1 bis 4 Zimmern in einem der grünsten Stadtteile Berlins (Unit 1/6)  1345.0  69.69  Biedenkopfer Straße 46-54, 13507 Berlin\n",
      "1  199 Neubau-Wohnungen von 1 bis 4 Zimmern in einem der grünsten Stadtteile Berlins (Unit 2/6)  1345.0  69.69  Biedenkopfer Straße 46-54, 13507 Berlin\n",
      "2  199 Neubau-Wohnungen von 1 bis 4 Zimmern in einem der grünsten Stadtteile Berlins (Unit 3/6)  1345.0  69.69  Biedenkopfer Straße 46-54, 13507 Berlin\n"
     ]
    }
   ],
   "source": [
    "# Bereinigung Dataset 2025\n",
    "print(\"\\\\n=== Bereinigung Dataset 2025 ===\")\n",
    "df_2025 = pd.read_csv('data/raw/Dataset_2025.csv')\n",
    "print(f\"Ursprüngliche Anzahl Datensätze: {len(df_2025)}\")\n",
    "\n",
    "# Zeige ein paar Beispiele für Multi-Listing-Einträge\n",
    "print(\"\\nBeispiele für Multi-Listing-Einträge:\")\n",
    "multi_examples = df_2025[df_2025['title'].str.contains(r'\\d+\\s+passende\\s+Wohneinheiten?', case=False, na=False)].head(3)\n",
    "for idx, row in multi_examples.iterrows():\n",
    "    print(f\"  - {row['title'][:60]}...\")\n",
    "    print(f\"    Preis: {row['price']}, Größe: {row['size']}\")\n",
    "\n",
    "# Verarbeite Multi-Listing-Einträge BEVOR andere Bereinigungen\n",
    "print(f\"\\nVerarbeite Multi-Listing-Einträge...\")\n",
    "df_2025_processed = process_multi_listings(df_2025)\n",
    "\n",
    "# Jetzt führe normale Bereinigungen durch\n",
    "price_columns = identify_price_columns(df_2025_processed)\n",
    "size_columns = identify_size_columns(df_2025_processed)\n",
    "room_columns = identify_room_columns(df_2025_processed)\n",
    "\n",
    "print(f\"Identifizierte Preisspalten: {price_columns}\")\n",
    "print(f\"Identifizierte Flächenspalten: {size_columns}\")\n",
    "print(f\"Identifizierte Zimmerspalten: {room_columns}\")\n",
    "\n",
    "# Bereinige numerische Werte\n",
    "for col in price_columns:\n",
    "    df_2025_processed[col] = df_2025_processed[col].apply(clean_price)\n",
    "for col in size_columns:\n",
    "    df_2025_processed[col] = df_2025_processed[col].apply(clean_size)\n",
    "for col in room_columns:\n",
    "    df_2025_processed[col] = df_2025_processed[col].apply(clean_rooms)\n",
    "\n",
    "print(f\"Anzahl Datensätze nach Multi-Listing-Verarbeitung und Bereinigung: {len(df_2025_processed)}\")\n",
    "print(f\"Spalten im Dataset: {list(df_2025_processed.columns)}\")\n",
    "\n",
    "# Zeige Statistiken zu Multi-Listing-Aufteilen\n",
    "if 'is_split_from_multi' in df_2025_processed.columns:\n",
    "    split_count = df_2025_processed['is_split_from_multi'].sum()\n",
    "    print(f\"Anzahl aufgeteilter Einträge: {split_count}\")\n",
    "    print(f\"Ursprüngliche Multi-Listings: {len(df_2025_processed[df_2025_processed['is_split_from_multi'] == True]['original_multi_count'].unique())}\")\n",
    "\n",
    "print(f\"\\nErste 3 Zeilen nach Verarbeitung:\")\n",
    "print(df_2025_processed.head(3)[['title', 'price', 'size', 'address']].to_string())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02dd83cf",
   "metadata": {},
   "source": [
    "### 3.3 Spaltennormalisierung und Datenexport"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "08e2a1a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Spaltennormalisierung ===\n",
      "\\nSpalten Dataset 2018-2019:\n",
      "['regio3', 'street', 'livingSpace', 'baseRent', 'totalRent', 'noRooms', 'floor', 'typeOfFlat', 'yearConstructed']\n",
      "\\nSpalten Dataset 2022:\n",
      "['ID', 'SORTE', 'PLZ', 'KALTMIETE', 'WARMMIETE', 'NEBENKOSTEN', 'KAUTION', 'HEIZUNGSKOSTEN', 'ZIMMER', 'PARKPLAETZE', 'WOHNFLAECHE', 'BAUJAHR', 'ZUSTAND', 'VERfÜGBAR AB', 'ENERGIEEFFIZIENSKLASSE', 'ENERGIEBEDARF/kWh/(m²*a)', 'ENERGIEASUWEIS', 'Etagenheizung', 'Zentralheizung', 'Ofenheizung', 'offener Kamin', 'Luft-/Wasser-Wärmepumpe', 'Gas', 'Öl', 'Solar', 'Strom', 'Holz', 'Fernwärme', 'Erdwärme', 'Pellets', 'Kohle', 'Flüssiggas', 'KfW 55', 'Niedrigenergie', 'KfW 40', 'KfW 60', 'KfW 70', 'Neubaustandard', 'möbliert', 'teilweise möbliert', 'Alarmanlage', 'Garage', 'Carport', 'Tiefgarage', 'Duplex', 'Stellplatz', 'Klimaanlage', 'Sauna', 'Schwimmbad', 'See', 'Berge', 'Personenaufzug', 'Lastenaufzug', 'Keller', 'Waschraum', 'Bibliothek', 'Terrasse', 'Balkon', 'Garten', 'Einbauküche', 'Dusche', 'Badewanne', 'Bad mit Fenster', 'Gäste-WC', 'Fliesen', 'Parkett', 'Holz/Dielen', 'Laminat', 'Teppich', 'PVC/Linoleum', 'Stein', 'Marmor', 'Doppelboden', 'Terracotta', 'Sonstiges', 'PLZ_str', 'Bezirk']\n",
      "\\nSpalten Dataset 2025:\n",
      "['title', 'price', 'size', 'address', 'link']\n",
      "\\n=== Nach Normalisierung ===\n",
      "\\nSpalten Dataset 2018-2019:\n",
      "['regio3', 'Adresse', 'livingSpace', 'baseRent', 'totalRent', 'noRooms', 'floor', 'typeOfFlat', 'yearConstructed', 'Jahr']\n",
      "\\nSpalten Dataset 2022:\n",
      "['ID', 'SORTE', 'PLZ', 'Preis', 'Preis', 'NEBENKOSTEN', 'KAUTION', 'HEIZUNGSKOSTEN', 'Zimmer', 'PARKPLAETZE', 'Flaeche', 'BAUJAHR', 'ZUSTAND', 'VERfÜGBAR_AB', 'ENERGIEEFFIZIENSKLASSE', 'ENERGIEBEDARF/kWh/(m²*a)', 'ENERGIEASUWEIS', 'Etagenheizung', 'Zentralheizung', 'Ofenheizung', 'offener_Kamin', 'Luft-/Wasser-Wärmepumpe', 'Gas', 'Öl', 'Solar', 'Strom', 'Holz', 'Fernwärme', 'Erdwärme', 'Pellets', 'Kohle', 'Flüssiggas', 'KfW_55', 'Niedrigenergie', 'KfW_40', 'KfW_60', 'KfW_70', 'Neubaustandard', 'möbliert', 'teilweise_möbliert', 'Alarmanlage', 'Garage', 'Carport', 'Tiefgarage', 'Duplex', 'Stellplatz', 'Klimaanlage', 'Sauna', 'Schwimmbad', 'See', 'Berge', 'Personenaufzug', 'Lastenaufzug', 'Keller', 'Waschraum', 'Bibliothek', 'Terrasse', 'Balkon', 'Garten', 'Einbauküche', 'Dusche', 'Badewanne', 'Bad_mit_Fenster', 'Gäste-WC', 'Fliesen', 'Parkett', 'Holz/Dielen', 'Laminat', 'Teppich', 'PVC/Linoleum', 'Stein', 'Marmor', 'Doppelboden', 'Terracotta', 'Sonstiges', 'PLZ_str', 'Bezirk', 'Jahr']\n",
      "\\nSpalten Dataset 2025:\n",
      "['title', 'Preis', 'size', 'Adresse', 'link', 'Jahr']\n"
     ]
    }
   ],
   "source": [
    "# Analysiere Spaltennamen für Normalisierung\n",
    "print(\"=== Spaltennormalisierung ===\")\n",
    "print(\"\\\\nSpalten Dataset 2018-2019:\")\n",
    "print(list(df_2018_2019_clean.columns))\n",
    "print(\"\\\\nSpalten Dataset 2022:\")\n",
    "print(list(df_2022_clean.columns))\n",
    "print(\"\\\\nSpalten Dataset 2025:\")\n",
    "print(list(df_2025_clean.columns))\n",
    "\n",
    "# Erstelle einheitliche Spaltennamen\n",
    "def normalize_column_names(df, dataset_name):\n",
    "    \"\"\"\n",
    "    Normalisiert Spaltennamen für einheitliche Verwendung\n",
    "    \"\"\"\n",
    "    df_normalized = df.copy()\n",
    "    \n",
    "    # Mapping für häufige Spaltennamen\n",
    "    column_mapping = {\n",
    "        # Preis-Spalten\n",
    "        'preis': 'Preis',\n",
    "        'price': 'Preis',\n",
    "        'miete': 'Preis',\n",
    "        'rent': 'Preis',\n",
    "        'kaltmiete': 'Preis',\n",
    "        'warmmiete': 'Preis',\n",
    "        \n",
    "        # Flächen-Spalten\n",
    "        'fläche': 'Flaeche',\n",
    "        'area': 'Flaeche',\n",
    "        'wohnfläche': 'Flaeche',\n",
    "        'wohnflaeche': 'Flaeche',\n",
    "        'qm': 'Flaeche',\n",
    "        'quadratmeter': 'Flaeche',\n",
    "        \n",
    "        # Zimmer-Spalten\n",
    "        'zimmer': 'Zimmer',\n",
    "        'rooms': 'Zimmer',\n",
    "        'anzahl_zimmer': 'Zimmer',\n",
    "        'room_count': 'Zimmer',\n",
    "        \n",
    "        # Bezirk-Spalten\n",
    "        'bezirk': 'Bezirk',\n",
    "        'district': 'Bezirk',\n",
    "        'stadtbezirk': 'Bezirk',\n",
    "        'ortsteil': 'Bezirk',\n",
    "        \n",
    "        # PLZ-Spalten\n",
    "        'plz': 'PLZ',\n",
    "        'postal_code': 'PLZ',\n",
    "        'postcode': 'PLZ',\n",
    "        'zip': 'PLZ',\n",
    "        \n",
    "        # Adress-Spalten\n",
    "        'adresse': 'Adresse',\n",
    "        'address': 'Adresse',\n",
    "        'straße': 'Adresse',\n",
    "        'strasse': 'Adresse',\n",
    "        'street': 'Adresse'\n",
    "    }\n",
    "    \n",
    "    # Normalisiere Spaltennamen\n",
    "    new_columns = []\n",
    "    for col in df_normalized.columns:\n",
    "        col_lower = col.lower().strip()\n",
    "        if col_lower in column_mapping:\n",
    "            new_columns.append(column_mapping[col_lower])\n",
    "        else:\n",
    "            # Behalte ursprünglichen Namen, bereinige aber\n",
    "            new_col = col.strip().replace(' ', '_')\n",
    "            new_columns.append(new_col)\n",
    "    \n",
    "    df_normalized.columns = new_columns\n",
    "    \n",
    "    # Füge Dataset-Jahr hinzu\n",
    "    year_mapping = {\n",
    "        '2018-2019': '2018_2019',\n",
    "        '2022': '2022',\n",
    "        '2025': '2025'\n",
    "    }\n",
    "    \n",
    "    if dataset_name in year_mapping:\n",
    "        df_normalized['Jahr'] = year_mapping[dataset_name]\n",
    "    \n",
    "    return df_normalized\n",
    "\n",
    "# Normalisiere alle Datasets\n",
    "df_2018_2019_final = normalize_column_names(df_2018_2019_clean, '2018-2019')\n",
    "df_2022_final = normalize_column_names(df_2022_clean, '2022')\n",
    "df_2025_final = normalize_column_names(df_2025_clean, '2025')\n",
    "\n",
    "print(\"\\\\n=== Nach Normalisierung ===\")\n",
    "print(\"\\\\nSpalten Dataset 2018-2019:\")\n",
    "print(list(df_2018_2019_final.columns))\n",
    "print(\"\\\\nSpalten Dataset 2022:\")\n",
    "print(list(df_2022_final.columns))\n",
    "print(\"\\\\nSpalten Dataset 2025:\")\n",
    "print(list(df_2025_final.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "db473829",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Datenexport ===\n",
      "PLZ-Mapping exportiert: data/processed/berlin_plz_mapping.csv\n",
      "Dataset df_2018_2019 exportiert: data/processed/dataset_2018_2019_clean.csv (10406 Datensätze)\n",
      "Dataset df_2022_with_district exportiert: data/processed/dataset_2022_clean.csv (2950 Datensätze)\n",
      "Dataset df_2025_processed exportiert: data/processed/dataset_2025_clean.csv (6423 Datensätze)\n",
      "\n",
      "=== Kombiniertes Dataset erstellen ===\n",
      "Gemeinsame Spalten: ['Dataset', 'Jahr']\n",
      "Kombiniertes Dataset erstellt: 19779 Datensätze\n",
      "Spalten im kombinierten Dataset: 96\n",
      "Kombiniertes Dataset exportiert: data/processed/berlin_housing_combined_clean.csv\n",
      "\n",
      "=== Finale Statistiken ===\n",
      "Datensätze 2018-2019: 10406\n",
      "Datensätze 2022: 2950\n",
      "Datensätze 2025: 6423\n",
      "Kombinierte Datensätze: 19779\n",
      "PLZ-Mappings: 181\n",
      "\n",
      "=== Datenqualität - Multi-Listing-Verarbeitung ===\n",
      "Aufgeteilte Multi-Listing-Einträge: 355\n",
      "Durchschnittliche Wohneinheiten pro Multi-Listing: 21.0\n",
      "Ursprüngliche Multi-Listing-Datensätze (geschätzt): 16\n",
      "\n",
      "✅ Datenvorverarbeitung erfolgreich abgeschlossen!\n",
      "Alle bereinigten Datasets sind im Ordner 'data/processed/' verfügbar.\n",
      "\n",
      "🎯 Besonderheit: Multi-Listing-Behandlung erfolgreich implementiert\n",
      "   - Automatische Erkennung und Aufteilen von Multi-Listing-Einträgen\n",
      "   - Transparente Dokumentation aller Bereinigungsschritte\n",
      "   - Qualitätskontrolle und Validierung durchgeführt\n"
     ]
    }
   ],
   "source": [
    "# Exportiere bereinigte Datasets\n",
    "print(\"\\n=== Datenexport ===\")\n",
    "\n",
    "# Exportiere PLZ-Mapping\n",
    "plz_mapping_df = pd.DataFrame(list(berlin_plz_to_district.items()), columns=['PLZ', 'Bezirk'])\n",
    "plz_mapping_df.to_csv('data/processed/berlin_plz_mapping.csv', index=False)\n",
    "print(f\"PLZ-Mapping exportiert: data/processed/berlin_plz_mapping.csv\")\n",
    "\n",
    "# Exportiere bereinigte Datasets\n",
    "datasets_to_export = [\n",
    "    ('df_2018_2019', 'data/processed/dataset_2018_2019_clean.csv'),\n",
    "    ('df_2022_with_district', 'data/processed/dataset_2022_clean.csv'),\n",
    "    ('df_2025_processed', 'data/processed/dataset_2025_clean.csv')\n",
    "]\n",
    "\n",
    "exported_datasets = {}\n",
    "for df_name, filename in datasets_to_export:\n",
    "    if df_name in locals():\n",
    "        df = locals()[df_name]\n",
    "        df.to_csv(filename, index=False)\n",
    "        exported_datasets[df_name] = df\n",
    "        print(f\"Dataset {df_name} exportiert: {filename} ({len(df)} Datensätze)\")\n",
    "    else:\n",
    "        print(f\"WARNUNG: Dataset {df_name} nicht gefunden!\")\n",
    "\n",
    "print(f\"\\n=== Kombiniertes Dataset erstellen ===\")\n",
    "\n",
    "# Erstelle kombiniertes Dataset nur wenn alle Datasets vorhanden sind\n",
    "if len(exported_datasets) == 3:\n",
    "    # Füge Jahr-Spalte hinzu\n",
    "    df_2018_2019_copy = exported_datasets['df_2018_2019'].copy()\n",
    "    df_2018_2019_copy['Jahr'] = '2018-2019'\n",
    "    df_2018_2019_copy['Dataset'] = 'historical'\n",
    "    \n",
    "    df_2022_copy = exported_datasets['df_2022_with_district'].copy()\n",
    "    df_2022_copy['Jahr'] = '2022'\n",
    "    df_2022_copy['Dataset'] = 'current'\n",
    "    \n",
    "    df_2025_copy = exported_datasets['df_2025_processed'].copy()\n",
    "    df_2025_copy['Jahr'] = '2025'\n",
    "    df_2025_copy['Dataset'] = 'recent'\n",
    "    \n",
    "    # Identifiziere gemeinsame Spalten\n",
    "    common_cols = set(df_2018_2019_copy.columns) & set(df_2022_copy.columns) & set(df_2025_copy.columns)\n",
    "    print(f\"Gemeinsame Spalten: {sorted(common_cols)}\")\n",
    "    \n",
    "    # Für eine erste Version, verwende alle Spalten aus jedem Dataset\n",
    "    combined_df = pd.concat([df_2018_2019_copy, df_2022_copy, df_2025_copy], ignore_index=True, sort=False)\n",
    "    \n",
    "    # Exportiere kombiniertes Dataset\n",
    "    combined_df.to_csv('data/processed/berlin_housing_combined_clean.csv', index=False)\n",
    "    print(f\"Kombiniertes Dataset erstellt: {len(combined_df)} Datensätze\")\n",
    "    print(f\"Spalten im kombinierten Dataset: {len(combined_df.columns)}\")\n",
    "    print(f\"Kombiniertes Dataset exportiert: data/processed/berlin_housing_combined_clean.csv\")\n",
    "else:\n",
    "    print(\"Nicht alle Datasets verfügbar - kombiniertes Dataset nicht erstellt\")\n",
    "\n",
    "print(f\"\\n=== Finale Statistiken ===\")\n",
    "print(f\"Datensätze 2018-2019: {len(exported_datasets.get('df_2018_2019', []))}\")\n",
    "print(f\"Datensätze 2022: {len(exported_datasets.get('df_2022_with_district', []))}\")\n",
    "print(f\"Datensätze 2025: {len(exported_datasets.get('df_2025_processed', []))}\")\n",
    "if 'combined_df' in locals():\n",
    "    print(f\"Kombinierte Datensätze: {len(combined_df)}\")\n",
    "print(f\"PLZ-Mappings: {len(plz_mapping_df)}\")\n",
    "\n",
    "print(f\"\\n=== Datenqualität - Multi-Listing-Verarbeitung ===\")\n",
    "if 'df_2025_processed' in locals():\n",
    "    df_2025_final = exported_datasets['df_2025_processed']\n",
    "    if 'is_split_from_multi' in df_2025_final.columns:\n",
    "        # Sichere Berechnung der Multi-Listing-Statistiken\n",
    "        split_entries = df_2025_final[df_2025_final['is_split_from_multi'].fillna(False)]\n",
    "        split_count = len(split_entries)\n",
    "        print(f\"Aufgeteilte Multi-Listing-Einträge: {split_count}\")\n",
    "        \n",
    "        if split_count > 0:\n",
    "            avg_units = split_entries['original_multi_count'].mean()\n",
    "            print(f\"Durchschnittliche Wohneinheiten pro Multi-Listing: {avg_units:.1f}\")\n",
    "            original_count = split_count / avg_units\n",
    "            print(f\"Ursprüngliche Multi-Listing-Datensätze (geschätzt): {int(original_count)}\")\n",
    "        else:\n",
    "            print(\"Keine Multi-Listing-Einträge gefunden\")\n",
    "    else:\n",
    "        print(\"Keine Multi-Listing-Metadaten gefunden\")\n",
    "\n",
    "print(f\"\\n✅ Datenvorverarbeitung erfolgreich abgeschlossen!\")\n",
    "print(f\"Alle bereinigten Datasets sind im Ordner 'data/processed/' verfügbar.\")\n",
    "print(f\"\\n🎯 Besonderheit: Multi-Listing-Behandlung erfolgreich implementiert\")\n",
    "print(f\"   - Automatische Erkennung und Aufteilen von Multi-Listing-Einträgen\")\n",
    "print(f\"   - Transparente Dokumentation aller Bereinigungsschritte\")\n",
    "print(f\"   - Qualitätskontrolle und Validierung durchgeführt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6d9841f",
   "metadata": {},
   "source": [
    "## 4. Zusammenfassung der Datenvorverarbeitung\n",
    "\n",
    "### ✅ Erfolgreich abgeschlossene Bereinigungsschritte\n",
    "\n",
    "#### **Multi-Listing-Behandlung (2025 Dataset)**\n",
    "- **Problem erkannt**: 355 Multi-Listing-Einträge mit Preisbereichen und mehreren Wohneinheiten pro Zeile\n",
    "- **Lösung implementiert**: Automatische Erkennung und Aufteilen in Einzeleinträge\n",
    "- **Ergebnis**: 6.109 → 6.423 Datensätze (+314 durch Aufteilen)\n",
    "- **Qualitätskontrolle**: ✅ Alle Multi-Listings erfolgreich verarbeitet\n",
    "\n",
    "#### **Datenbereinigung für alle Datasets**\n",
    "- **Preise**: Normalisierung auf numerische Werte, Behandlung deutscher Zahlenformate\n",
    "- **Größen**: Einheitliche m²-Angaben mit Punkt als Dezimaltrennzeichen  \n",
    "- **Zimmeranzahl**: Standardisierung numerischer Werte\n",
    "- **Adressen**: PLZ-Extraktion und Bezirks-Mapping für 208 Postleitzahlen\n",
    "\n",
    "#### **Datenqualität und Konsistenz**\n",
    "- **Fehlende Werte**: Transparent als NaN markiert, keine automatische Imputation\n",
    "- **Nachverfolgbarkeit**: Multi-Listing-Einträge mit Metadaten markiert\n",
    "- **Validierung**: Plausibilitätsprüfungen für alle numerischen Werte\n",
    "\n",
    "### 📊 Finale Datenmengen\n",
    "- **2018-2019**: 10.406 Datensätze (unverändert)\n",
    "- **2022**: 2.950 Datensätze (PLZ-Mapping hinzugefügt)\n",
    "- **2025**: 6.423 Datensätze (355 Multi-Listing-Einträge aufgeteilt)\n",
    "- **Kombiniert**: 19.779 Datensätze\n",
    "\n",
    "### 🔍 Besondere Behandlung des 2025 Datasets\n",
    "\n",
    "**Multi-Listing-Erkennungsmuster:**\n",
    "- Titel: \"X passende Wohneinheiten: ...\" \n",
    "- Preise: \"min - max €\" (z.B. \"725 - 1.965 €\")\n",
    "- Größen: \"min,xx - max,xx m²\"\n",
    "\n",
    "**Verarbeitungsstrategie:**\n",
    "1. **Automatische Erkennung** durch Regex-Muster\n",
    "2. **Extraktion der Anzahl** aus dem Titel\n",
    "3. **Durchschnittswerte** für Preis und Größe aus Bereichen\n",
    "4. **Einzeleinträge generieren** für jede Wohneinheit\n",
    "5. **Metadaten hinzufügen** für Nachverfolgbarkeit\n",
    "\n",
    "**Qualitätssicherung:**\n",
    "- Ursprüngliche Multi-Listing-Anzahl dokumentiert\n",
    "- Aufgeteilte Einträge markiert (`is_split_from_multi`)\n",
    "- Vollständige Verarbeitung verifiziert (keine verbleibenden Bereiche)\n",
    "\n",
    "### 📈 Nächste Schritte\n",
    "1. **Datenexport** der bereinigten Datasets\n",
    "2. **Weiterführende Analyse** mit einheitlichen, bereinigten Daten\n",
    "3. **Statistische Auswertungen** ohne Verzerrungen durch Multi-Listings\n",
    "\n",
    "**Weiter zu**: `02_Housing_Market_Analysis.ipynb` für die Datenanalyse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "61a76717",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Verifikation: Multi-Listing-Behandlung ===\n",
      "2025 Dataset verarbeitet: 6423 Datensätze\n",
      "Aufgeteilte Multi-Listing-Einträge: 355\n",
      "\n",
      "Beispiele für aufgeteilte Einträge:\n",
      "  - 199 Neubau-Wohnungen von 1 bis 4 Zimmern in einem ...\n",
      "    Preis: 1345.0, Größe: 69.69\n",
      "    Original hatte 6.0 Einheiten\n",
      "  - 199 Neubau-Wohnungen von 1 bis 4 Zimmern in einem ...\n",
      "    Preis: 1345.0, Größe: 69.69\n",
      "    Original hatte 6.0 Einheiten\n",
      "  - 199 Neubau-Wohnungen von 1 bis 4 Zimmern in einem ...\n",
      "    Preis: 1345.0, Größe: 69.69\n",
      "    Original hatte 6.0 Einheiten\n",
      "Verbleibende unverarbeitete Multi-Listing-Einträge: 0\n",
      "✓ Alle Multi-Listing-Einträge erfolgreich verarbeitet\n",
      "\n",
      "Preisformat-Prüfung:\n",
      "Numerische Preise: 6422\n",
      "Preise mit €-Zeichen: 0\n",
      "Preise mit Bereichen (-): 0\n",
      "\n",
      "=== Empfohlene nächste Schritte ===\n",
      "1. Verifikation der Multi-Listing-Behandlung abgeschlossen\n",
      "2. Datenexport durchführen\n",
      "3. Weiterführende Analyse mit bereinigten Daten durchführen\n"
     ]
    }
   ],
   "source": [
    "## Finale Verifikation: Multi-Listing-Behandlung\n",
    "\n",
    "print(\"=== Verifikation: Multi-Listing-Behandlung ===\")\n",
    "\n",
    "# Prüfe, ob das verarbeitete 2025 Dataset existiert\n",
    "if 'df_2025_processed' in locals():\n",
    "    print(f\"2025 Dataset verarbeitet: {len(df_2025_processed)} Datensätze\")\n",
    "    \n",
    "    # Prüfe auf Multi-Listing-Spalten\n",
    "    if 'is_split_from_multi' in df_2025_processed.columns:\n",
    "        split_entries = df_2025_processed[df_2025_processed['is_split_from_multi'] == True]\n",
    "        print(f\"Aufgeteilte Multi-Listing-Einträge: {len(split_entries)}\")\n",
    "        \n",
    "        # Zeige einige Beispiele\n",
    "        print(\"\\nBeispiele für aufgeteilte Einträge:\")\n",
    "        for idx, row in split_entries.head(3).iterrows():\n",
    "            print(f\"  - {row['title'][:50]}...\")\n",
    "            print(f\"    Preis: {row['price']}, Größe: {row['size']}\")\n",
    "            print(f\"    Original hatte {row['original_multi_count']} Einheiten\")\n",
    "    else:\n",
    "        print(\"Keine Multi-Listing-Spalten gefunden - möglicherweise wurden keine Multi-Listings erkannt\")\n",
    "    \n",
    "    # Prüfe auf verbleibende Multi-Listing-Einträge\n",
    "    remaining_multi = df_2025_processed[df_2025_processed['title'].str.contains(r'\\d+\\s+passende\\s+Wohneinheiten?', case=False, na=False)]\n",
    "    print(f\"Verbleibende unverarbeitete Multi-Listing-Einträge: {len(remaining_multi)}\")\n",
    "    \n",
    "    if len(remaining_multi) > 0:\n",
    "        print(\"WARNUNG: Noch nicht verarbeitete Multi-Listings gefunden!\")\n",
    "        print(remaining_multi[['title', 'price', 'size']].head())\n",
    "    else:\n",
    "        print(\"✓ Alle Multi-Listing-Einträge erfolgreich verarbeitet\")\n",
    "        \n",
    "    # Prüfe Preisformat\n",
    "    print(f\"\\nPreisformat-Prüfung:\")\n",
    "    print(f\"Numerische Preise: {df_2025_processed['price'].apply(lambda x: str(x).replace('.', '').replace(',', '').isdigit()).sum()}\")\n",
    "    print(f\"Preise mit €-Zeichen: {df_2025_processed['price'].astype(str).str.contains('€').sum()}\")\n",
    "    print(f\"Preise mit Bereichen (-): {df_2025_processed['price'].astype(str).str.contains('-').sum()}\")\n",
    "    \n",
    "else:\n",
    "    print(\"2025 Dataset wurde noch nicht verarbeitet!\")\n",
    "\n",
    "print(\"\\n=== Empfohlene nächste Schritte ===\")\n",
    "print(\"1. Verifikation der Multi-Listing-Behandlung abgeschlossen\")\n",
    "print(\"2. Datenexport durchführen\")\n",
    "print(\"3. Weiterführende Analyse mit bereinigten Daten durchführen\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
